{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import feedparser\n",
    "import re\n",
    "import numpy\n",
    "from datetime import datetime, timezone\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from keybert.llm import TextGeneration\n",
    "from keybert import KeyLLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "endpoint = \"https://active-monitor-48.hasura.app/v1/graphql\"\n",
    "admin_key = \"bAQuK7HSYvMAp6S6pnqXH0wQlyuKNUICzoW3jwecc27pwz6COLhE750s5YAec7Hz\"\n",
    "\n",
    "\n",
    "def query_hasura_graphql(endpoint, admin_key, query, variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'query': query,\n",
    "        'variables': variables\n",
    "    }\n",
    "    response = requests.post(endpoint, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def is_valid_timezone_format(published):\n",
    "    try:\n",
    "        # Attempt to parse the string\n",
    "        date_format = \"%a, %d %b %Y %H:%M:%S %z\"\n",
    "        date_object = datetime.strptime(published, date_format)\n",
    "\n",
    "        hasura_timestamp = date_object.astimezone(timezone.utc).isoformat()\n",
    "        return True, hasura_timestamp\n",
    "    except ValueError:\n",
    "        # If parsing fails, the string is not in the correct format\n",
    "        return False, None\n",
    "\n",
    "def check_date_format(date_string):\n",
    "    try:\n",
    "        datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def mutation_hasura_graphql(endpoint, admin_key, mutation_query, mutation_variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "    response = requests.post(endpoint, json={'query': mutation_query, 'variables': mutation_variables}, headers=headers)\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "        return True, data\n",
    "    else:\n",
    "        print(f\"Mutation failed with status code {response.status_code}: {response.text}\")\n",
    "        return False, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array2dto2d(n2):\n",
    "    n1 = []\n",
    "    for sublist in n2:\n",
    "        for element in sublist:\n",
    "            n1.append(element)\n",
    "    n2 = list(set(n1))\n",
    "    return n2\n",
    "def detail_tags(offset1):\n",
    "  graphql_query = '''\n",
    "  query MyQuery($limit: Int!, $offset: Int!) {\n",
    "  synopse_articles_t_v4_article_groups_l2_detail(where: {logo_urls: {_is_null: true}, summary_60_words: {_is_null: false}}, limit: $limit, offset: $offset) {\n",
    "      id\n",
    "      t_v3_article_groups_l2 {\n",
    "        articles_group\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  '''\n",
    "  query2 = '''\n",
    "  query MyQuery($article_id: bigint = \"\") {\n",
    "    synopse_articles_t_v1_rss1_articles(where: {id: {_eq: $article_id}}) {\n",
    "      image_link\n",
    "      tags\n",
    "      t_v1_rss1_feed_link {\n",
    "        t_v1_outlet {\n",
    "          logo_url\n",
    "        }\n",
    "      }\n",
    "      t_v2_articles_summary {\n",
    "        keywords_tags\n",
    "        location_tags\n",
    "        org_tags\n",
    "        person_tags\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  '''\n",
    "  offset = offset1\n",
    "  mutation_query = \"\"\"\n",
    "  mutation MyMutation($updates: [synopse_articles_t_v4_article_groups_l2_detail_updates!] = {where: {}}) {\n",
    "    update_synopse_articles_t_v4_article_groups_l2_detail_many(updates: $updates) {\n",
    "      affected_rows\n",
    "    }\n",
    "  }\n",
    "  \"\"\"\n",
    "  while True:\n",
    "      variables = {\n",
    "      \"limit\": 1,\n",
    "      \"offset\": offset\n",
    "      }\n",
    "      response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "      synopse_articles_t_v4_article_groups_l2_detail_updates_loc=[]\n",
    "      image_urls=[]\n",
    "      logo_urls=[]\n",
    "      keywords_tags=[]\n",
    "      location_tags=[]\n",
    "      org_tags=[]\n",
    "      person_tags=[]\n",
    "      if len(response_data['data']['synopse_articles_t_v4_article_groups_l2_detail']) == 0:\n",
    "            break\n",
    "      for response in response_data['data']['synopse_articles_t_v4_article_groups_l2_detail']:\n",
    "          for article in response['t_v3_article_groups_l2']['articles_group']:\n",
    "              variables2 = {\n",
    "              \"article_id\": article\n",
    "              }\n",
    "              response_data1 = query_hasura_graphql(endpoint, admin_key, query2, variables2)\n",
    "              for response1 in response_data1['data']['synopse_articles_t_v1_rss1_articles']:\n",
    "                  image_urls.append(response1['image_link'])\n",
    "                  logo_urls.append(response1['t_v1_rss1_feed_link']['t_v1_outlet']['logo_url'])\n",
    "                  keywords_tags.append(response1['tags'])\n",
    "                  keywords_tags.append(response1['t_v2_articles_summary']['keywords_tags'])\n",
    "                  location_tags.append(response1['t_v2_articles_summary']['location_tags'])\n",
    "                  org_tags.append(response1['t_v2_articles_summary']['org_tags'])\n",
    "                  person_tags.append(response1['t_v2_articles_summary']['person_tags'])\n",
    "      image_urls = list(set(image_urls))\n",
    "      logo_urls = list(set(logo_urls))\n",
    "      keywords_tags = array2dto2d(keywords_tags)\n",
    "      location_tags = array2dto2d(location_tags)\n",
    "      org_tags = array2dto2d(org_tags)\n",
    "      person_tags = array2dto2d(person_tags)\n",
    "      synopse_articles_t_v4_article_groups_l2_detail_updates_loc.append({\n",
    "          \"where\": {\"id\" : { \"_eq\": response['id'] }},\n",
    "          \"_set\": {\"image_urls\": image_urls,\n",
    "                  \"logo_urls\": logo_urls,\n",
    "                  \"keywords_tags\": keywords_tags,\n",
    "                  \"location_tags\": location_tags,\n",
    "                  \"org_tags\": org_tags,\n",
    "                  \"person_tags\": person_tags }\n",
    "          })\n",
    "      mutation_variables = {\n",
    "      \"updates\": synopse_articles_t_v4_article_groups_l2_detail_updates_loc,\n",
    "      }\n",
    "      out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "\n",
    "detail_tags(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "  synopse_articles_t_v3_article_groups_l1(where: {t_v1_rss1_article: {is_grouped: {_eq: 1}}, article_count: {_gt: 1}}, order_by: {updated_at: asc}, limit: $limit, offset: $offset) {\n",
    "    article_id\n",
    "    initial_group\n",
    "  }\n",
    "}\n",
    "'''\n",
    "query2 = '''\n",
    "query MyQuery($articleid: [bigint!] = []) {\n",
    "    synopse_articles_t_v3_article_groups_l1(where: {initial_group: {_contains: $articleid}}) {\n",
    "    article_id\n",
    "    initial_group\n",
    "    }\n",
    "}\n",
    "'''\n",
    "query3 = '''\n",
    "query MyQuery($articleid: [bigint!] = []) {\n",
    "    synopse_articles_t_v3_article_groups_l2(where: {articles_group: {_contains: $articleid}}, order_by: {is_valid: desc, updated_at: desc}) {\n",
    "    id\n",
    "    articles_group\n",
    "    is_valid\n",
    "    }\n",
    "}\n",
    "'''\n",
    "mutation_query = \"\"\"\n",
    "mutation MyMutation($objects: [synopse_articles_t_v3_article_groups_l2_insert_input!] = {}, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = {where: {}}, $updates1: [synopse_articles_t_v3_article_groups_l2_updates!] = {where: {}}, $articleGroupIds: [bigint!] = \"\") {\n",
    "  insert_synopse_articles_t_v3_article_groups_l2(objects: $objects, on_conflict: {constraint: t_v3_article_groups_l2_pkey}) {\n",
    "    affected_rows\n",
    "  }\n",
    "  update_synopse_articles_t_v1_rss1_articles_many(updates: $updates) {\n",
    "    affected_rows\n",
    "  }\n",
    "  update_synopse_articles_t_v3_article_groups_l2_many(updates: $updates1) {\n",
    "    affected_rows\n",
    "  }\n",
    "  delete_synopse_articles_t_v3_article_groups_l2(where: {id: {_in: $articleGroupIds}}) {\n",
    "    affected_rows\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "while True:\n",
    "    variables = {\n",
    "    \"limit\": 1,\n",
    "    \"offset\": 0\n",
    "    }\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    synopse_articles_t_v3_article_groups_l2_insert_input_loc=[]\n",
    "    synopse_articles_t_v1_rss1_articles_updates_loc=[]\n",
    "    synopse_articles_t_v3_article_groups_l2_updates_loc=[]\n",
    "    articleGroupIds_loc=[]\n",
    "    if len(response_data['data']['synopse_articles_t_v3_article_groups_l1']) == 0:\n",
    "        break\n",
    "    for response in response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "        variables2 = {\n",
    "            \"articleid\": [response['article_id']]\n",
    "            }\n",
    "        response_data1 = query_hasura_graphql(endpoint, admin_key, query2, variables2)\n",
    "        articles_ids = []\n",
    "        if len(response_data1['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "            for func_response in response_data1['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "                articles_ids.append(func_response['initial_group'])\n",
    "        n1 = []\n",
    "        for sublist in articles_ids:\n",
    "            for element in sublist:\n",
    "                n1.append(element)\n",
    "        articles_ids = list(set(n1))\n",
    "        articles_ids.sort(reverse=True)\n",
    "        while True:\n",
    "            if len(articles_ids) > 1:\n",
    "                articles_news = []\n",
    "                for article_id in articles_ids:\n",
    "                    variables3 = {\n",
    "                        \"articleid\": [article_id]\n",
    "                        }\n",
    "                    response_data2 = query_hasura_graphql(endpoint, admin_key, query2, variables3)\n",
    "                    if len(response_data1['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "                        for func_response in response_data1['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "                            articles_news.append(func_response['initial_group'])\n",
    "                n2 = []\n",
    "                for sublist in articles_news:\n",
    "                    for element in sublist:\n",
    "                        n2.append(element)\n",
    "                articles_news = list(set(n2))\n",
    "                articles_news.sort(reverse=True)\n",
    "                if articles_ids == articles_news:\n",
    "                    break\n",
    "                else:\n",
    "                    articles_ids = articles_news\n",
    "        n5 = []\n",
    "        for a1 in articles_ids:\n",
    "            variables3 = {\n",
    "                \"articleid\": [a1]\n",
    "                }\n",
    "            response_data2 = query_hasura_graphql(endpoint, admin_key, query3, variables3)\n",
    "            if len(response_data2['data']['synopse_articles_t_v3_article_groups_l2']) > 0:\n",
    "                for func_response in response_data2['data']['synopse_articles_t_v3_article_groups_l2']:\n",
    "                    n5.append(func_response['articles_group'])\n",
    "                    if func_response('is_valid') == 0:\n",
    "                        articleGroupIds_loc.append(func_response['id'])\n",
    "        n5.append(articles_ids)\n",
    "        n2 = []\n",
    "        for sublist in n5:\n",
    "            for element in sublist:\n",
    "                n2.append(element)\n",
    "        articles_ids = list(set(n2))\n",
    "        articles_ids.sort(reverse=True)\n",
    "        synopse_articles_t_v3_article_groups_l2_insert_input_loc.append({\n",
    "            \"articles_group\": articles_ids,\n",
    "            'articles_in_group': len(articles_ids)\n",
    "            }\n",
    "            )\n",
    "        for article in articles_ids:\n",
    "            synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "                \"where\": {\"id\" : { \"_eq\": article }},\n",
    "                \"_set\": {\"is_grouped\": 2}\n",
    "                })\n",
    "    mutation_variables = {\n",
    "        \"objects\": synopse_articles_t_v3_article_groups_l2_insert_input_loc,\n",
    "        \"updates\": synopse_articles_t_v1_rss1_articles_updates_loc,\n",
    "        \"updates1\": synopse_articles_t_v3_article_groups_l2_updates_loc,\n",
    "        \"articleGroupIds\": articleGroupIds_loc\n",
    "        }\n",
    "    out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[504, 441]\n",
      "441\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[515, 275]\n",
      "275\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[442, 30]\n",
      "30\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[500, 305, 284, 109]\n",
      "109\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[504, 441]\n",
      "441\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[448, 270]\n",
      "270\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[413, 51]\n",
      "51\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[287, 77, 61]\n",
      "61\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[290, 64]\n",
      "64\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[362, 293]\n",
      "293\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[312, 125]\n",
      "125\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[299, 282]\n",
      "282\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[347, 319, 316, 119]\n",
      "119\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[515, 275]\n",
      "275\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[347, 319, 316, 119]\n",
      "119\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[310, 280]\n",
      "280\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[347, 319, 316]\n",
      "316\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[320, 295]\n",
      "295\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[362, 293]\n",
      "293\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n",
      "[310, 280]\n",
      "280\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l2': []}}\n"
     ]
    }
   ],
   "source": [
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "  synopse_articles_t_v3_article_groups_l1(where: {t_v1_rss1_article: {is_grouped: {_eq: 1}}, article_count: {_gt: 1}}, order_by: {updated_at: asc}, limit: $limit, offset: $offset) {\n",
    "    article_id\n",
    "    initial_group\n",
    "  }\n",
    "}\n",
    "'''\n",
    "query2 = '''\n",
    "query MyQuery($articleid: [bigint!] = []) {\n",
    "    synopse_articles_t_v3_article_groups_l1(where: {initial_group: {_contains: $articleid}}) {\n",
    "    article_id\n",
    "    initial_group\n",
    "    }\n",
    "}\n",
    "'''\n",
    "query3 = '''\n",
    "query MyQuery($articleid: [bigint!] = []) {\n",
    "    synopse_articles_t_v3_article_groups_l2(where: {articles_group: {_contains: $articleid}, is_valid: {_eq: 0}}, order_by: {is_valid: desc, updated_at: desc}, limit: 1) {\n",
    "    id\n",
    "    articles_group\n",
    "    is_summerized\n",
    "    is_valid\n",
    "    }\n",
    "}\n",
    "'''\n",
    "mutation_query = \"\"\"\n",
    "mutation MyMutation($objects: [synopse_articles_t_v3_article_groups_l2_insert_input!] = {}, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = {where: {}}, $updates1: [synopse_articles_t_v3_article_groups_l2_updates!] = {where: {}}, $articleGroupIds: [bigint!] = \"\") {\n",
    "  insert_synopse_articles_t_v3_article_groups_l2(objects: $objects, on_conflict: {constraint: t_v3_article_groups_l2_pkey}) {\n",
    "    affected_rows\n",
    "  }\n",
    "  update_synopse_articles_t_v1_rss1_articles_many(updates: $updates) {\n",
    "    affected_rows\n",
    "  }\n",
    "  update_synopse_articles_t_v3_article_groups_l2_many(updates: $updates1) {\n",
    "    affected_rows\n",
    "  }\n",
    "  delete_synopse_articles_t_v3_article_groups_l2(where: {id: {_in: $articleGroupIds}}) {\n",
    "    affected_rows\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "variables = {\n",
    "\"limit\": 20,\n",
    "\"offset\": 0\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "synopse_articles_t_v3_article_groups_l2_insert_input_loc=[]\n",
    "synopse_articles_t_v1_rss1_articles_updates_loc=[]\n",
    "synopse_articles_t_v3_article_groups_l2_updates_loc=[]\n",
    "articleGroupIds=[]\n",
    "for response in response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "    variables2 = {\n",
    "        \"articleid\": [response['article_id']]\n",
    "        }\n",
    "    response_data1 = query_hasura_graphql(endpoint, admin_key, query2, variables2)\n",
    "    articles_ids = []\n",
    "    if len(response_data1['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "        for func_response in response_data1['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "            articles_ids.append(func_response['initial_group'])\n",
    "    n1 = []\n",
    "    for sublist in articles_ids:\n",
    "        for element in sublist:\n",
    "            n1.append(element)\n",
    "    articles_ids = list(set(n1))\n",
    "    articles_ids.sort(reverse=True)\n",
    "    while True:\n",
    "        if len(articles_ids) > 1:\n",
    "            articles_news = []\n",
    "            for article_id in articles_ids:\n",
    "                variables3 = {\n",
    "                    \"articleid\": [article_id]\n",
    "                    }\n",
    "                response_data2 = query_hasura_graphql(endpoint, admin_key, query2, variables3)\n",
    "                if len(response_data1['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "                    for func_response in response_data1['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "                        articles_news.append(func_response['initial_group'])\n",
    "            n2 = []\n",
    "            for sublist in articles_news:\n",
    "                for element in sublist:\n",
    "                    n2.append(element)\n",
    "            articles_news = list(set(n2))\n",
    "            articles_news.sort(reverse=True)\n",
    "            if articles_ids == articles_news:\n",
    "                break\n",
    "            else:\n",
    "                articles_ids = articles_news\n",
    "     \n",
    "    last_element = articles_ids[-1]\n",
    "    variables3 = {\n",
    "        \"articleid\": [last_element]\n",
    "        }\n",
    "    response_data2 = query_hasura_graphql(endpoint, admin_key, query3, variables3)\n",
    "    if len (response_data2['data']['synopse_articles_t_v3_article_groups_l2'] > 0):\n",
    "        for func_response in response_data2['data']['synopse_articles_t_v3_article_groups_l2']:\n",
    "            articles_ids.append(func_response['articles_group'])\n",
    "            articleGroupIds.append(func_response['id'])\n",
    "        n2 = []\n",
    "        for sublist in articles_ids:\n",
    "            for element in sublist:\n",
    "                n2.append(element)\n",
    "        articles_ids = list(set(n2))\n",
    "        articles_ids.sort(reverse=True)\n",
    "    synopse_articles_t_v3_article_groups_l2_insert_input_loc.append({\n",
    "        \"articles_group\": articles_ids,\n",
    "        'articles_in_group': len(articles_ids)\n",
    "        }\n",
    "        )\n",
    "    for article in articles_ids:\n",
    "        synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "            \"where\": {\"id\" : { \"_eq\": article }},\n",
    "            \"_set\": {\"is_grouped\": 2}\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "  synopse_articles_t_v3_article_groups_l1(where: {t_v1_rss1_article: {is_grouped: {_eq: 1}}, article_count: {_gt: 1}}, order_by: {updated_at: asc}, limit: $limit, offset: $offset) {\n",
    "    article_id\n",
    "    initial_group\n",
    "  }\n",
    "}\n",
    "'''\n",
    "query2 = '''\n",
    "query MyQuery($articleid: [bigint!] = []) {\n",
    "    synopse_articles_t_v3_article_groups_l1(where: {initial_group: {_contains: $articleid}}) {\n",
    "    article_id\n",
    "    initial_group\n",
    "    }\n",
    "}\n",
    "'''\n",
    "query3 = '''\n",
    "query MyQuery($articleid: [bigint!] = []) {\n",
    "    synopse_articles_t_v3_article_groups_l2(where: {articles_group: {_contains: $articleid}, is_valid: {_eq: 0}}, order_by: {is_valid: desc, updated_at: desc}, limit: 1) {\n",
    "    id\n",
    "    articles_group\n",
    "    is_summerized\n",
    "    is_valid\n",
    "    }\n",
    "}\n",
    "'''\n",
    "mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [synopse_articles_t_v3_article_groups_l2_insert_input!] = {}, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = {where: {}}, $updates1: [synopse_articles_t_v3_article_groups_l2_updates!] = {where: {}}) {\n",
    "        insert_synopse_articles_t_v3_article_groups_l2(objects: $objects, on_conflict: {constraint: t_v3_article_groups_l2_pkey}) {\n",
    "        affected_rows\n",
    "        }\n",
    "        update_synopse_articles_t_v1_rss1_articles_many(updates: $updates) {\n",
    "        affected_rows\n",
    "        }\n",
    "        update_synopse_articles_t_v3_article_groups_l2_many(updates: $updates1) {\n",
    "        affected_rows\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "variables = {\n",
    "\"limit\": 2,\n",
    "\"offset\": 0\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "for response in response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "    print(response)\n",
    "    variables2 = {\n",
    "        \"articleid\": [response['article_id']]\n",
    "        }\n",
    "    synopse_articles_t_v3_article_groups_l2_insert_input_loc=[]\n",
    "    synopse_articles_t_v1_rss1_articles_updates_loc=[]\n",
    "    synopse_articles_t_v3_article_groups_l2_updates_loc=[]\n",
    "    response_data1 = query_hasura_graphql(endpoint, admin_key, query2, variables2)\n",
    "    articles_ids = []\n",
    "    if len(response_data1['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "        for func_response in response_data1['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "            articles_ids.append(func_response['initial_group'])\n",
    "    n1 = []\n",
    "    for sublist in articles_ids:\n",
    "        for element in sublist:\n",
    "            n1.append(element)\n",
    "    articles_ids = list(set(n1))\n",
    "    articles_ids.sort(reverse=True)\n",
    "    print(articles_ids)\n",
    "    while True:\n",
    "        if len(articles_ids) > 1:\n",
    "            articles_news = []\n",
    "            for article_id in articles_ids:\n",
    "                variables3 = {\n",
    "                    \"articleid\": [article_id]\n",
    "                    }\n",
    "                response_data2 = query_hasura_graphql(endpoint, admin_key, query2, variables3)\n",
    "                if len(response_data1['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "                    for func_response in response_data1['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "                        articles_news.append(func_response['initial_group'])\n",
    "            n2 = []\n",
    "            for sublist in articles_news:\n",
    "                for element in sublist:\n",
    "                    n2.append(element)\n",
    "            articles_news = list(set(n2))\n",
    "            articles_news.sort(reverse=True)\n",
    "            if articles_ids == articles_news:\n",
    "                print(articles_news)\n",
    "                break\n",
    "            else:\n",
    "                articles_ids = articles_news\n",
    "    exists = 0\n",
    "    ids = []\n",
    "    articles_groups = []\n",
    "    for article_id in articles_ids:\n",
    "        variables4 = {\n",
    "        \"articleid\": [article_id]\n",
    "        }\n",
    "        response_data3 = query_hasura_graphql(endpoint, admin_key, query3, variables4)\n",
    "        if len(response_data3['data']['synopse_articles_t_v3_article_groups_l2']) > 0:\n",
    "            for func_response in response_data3['data']['synopse_articles_t_v3_article_groups_l2']:\n",
    "                if func_response['is_valid'] == 0:\n",
    "                    exists = exists + 1\n",
    "                    ids.append(func_response['id'])\n",
    "                    articles_groups.append(func_response['articles_group'])\n",
    "                \n",
    "                    \n",
    "    if exists == 0 : \n",
    "        synopse_articles_t_v3_article_groups_l2_insert_input_loc.append({\n",
    "            \"articles_group\": articles_ids,\n",
    "            'articles_in_group': len(articles_ids)\n",
    "            }\n",
    "            )\n",
    "        synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "            \"where\": {\"id\" : { \"_eq\": response['id'] }},\n",
    "            \"_set\": {\"is_grouped\": 2}\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article_id': 502, 'initial_group': [502, 458, 416, 105]}\n",
      "[416, 105, 458, 502]\n"
     ]
    }
   ],
   "source": [
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "  synopse_articles_t_v3_article_groups_l1(where: {t_v1_rss1_article: {is_grouped: {_eq: 1}}, article_count: {_gt: 1}}, order_by: {updated_at: asc}, limit: $limit, offset: $offset) {\n",
    "    article_id\n",
    "    initial_group\n",
    "  }\n",
    "}\n",
    "'''\n",
    "query2 = '''\n",
    "query MyQuery($articleid: [bigint!] = [1088]) {\n",
    "  synopse_articles_t_v3_article_groups_l1(where: {initial_group: {_contains: $articleid}}) {\n",
    "    initial_group\n",
    "  }\n",
    "}\n",
    "'''\n",
    "mutation_query = \"\"\"\n",
    "mutation MyMutation($objects: [synopse_articles_t_v3_article_groups_l2_insert_input!] = {}, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = {where: {}}, $updates1: [synopse_articles_t_v3_article_groups_l2_updates!] = {where: {}}) {\n",
    "    insert_synopse_articles_t_v3_article_groups_l2(objects: $objects, on_conflict: {constraint: t_v3_article_groups_l2_pkey}) {\n",
    "    affected_rows\n",
    "    }\n",
    "    update_synopse_articles_t_v1_rss1_articles_many(updates: $updates) {\n",
    "    affected_rows\n",
    "      }\n",
    "      update_synopse_articles_t_v3_article_groups_l2_many(updates: $updates1) {\n",
    "      affected_rows\n",
    "      }\n",
    "}\n",
    "\"\"\"\n",
    "while True: \n",
    "    variables = {\n",
    "    \"limit\": 1,\n",
    "    \"offset\": 0\n",
    "    }\n",
    "    synopse_articles_t_v3_article_groups_l2_insert_input_loc=[]\n",
    "    synopse_articles_t_v1_rss1_articles_updates_loc=[]\n",
    "    synopse_articles_t_v3_article_groups_l2_updates_loc=[]\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    if len(response_data['data']['synopse_articles_t_v3_article_groups_l1']) == 0:\n",
    "        break\n",
    "    for response in response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "        print(response)\n",
    "        variables2 = {\n",
    "            \"articleid\": [response['article_id']]\n",
    "            }\n",
    "        func_response_data = query_hasura_graphql(endpoint, admin_key, query2, variables2)\n",
    "        articles_ids = []\n",
    "        if len(func_response_data['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "            for func_response in func_response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "                articles_ids.append(func_response['initial_group'])\n",
    "        new_lst = []\n",
    "        for sublist in articles_ids:\n",
    "            for element in sublist:\n",
    "                new_lst.append(element)\n",
    "        articles_ids = list(set(new_lst))\n",
    "        \n",
    "        print(articles_ids)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[502, 458, 416, 105]\n",
      "[515, 275]\n",
      "[504, 441]\n",
      "[500, 284, 305]\n",
      "[504, 441]\n",
      "[502, 458]\n",
      "[449, 285, 108]\n",
      "[443, 285, 296, 109, 94]\n",
      "[442, 30]\n",
      "[448, 270]\n",
      "[413, 51]\n",
      "[502, 416]\n",
      "[403, 109]\n",
      "[282, 299]\n",
      "[287, 77, 61]\n",
      "[290, 64]\n",
      "[293, 362]\n",
      "[312, 125]\n",
      "[283, 285]\n",
      "[443, 285, 296, 94]\n",
      "[316, 319, 347]\n",
      "[500, 284, 305, 109]\n",
      "[285, 349]\n",
      "[280, 310]\n",
      "[515, 275]\n",
      "[316, 347]\n",
      "[320, 295]\n",
      "[443, 449, 283, 285, 349, 296, 75, 94]\n",
      "[319, 347, 119]\n",
      "[448, 270]\n",
      "[280, 310]\n",
      "[293, 362]\n",
      "[318, 84]\n",
      "[320, 295]\n",
      "[282, 299]\n",
      "[318, 84, 53]\n",
      "[116, 108]\n",
      "[319, 119]\n",
      "[443, 285, 296, 94]\n",
      "[500, 284, 305]\n",
      "[109, 111]\n",
      "[502, 105]\n",
      "[285, 75]\n",
      "[443, 403, 284, 109, 111]\n",
      "[287, 77]\n",
      "[449, 116, 108]\n",
      "[312, 125]\n",
      "[290, 64]\n",
      "[84, 53]\n",
      "[287, 61]\n",
      "[413, 51]\n",
      "[442, 30]\n"
     ]
    }
   ],
   "source": [
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "  synopse_articles_t_v3_article_groups_l1(where: {t_v1_rss1_article: {is_grouped: {_eq: 1}}, article_count: {_gt: 1}}, order_by: {updated_at: asc}, limit: $limit, offset: $offset) {\n",
    "    article_id\n",
    "    initial_group\n",
    "  }\n",
    "}\n",
    "'''\n",
    "variables = {\n",
    "\"limit\": 100,\n",
    "\"offset\": 0\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "arrays = []\n",
    "for response in response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "    print(response['initial_group'])\n",
    "    arrays.append(response['initial_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{502: [[502, 458], [502, 105], [502, 416], [502, 458, 416, 105]], 458: [[502, 458], [502, 458, 416, 105]], 416: [[502, 416], [502, 458, 416, 105]], 105: [[502, 105], [502, 458, 416, 105]], 515: [[515, 275]], 275: [[515, 275]], 504: [[504, 441]], 441: [[504, 441]], 500: [[500, 284, 305], [500, 284, 305, 109]], 284: [[500, 284, 305], [443, 403, 284, 109, 111], [500, 284, 305, 109]], 305: [[500, 284, 305], [500, 284, 305, 109]], 449: [[449, 116, 108], [443, 449, 283, 285, 349, 296, 75, 94], [449, 285, 108]], 285: [[285, 349], [285, 75], [443, 285, 296, 109, 94], [443, 449, 283, 285, 349, 296, 75, 94], [283, 285], [443, 285, 296, 94], [449, 285, 108]], 108: [[449, 116, 108], [116, 108], [449, 285, 108]], 443: [[443, 285, 296, 109, 94], [443, 449, 283, 285, 349, 296, 75, 94], [443, 403, 284, 109, 111], [443, 285, 296, 94]], 296: [[443, 285, 296, 109, 94], [443, 449, 283, 285, 349, 296, 75, 94], [443, 285, 296, 94]], 109: [[403, 109], [109, 111], [443, 285, 296, 109, 94], [443, 403, 284, 109, 111], [500, 284, 305, 109]], 94: [[443, 285, 296, 109, 94], [443, 449, 283, 285, 349, 296, 75, 94], [443, 285, 296, 94]], 442: [[442, 30]], 30: [[442, 30]], 448: [[448, 270]], 270: [[448, 270]], 413: [[413, 51]], 51: [[413, 51]], 403: [[403, 109], [443, 403, 284, 109, 111]], 282: [[282, 299]], 299: [[282, 299]], 287: [[287, 77], [287, 77, 61], [287, 61]], 77: [[287, 77], [287, 77, 61]], 61: [[287, 77, 61], [287, 61]], 290: [[290, 64]], 64: [[290, 64]], 293: [[293, 362]], 362: [[293, 362]], 312: [[312, 125]], 125: [[312, 125]], 283: [[443, 449, 283, 285, 349, 296, 75, 94], [283, 285]], 316: [[316, 319, 347], [316, 347]], 319: [[319, 347, 119], [319, 119], [316, 319, 347]], 347: [[319, 347, 119], [316, 319, 347], [316, 347]], 349: [[443, 449, 283, 285, 349, 296, 75, 94], [285, 349]], 280: [[280, 310]], 310: [[280, 310]], 320: [[320, 295]], 295: [[320, 295]], 75: [[285, 75], [443, 449, 283, 285, 349, 296, 75, 94]], 119: [[319, 119], [319, 347, 119]], 318: [[318, 84, 53], [318, 84]], 84: [[84, 53], [318, 84, 53], [318, 84]], 53: [[84, 53], [318, 84, 53]], 116: [[449, 116, 108], [116, 108]], 111: [[443, 403, 284, 109, 111], [109, 111]]}\n"
     ]
    }
   ],
   "source": [
    "groups = {}\n",
    "for array in arrays:\n",
    "    for num in array:\n",
    "        if num in groups:\n",
    "            if array not in groups[num]:\n",
    "                groups[num].append(array)\n",
    "        else:\n",
    "            groups[num] = [array]\n",
    "\n",
    "# Remove duplicates\n",
    "for key in groups:\n",
    "    groups[key] = [list(x) for x in set(tuple(x) for x in groups[key])]\n",
    "\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article_id': 449, 'initial_group': [449, 285, 108]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 443, 'initial_group': [443, 285, 296, 109, 94]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 458, 'initial_group': [502, 458]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 504, 'initial_group': [504, 441]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 442, 'initial_group': [442, 30]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 500, 'initial_group': [500, 284, 305]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 441, 'initial_group': [504, 441]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 515, 'initial_group': [515, 275]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 403, 'initial_group': [403, 109]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 416, 'initial_group': [502, 416]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 413, 'initial_group': [413, 51]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 448, 'initial_group': [448, 270]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 287, 'initial_group': [287, 77, 61]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 290, 'initial_group': [290, 64]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 282, 'initial_group': [282, 299]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 293, 'initial_group': [293, 362]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 312, 'initial_group': [312, 125]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 283, 'initial_group': [283, 285]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 347, 'initial_group': [316, 319, 347]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 296, 'initial_group': [443, 285, 296, 94]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 319, 'initial_group': [319, 347, 119]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 280, 'initial_group': [280, 310]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 275, 'initial_group': [515, 275]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 316, 'initial_group': [316, 347]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 285, 'initial_group': [443, 449, 283, 285, 349, 296, 75, 94]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 349, 'initial_group': [285, 349]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 284, 'initial_group': [500, 284, 305, 109]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 320, 'initial_group': [320, 295]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 362, 'initial_group': [293, 362]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 310, 'initial_group': [280, 310]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 270, 'initial_group': [448, 270]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 318, 'initial_group': [318, 84]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 299, 'initial_group': [282, 299]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 295, 'initial_group': [320, 295]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 119, 'initial_group': [319, 119]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 116, 'initial_group': [116, 108]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 94, 'initial_group': [443, 285, 296, 94]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 84, 'initial_group': [318, 84, 53]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 305, 'initial_group': [500, 284, 305]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 105, 'initial_group': [502, 105]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 111, 'initial_group': [109, 111]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'article_id': 109, 'initial_group': [443, 403, 284, 109, 111]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 75, 'initial_group': [285, 75]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 108, 'initial_group': [449, 116, 108]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 77, 'initial_group': [287, 77]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 125, 'initial_group': [312, 125]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 64, 'initial_group': [290, 64]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 53, 'initial_group': [84, 53]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 61, 'initial_group': [287, 61]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 51, 'initial_group': [413, 51]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n",
      "{'article_id': 30, 'initial_group': [442, 30]}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n"
     ]
    }
   ],
   "source": [
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "  synopse_articles_t_v3_article_groups_l1(where: {t_v1_rss1_article: {is_grouped: {_eq: 1}}, article_count: {_gt: 1}}, order_by: {updated_at: asc}, limit: $limit, offset: $offset) {\n",
    "    article_id\n",
    "    initial_group\n",
    "  }\n",
    "}\n",
    "'''\n",
    "query2 = '''\n",
    "query MyQuery($articleid: [bigint!] = []) {\n",
    "    synopse_articles_t_v3_article_groups_l2(where: {articles_group: {_contains: $articleid}, is_valid: {_eq: 0}}, order_by: {updated_at: desc}, limit: 1) {\n",
    "    id\n",
    "    articles_group\n",
    "    is_summerized\n",
    "    is_valid\n",
    "    }\n",
    "}\n",
    "'''\n",
    "mutation_query = \"\"\"\n",
    "mutation MyMutation($objects: [synopse_articles_t_v3_article_groups_l2_insert_input!] = {}, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = {where: {}}, $updates1: [synopse_articles_t_v3_article_groups_l2_updates!] = {where: {}}) {\n",
    "    insert_synopse_articles_t_v3_article_groups_l2(objects: $objects, on_conflict: {constraint: t_v3_article_groups_l2_pkey}) {\n",
    "    affected_rows\n",
    "    }\n",
    "    update_synopse_articles_t_v1_rss1_articles_many(updates: $updates) {\n",
    "    affected_rows\n",
    "    }\n",
    "    update_synopse_articles_t_v3_article_groups_l2_many(updates: $updates1) {\n",
    "    affected_rows\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "while True: \n",
    "    variables = {\n",
    "    \"limit\": 1,\n",
    "    \"offset\": 0\n",
    "    }\n",
    "    synopse_articles_t_v3_article_groups_l2_insert_input_loc=[]\n",
    "    synopse_articles_t_v1_rss1_articles_updates_loc=[]\n",
    "    synopse_articles_t_v3_article_groups_l2_updates_loc=[]\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    if len(response_data['data']['synopse_articles_t_v3_article_groups_l1']) == 0:\n",
    "        break\n",
    "    for response in response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "        print(response)\n",
    "        variables2 = {\n",
    "          \"articleid\": [response['article_id']]\n",
    "          }\n",
    "        response_data1 = query_hasura_graphql(endpoint, admin_key, query2, variables2)\n",
    "        if len(response_data1['data']['synopse_articles_t_v3_article_groups_l2']) == 0:\n",
    "            synopse_articles_t_v3_article_groups_l2_insert_input_loc.append({\n",
    "                \"articles_group\": response['initial_group'],\n",
    "                'articles_in_group': len(response['initial_group'])\n",
    "                }\n",
    "                )\n",
    "            synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "                \"where\": {\"id\" : { \"_eq\": response['article_id'] }},\n",
    "                \"_set\": {\"is_grouped\": 2}\n",
    "                })\n",
    "        if len(response_data1['data']['synopse_articles_t_v3_article_groups_l2']) == 1:\n",
    "            articles  = []\n",
    "            articles.append(response['initial_group'])\n",
    "            articles.append(response_data1['data']['synopse_articles_t_v3_article_groups_l2'][0]['articles_group'])\n",
    "            new_lst = []\n",
    "            for sublist in articles:\n",
    "                for element in sublist:\n",
    "                    new_lst.append(element)\n",
    "            articles = list(set(new_lst))\n",
    "            synopse_articles_t_v3_article_groups_l2_updates_loc.append({\n",
    "                \"where\": {\"id\" : { \"_eq\": response_data1['data']['synopse_articles_t_v3_article_groups_l2'][0]['id'] }},\n",
    "                \"_set\": {\"articles_group\": articles, 'articles_in_group': len(articles)}\n",
    "                })\n",
    "            synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "                \"where\": {\"id\" : { \"_eq\": response['article_id'] }},\n",
    "                \"_set\": {\"is_grouped\": 2}\n",
    "                })\n",
    "    mutation_variables = {\n",
    "        \"objects\": synopse_articles_t_v3_article_groups_l2_insert_input_loc,\n",
    "        \"updates\": synopse_articles_t_v1_rss1_articles_updates_loc,\n",
    "        \"updates1\": synopse_articles_t_v3_article_groups_l2_updates_loc,\n",
    "        }\n",
    "    out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'synopse_articles_t_v3_article_groups_l1': [{'article_id': 284, 'initial_group': [500, 284, 305, 109]}]}}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': {'affected_rows': 0}, 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l1': [{'article_id': 284, 'initial_group': [500, 284, 305, 109]}]}}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': {'affected_rows': 0}, 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'data': {'synopse_articles_t_v3_article_groups_l1': [{'article_id': 284, 'initial_group': [500, 284, 305, 109]}]}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\D\\30_git\\test123\\samples\\rss1 copy.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mfor\u001b[39;00m article \u001b[39min\u001b[39;00m initial_group:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     variables2 \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39marticleid\u001b[39m\u001b[39m\"\u001b[39m: [article]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m       }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     response_data1 \u001b[39m=\u001b[39m query_hasura_graphql(endpoint, admin_key, query2, variables2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(response_data1[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msynopse_articles_t_v3_article_groups_l2\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m         \u001b[39mfor\u001b[39;00m response1 \u001b[39min\u001b[39;00m response_data1[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msynopse_articles_t_v3_article_groups_l2\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "\u001b[1;32mc:\\D\\30_git\\test123\\samples\\rss1 copy.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m headers \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mx-hasura-admin-secret\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00madmin_key\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m data \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m'\u001b[39m: query,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mvariables\u001b[39m\u001b[39m'\u001b[39m: variables\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mpost(endpoint, json\u001b[39m=\u001b[39;49mdata, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\urllib3\\connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    792\u001b[0m     conn,\n\u001b[0;32m    793\u001b[0m     method,\n\u001b[0;32m    794\u001b[0m     url,\n\u001b[0;32m    795\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    796\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    797\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    798\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    799\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    800\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[0;32m    801\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[0;32m    802\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[0;32m    803\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[0;32m    804\u001b[0m )\n\u001b[0;32m    806\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[0;32m    807\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\urllib3\\connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 468\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    469\u001b[0m     \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    470\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\urllib3\\connectionpool.py:1097\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[1;32m-> 1097\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[0;32m   1100\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1101\u001b[0m         (\n\u001b[0;32m   1102\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mconn\u001b[39m.\u001b[39mhost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         InsecureRequestWarning,\n\u001b[0;32m   1108\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\urllib3\\connection.py:642\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[39mif\u001b[39;00m is_time_off:\n\u001b[0;32m    634\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    635\u001b[0m         (\n\u001b[0;32m    636\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSystem time is way off (before \u001b[39m\u001b[39m{\u001b[39;00mRECENT_DATE\u001b[39m}\u001b[39;00m\u001b[39m). This will probably \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    639\u001b[0m         SystemTimeWarning,\n\u001b[0;32m    640\u001b[0m     )\n\u001b[1;32m--> 642\u001b[0m sock_and_verified \u001b[39m=\u001b[39m _ssl_wrap_socket_and_match_hostname(\n\u001b[0;32m    643\u001b[0m     sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    644\u001b[0m     cert_reqs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_reqs,\n\u001b[0;32m    645\u001b[0m     ssl_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_version,\n\u001b[0;32m    646\u001b[0m     ssl_minimum_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_minimum_version,\n\u001b[0;32m    647\u001b[0m     ssl_maximum_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_maximum_version,\n\u001b[0;32m    648\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[0;32m    649\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[0;32m    650\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[0;32m    651\u001b[0m     cert_file\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_file,\n\u001b[0;32m    652\u001b[0m     key_file\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_file,\n\u001b[0;32m    653\u001b[0m     key_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_password,\n\u001b[0;32m    654\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    655\u001b[0m     ssl_context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_context,\n\u001b[0;32m    656\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[0;32m    657\u001b[0m     assert_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massert_hostname,\n\u001b[0;32m    658\u001b[0m     assert_fingerprint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massert_fingerprint,\n\u001b[0;32m    659\u001b[0m )\n\u001b[0;32m    660\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock_and_verified\u001b[39m.\u001b[39msocket\n\u001b[0;32m    661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_verified \u001b[39m=\u001b[39m sock_and_verified\u001b[39m.\u001b[39mis_verified\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\urllib3\\connection.py:783\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[39mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[0;32m    781\u001b[0m         server_hostname \u001b[39m=\u001b[39m normalized\n\u001b[1;32m--> 783\u001b[0m ssl_sock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    784\u001b[0m     sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    785\u001b[0m     keyfile\u001b[39m=\u001b[39;49mkey_file,\n\u001b[0;32m    786\u001b[0m     certfile\u001b[39m=\u001b[39;49mcert_file,\n\u001b[0;32m    787\u001b[0m     key_password\u001b[39m=\u001b[39;49mkey_password,\n\u001b[0;32m    788\u001b[0m     ca_certs\u001b[39m=\u001b[39;49mca_certs,\n\u001b[0;32m    789\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49mca_cert_dir,\n\u001b[0;32m    790\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49mca_cert_data,\n\u001b[0;32m    791\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    792\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mcontext,\n\u001b[0;32m    793\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[0;32m    794\u001b[0m )\n\u001b[0;32m    796\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m     \u001b[39mif\u001b[39;00m assert_fingerprint:\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\urllib3\\util\\ssl_.py:446\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[39mif\u001b[39;00m ca_certs \u001b[39mor\u001b[39;00m ca_cert_dir \u001b[39mor\u001b[39;00m ca_cert_data:\n\u001b[0;32m    445\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 446\u001b[0m         context\u001b[39m.\u001b[39;49mload_verify_locations(ca_certs, ca_cert_dir, ca_cert_data)\n\u001b[0;32m    447\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    448\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "  synopse_articles_t_v3_article_groups_l1(where: {t_v1_rss1_article: {is_grouped: {_eq: 1}}, article_count: {_gt: 1}}, order_by: {updated_at: asc}, limit: $limit, offset: $offset) {\n",
    "    article_id\n",
    "    initial_group\n",
    "  }\n",
    "}\n",
    "'''\n",
    "query2 = '''\n",
    "query MyQuery($articleid: [bigint!] = []) {\n",
    "    synopse_articles_t_v3_article_groups_l2(where: {articles_group: {_contains: $articleid}, is_valid: {_eq: 0}}, order_by: {updated_at: desc}) {\n",
    "    id\n",
    "    articles_group\n",
    "    is_summerized\n",
    "    is_valid\n",
    "    }\n",
    "}\n",
    "'''\n",
    "query3 = '''\n",
    "query MyQuery($articleid: [bigint!] = []) {\n",
    "    synopse_articles_t_v3_article_groups_l2(where: {articles_group: {_contains: $articleid}, is_valid: {_eq: 1}}, order_by: {updated_at: desc}, limit: 1) {\n",
    "    id\n",
    "    articles_group\n",
    "    is_summerized\n",
    "    is_valid\n",
    "    }\n",
    "}\n",
    "'''\n",
    "mutation_query = \"\"\"\n",
    "mutation MyMutation($objects: [synopse_articles_t_v3_article_groups_l2_insert_input!] = {}, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = {where: {}}, $updates1: [synopse_articles_t_v3_article_groups_l2_updates!] = {where: {}}) {\n",
    "    insert_synopse_articles_t_v3_article_groups_l2(objects: $objects, on_conflict: {constraint: t_v3_article_groups_l2_pkey}) {\n",
    "    affected_rows\n",
    "    }\n",
    "    update_synopse_articles_t_v1_rss1_articles_many(updates: $updates) {\n",
    "    affected_rows\n",
    "    }\n",
    "    update_synopse_articles_t_v3_article_groups_l2_many(updates: $updates1) {\n",
    "    affected_rows\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "while True: \n",
    "    variables = {\n",
    "    \"limit\": 1,\n",
    "    \"offset\": 0\n",
    "    }\n",
    "    synopse_articles_t_v3_article_groups_l2_insert_input_loc=[]\n",
    "    synopse_articles_t_v1_rss1_articles_updates_loc=[]\n",
    "    synopse_articles_t_v3_article_groups_l2_updates_loc=[]\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    print(response_data)\n",
    "    if len(response_data['data']['synopse_articles_t_v3_article_groups_l1']) == 0:\n",
    "        break\n",
    "    for response in response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "        initial_group = response['initial_group']\n",
    "        new_article_ids = []\n",
    "        ids = []\n",
    "        for article in initial_group:\n",
    "            variables2 = {\n",
    "              \"articleid\": [article]\n",
    "              }\n",
    "            response_data1 = query_hasura_graphql(endpoint, admin_key, query2, variables2)\n",
    "            if len(response_data1['data']['synopse_articles_t_v3_article_groups_l2']) > 0:\n",
    "                for response1 in response_data1['data']['synopse_articles_t_v3_article_groups_l2']:\n",
    "                    ids.append(response1['id'])\n",
    "                    new_article_ids.append(response1['articles_group'])\n",
    "        ids_exists = []\n",
    "        for article in initial_group:\n",
    "            variables2 = {\n",
    "              \"articleid\": [article]\n",
    "              }\n",
    "            response_data1 = query_hasura_graphql(endpoint, admin_key, query3, variables2)\n",
    "            if len(response_data1['data']['synopse_articles_t_v3_article_groups_l2']) > 0:\n",
    "                for response1 in response_data1['data']['synopse_articles_t_v3_article_groups_l2']:\n",
    "                    ids_exists.append(response1['id'])\n",
    "                    new_article_ids.append(response1['articles_group'])\n",
    "            \n",
    "        ids = list(set(ids))\n",
    "        if len(ids) == 0:\n",
    "            if len(ids_exists) == 0:\n",
    "                synopse_articles_t_v3_article_groups_l2_insert_input_loc.append({\n",
    "                    \"articles_group\": response['initial_group'],\n",
    "                    'articles_in_group': len(response['initial_group'])\n",
    "                    }\n",
    "                    )\n",
    "                synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "                    \"where\": {\"id\" : { \"_eq\": response['article_id'] }},\n",
    "                    \"_set\": {\"is_grouped\": 2}\n",
    "                    })\n",
    "            elif len(ids_exists) > 0:\n",
    "                new_lst = []\n",
    "                new_article_ids.append(initial_group)\n",
    "                for sublist in new_article_ids:\n",
    "                    for element in sublist:\n",
    "                        new_lst.append(element)\n",
    "                new_article_ids = list(set(new_lst))\n",
    "                synopse_articles_t_v3_article_groups_l2_insert_input_loc.append({\n",
    "                    \"articles_group\": new_article_ids,\n",
    "                    'articles_in_group': len(new_article_ids)\n",
    "                    }\n",
    "                    )\n",
    "                synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "                    \"where\": {\"id\" : { \"_eq\": response['article_id'] }},\n",
    "                    \"_set\": {\"is_grouped\": 2}\n",
    "                    })\n",
    "        if len(ids) == 1:\n",
    "            new_lst = []\n",
    "            new_article_ids.append(initial_group)\n",
    "            for sublist in new_article_ids:\n",
    "                for element in sublist:\n",
    "                    new_lst.append(element)\n",
    "            new_article_ids = list(set(new_lst))\n",
    "            synopse_articles_t_v3_article_groups_l2_updates_loc.append({\n",
    "                \"where\": {\"id\" : { \"_eq\": ids[0] }},\n",
    "                \"_set\": {\"articles_group\": new_article_ids, 'articles_in_group': len(new_article_ids)}\n",
    "                })\n",
    "            synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "                \"where\": {\"id\" : { \"_eq\": response['article_id'] }},\n",
    "                \"_set\": {\"is_grouped\": 2}\n",
    "                })\n",
    "\n",
    "    mutation_variables = {\n",
    "        \"objects\": synopse_articles_t_v3_article_groups_l2_insert_input_loc,\n",
    "        \"updates\": synopse_articles_t_v1_rss1_articles_updates_loc,\n",
    "        \"updates1\": synopse_articles_t_v3_article_groups_l2_updates_loc,\n",
    "        }\n",
    "    out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article_id': 502}\n",
      "[502, 458, 416, 105]\n",
      "[502, 458, 416, 105]\n",
      "{'article_id': 449}\n",
      "[449, 443, 349, 296, 285, 283, 116, 108, 94, 75]\n",
      "[449, 443, 349, 296, 285, 283, 116, 108, 94, 75]\n"
     ]
    }
   ],
   "source": [
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "  synopse_articles_t_v3_article_groups_l1(where: {t_v1_rss1_article: {is_grouped: {_eq: 1}}, article_count: {_gt: 1}}, order_by: {updated_at: asc}, limit: $limit, offset: $offset) {\n",
    "    article_id\n",
    "    initial_group\n",
    "  }\n",
    "}\n",
    "'''\n",
    "query2 = '''\n",
    "query MyQuery($articleid: [bigint!] = []) {\n",
    "    synopse_articles_t_v3_article_groups_l1(where: {initial_group: {_contains: $articleid}}) {\n",
    "    article_id\n",
    "    initial_group\n",
    "    }\n",
    "}\n",
    "'''\n",
    "query3 = '''\n",
    "query MyQuery($articleid: [bigint!] = []) {\n",
    "    synopse_articles_t_v3_article_groups_l2(where: {articles_group: {_contains: $articleid}, is_valid: {_eq: 0}}, order_by: {is_valid: desc, updated_at: desc}, limit: 1) {\n",
    "    id\n",
    "    articles_group\n",
    "    is_summerized\n",
    "    is_valid\n",
    "    }\n",
    "}\n",
    "'''\n",
    "mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [synopse_articles_t_v3_article_groups_l2_insert_input!] = {}, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = {where: {}}, $updates1: [synopse_articles_t_v3_article_groups_l2_updates!] = {where: {}}) {\n",
    "        insert_synopse_articles_t_v3_article_groups_l2(objects: $objects, on_conflict: {constraint: t_v3_article_groups_l2_pkey}) {\n",
    "        affected_rows\n",
    "        }\n",
    "        update_synopse_articles_t_v1_rss1_articles_many(updates: $updates) {\n",
    "        affected_rows\n",
    "        }\n",
    "        update_synopse_articles_t_v3_article_groups_l2_many(updates: $updates1) {\n",
    "        affected_rows\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "variables = {\n",
    "\"limit\": 2,\n",
    "\"offset\": 0\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "for response in response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "    print(response)\n",
    "    variables2 = {\n",
    "        \"articleid\": [response['article_id']]\n",
    "        }\n",
    "    synopse_articles_t_v3_article_groups_l2_insert_input_loc=[]\n",
    "    synopse_articles_t_v1_rss1_articles_updates_loc=[]\n",
    "    synopse_articles_t_v3_article_groups_l2_updates_loc=[]\n",
    "    response_data1 = query_hasura_graphql(endpoint, admin_key, query2, variables2)\n",
    "    articles_ids = []\n",
    "    if len(response_data1['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "        for func_response in response_data1['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "            articles_ids.append(func_response['initial_group'])\n",
    "    n1 = []\n",
    "    for sublist in articles_ids:\n",
    "        for element in sublist:\n",
    "            n1.append(element)\n",
    "    articles_ids = list(set(n1))\n",
    "    articles_ids.sort(reverse=True)\n",
    "    print(articles_ids)\n",
    "    while True:\n",
    "        if len(articles_ids) > 1:\n",
    "            articles_news = []\n",
    "            for article_id in articles_ids:\n",
    "                variables3 = {\n",
    "                    \"articleid\": [article_id]\n",
    "                    }\n",
    "                response_data2 = query_hasura_graphql(endpoint, admin_key, query2, variables3)\n",
    "                if len(response_data1['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "                    for func_response in response_data1['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "                        articles_news.append(func_response['initial_group'])\n",
    "            n2 = []\n",
    "            for sublist in articles_news:\n",
    "                for element in sublist:\n",
    "                    n2.append(element)\n",
    "            articles_news = list(set(n2))\n",
    "            articles_news.sort(reverse=True)\n",
    "            if articles_ids == articles_news:\n",
    "                print(articles_news)\n",
    "                break\n",
    "            else:\n",
    "                articles_ids = articles_news\n",
    "    exists = 0\n",
    "    ids = []\n",
    "    articles_groups = []\n",
    "    for article_id in articles_ids:\n",
    "        variables4 = {\n",
    "        \"articleid\": [article_id]\n",
    "        }\n",
    "        response_data3 = query_hasura_graphql(endpoint, admin_key, query3, variables4)\n",
    "        if len(response_data3['data']['synopse_articles_t_v3_article_groups_l2']) > 0:\n",
    "            for func_response in response_data3['data']['synopse_articles_t_v3_article_groups_l2']:\n",
    "                if func_response['is_valid'] == 0:\n",
    "                    exists = exists + 1\n",
    "                    ids.append(func_response['id'])\n",
    "                    articles_groups.append(func_response['articles_group'])\n",
    "                \n",
    "                    \n",
    "    if exists == 0 : \n",
    "        synopse_articles_t_v3_article_groups_l2_insert_input_loc.append({\n",
    "            \"articles_group\": articles_ids,\n",
    "            'articles_in_group': len(articles_ids)\n",
    "            }\n",
    "            )\n",
    "        synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "            \"where\": {\"id\" : { \"_eq\": response['id'] }},\n",
    "            \"_set\": {\"is_grouped\": 2}\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[502, 416]\n",
      "[502, 458, 416, 105]\n",
      "[502, 458, 416, 105]\n",
      "[502, 458, 416, 105]\n",
      "##############\n",
      "[403, 109]\n",
      "[443, 403, 284, 111, 109]\n",
      "[443, 403, 284, 111, 109]\n",
      "[443, 403, 284, 111, 109]\n",
      "##############\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "  synopse_articles_t_v3_article_groups_l1(where: {t_v1_rss1_article: {is_grouped: {_eq: 1}}, article_count: {_gt: 1}}, order_by: {updated_at: asc}, limit: $limit, offset: $offset) {\n",
    "    article_id\n",
    "    initial_group\n",
    "  }\n",
    "}\n",
    "'''\n",
    "query2 = '''\n",
    "query MyQuery($articleid: [bigint!] = []) {\n",
    "    synopse_articles_t_v3_article_groups_l1(where: {initial_group: {_contains: $articleid}}) {\n",
    "    article_id\n",
    "    initial_group\n",
    "    }\n",
    "}\n",
    "'''\n",
    "query3 = '''\n",
    "query MyQuery($articleid: [bigint!] = [1088]) {\n",
    "    synopse_articles_t_v3_article_groups_l2(where: {articles_group: {_contains: $articleid}, is_valid: {_eq: 0}}, order_by: {is_valid: desc, updated_at: desc}, limit: 1) {\n",
    "    id\n",
    "    articles_group\n",
    "    is_summerized\n",
    "    is_valid\n",
    "    }\n",
    "}\n",
    "'''\n",
    "offset = 10\n",
    "while True:\n",
    "    variables = {\n",
    "    \"limit\": 2,\n",
    "    \"offset\": offset\n",
    "    }\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    if len(response_data['data']['synopse_articles_t_v3_article_groups_l1']) == 0:\n",
    "        break\n",
    "    #print(json.dumps(response_data, indent=4))\n",
    "    for response in response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "        variables2 = {\n",
    "            \"articleid\": [response['article_id']]\n",
    "            }\n",
    "        response_data1 = query_hasura_graphql(endpoint, admin_key, query2, variables2)\n",
    "        articles_ids = []\n",
    "        if len(response_data1['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "            for func_response in response_data1['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "                articles_ids.append(func_response['initial_group'])\n",
    "        n1 = []\n",
    "        for sublist in articles_ids:\n",
    "            for element in sublist:\n",
    "                n1.append(element)\n",
    "        articles_ids = list(set(n1))\n",
    "        articles_ids.sort(reverse=True)\n",
    "        while True:\n",
    "            if len(articles_ids) > 1:\n",
    "                articles_news = []\n",
    "                for article_id in articles_ids:\n",
    "                    variables3 = {\n",
    "                        \"articleid\": [article_id]\n",
    "                        }\n",
    "                    response_data2 = query_hasura_graphql(endpoint, admin_key, query2, variables3)\n",
    "                    if len(response_data1['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "                        for func_response in response_data1['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "                            articles_news.append(func_response['initial_group'])\n",
    "                n2 = []\n",
    "                for sublist in articles_news:\n",
    "                    for element in sublist:\n",
    "                        n2.append(element)\n",
    "                articles_news = list(set(n2))\n",
    "                articles_news.sort(reverse=True)\n",
    "                if articles_ids == articles_news:\n",
    "                    break\n",
    "                else:\n",
    "                    articles_ids = articles_news\n",
    "        \n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[413, 51]\n",
      "[51, 413]\n",
      "[[413, 51], [413, 51], [413, 51], [413, 51]]\n",
      "[51, 413]\n",
      "###########\n",
      "[502, 416]\n",
      "[105, 416, 458, 502]\n",
      "[[502, 458, 416, 105], [502, 416], [502, 458, 416, 105], [502, 416], [502, 458, 416, 105], [502, 416], [502, 458, 416, 105], [502, 416]]\n",
      "[105, 416, 458, 502]\n",
      "###########\n",
      "[403, 109]\n",
      "[109, 111, 284, 403, 443]\n",
      "[[403, 109], [443, 403, 284, 109, 111], [403, 109], [443, 403, 284, 109, 111], [403, 109], [443, 403, 284, 109, 111], [403, 109], [443, 403, 284, 109, 111], [403, 109], [443, 403, 284, 109, 111]]\n",
      "[109, 111, 284, 403, 443]\n",
      "###########\n",
      "[287, 77, 61]\n",
      "[61, 77, 287]\n",
      "[[287, 77, 61], [287, 77], [287, 61], [287, 77, 61], [287, 77], [287, 61], [287, 77, 61], [287, 77], [287, 61]]\n",
      "[61, 77, 287]\n",
      "###########\n",
      "[282, 299]\n",
      "[282, 299]\n",
      "[[282, 299], [282, 299], [282, 299], [282, 299]]\n",
      "[282, 299]\n",
      "###########\n"
     ]
    }
   ],
   "source": [
    "for response in response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "    print(response['initial_group'])\n",
    "    variables2 = {\n",
    "        \"articleid\": [response['article_id']]\n",
    "        }\n",
    "    response_data1 = query_hasura_graphql(endpoint, admin_key, query2, variables2)\n",
    "    articles_ids = []\n",
    "    if len(response_data1['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "        for func_response in response_data1['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "            articles_ids.append(func_response['initial_group'])\n",
    "    n1 = []\n",
    "    for sublist in articles_ids:\n",
    "        for element in sublist:\n",
    "            n1.append(element)\n",
    "    articles_ids = list(set(n1))\n",
    "    articles_ids.sort()  # Sort the list in-place\n",
    "    print(articles_ids)\n",
    "    while True:\n",
    "        if len(articles_ids) > 1:\n",
    "            articles_news = []\n",
    "            for article_id in articles_ids:\n",
    "                variables3 = {\n",
    "                    \"articleid\": [article_id]\n",
    "                    }\n",
    "                response_data2 = query_hasura_graphql(endpoint, admin_key, query2, variables3)\n",
    "                if len(response_data1['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "                    for func_response in response_data1['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "                        articles_news.append(func_response['initial_group'])\n",
    "            n2 = []\n",
    "            print(articles_news)\n",
    "            for sublist in articles_news:\n",
    "                for element in sublist:\n",
    "                    n2.append(element)\n",
    "            articles_news = list(set(n2))\n",
    "            articles_news.sort()  # Sort the list in-place\n",
    "            print(articles_news)\n",
    "            break\n",
    "    print(\"###########\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[443, 285, 296, 109, 94], [443, 449, 283, 285, 349, 296, 75, 94], [443, 285, 296, 94], [443, 285, 296, 94], [443, 403, 284, 109, 111]]\n",
      "[[403, 109], [443, 403, 284, 109, 111]]\n",
      "[[443, 285, 296, 109, 94], [443, 449, 283, 285, 349, 296, 75, 94], [443, 285, 296, 94], [443, 285, 296, 94]]\n",
      "[[443, 285, 296, 109, 94], [449, 285, 108], [283, 285], [285, 349], [443, 449, 283, 285, 349, 296, 75, 94], [443, 285, 296, 94], [285, 75], [443, 285, 296, 94]]\n",
      "[[500, 284, 305], [500, 284, 305, 109], [500, 284, 305], [443, 403, 284, 109, 111]]\n",
      "[[443, 285, 296, 109, 94], [443, 449, 283, 285, 349, 296, 75, 94], [443, 285, 296, 94], [443, 285, 296, 94]]\n",
      "[[443, 285, 296, 109, 94], [403, 109], [500, 284, 305, 109], [109, 111], [443, 403, 284, 109, 111]]\n",
      "[[109, 111], [443, 403, 284, 109, 111]]\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}]}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "  synopse_articles_t_v1_rss1_articles(limit: $limit, offset: $offset, order_by: {created_at: desc}, where: { id: {_in: [443, 403, 284, 109, 111,  285, 296, 94 ]}}) {\n",
    "    id\n",
    "    t_v3_article_groups_l1 {\n",
    "      initial_group\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "query2 = '''\n",
    "query MyQuery($articleid: [bigint!] = [1088]) {\n",
    "    synopse_articles_t_v3_article_groups_l1(where: {initial_group: {_contains: $articleid}}) {\n",
    "    initial_group\n",
    "    }\n",
    "}\n",
    "'''\n",
    "query3 = '''\n",
    "query MyQuery($articleid: [bigint!] = [1088]) {\n",
    "  synopse_articles_t_v3_article_groups_l2(where: {articles_group: {_contains: $articleid}, is_valid: {_eq: 0}}, order_by: {is_valid: desc, updated_at: desc}, limit: 1) {\n",
    "    id\n",
    "    articles_group\n",
    "    is_summerized\n",
    "    is_valid\n",
    "  }\n",
    "}\n",
    "'''\n",
    "offset = 0\n",
    "variables = {\n",
    "\"limit\": 20,\n",
    "\"offset\": offset\n",
    "}\n",
    "mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [synopse_articles_t_v3_article_groups_l2_insert_input!] = {}, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = {where: {}}, $updates1: [synopse_articles_t_v3_article_groups_l2_updates!] = {where: {}}) {\n",
    "        insert_synopse_articles_t_v3_article_groups_l2(objects: $objects, on_conflict: {constraint: t_v3_article_groups_l2_pkey}) {\n",
    "        affected_rows\n",
    "        }\n",
    "        update_synopse_articles_t_v1_rss1_articles_many(updates: $updates) {\n",
    "        affected_rows\n",
    "        }\n",
    "        update_synopse_articles_t_v3_article_groups_l2_many(updates: $updates1) {\n",
    "        affected_rows\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "#print(json.dumps(response_data, indent=4))\n",
    "for response in response_data['data']['synopse_articles_t_v1_rss1_articles']:\n",
    "    variables2 = {\n",
    "        \"articleid\": [response['id']]\n",
    "        }\n",
    "    synopse_articles_t_v3_article_groups_l2_insert_input_loc=[]\n",
    "    synopse_articles_t_v1_rss1_articles_updates_loc=[]\n",
    "    synopse_articles_t_v3_article_groups_l2_updates_loc=[]\n",
    "    func_response_data = query_hasura_graphql(endpoint, admin_key, query2, variables2)\n",
    "    #print(json.dumps(func_response_data, indent=4))\n",
    "    articles_ids = []\n",
    "    if len(func_response_data['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "        for func_response in func_response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "            articles_ids.append(func_response['initial_group'])\n",
    "    print(articles_ids)\n",
    "    for article in articles_ids:\n",
    "        variables3 = {\n",
    "            \"articleid\": [article]\n",
    "            }\n",
    "        func_response_data1 = query_hasura_graphql(endpoint, admin_key, query3, variables3)n\n",
    "    if len(func_response_data1['data']['synopse_articles_t_v3_article_groups_l2']) == 0:\n",
    "        print(\"No Data\")\n",
    "        new_lst = []\n",
    "        for sublist in articles_ids:\n",
    "            for element in sublist:\n",
    "                new_lst.append(element)\n",
    "        my_list = list(set(new_lst))\n",
    "        synopse_articles_t_v3_article_groups_l2_insert_input_loc.append({\n",
    "            \"articles_group\": my_list,\n",
    "            'articles_in_group': len(my_list)\n",
    "            }\n",
    "            )\n",
    "        synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "            \"where\": {\"id\" : { \"_eq\": response['id'] }},\n",
    "            \"_set\": {\"is_grouped\": 2}\n",
    "            })\n",
    "    elif len(func_response_data1['data']['synopse_articles_t_v3_article_groups_l2']) == 1:\n",
    "        articles_ids.append(func_response_data1['data']['synopse_articles_t_v3_article_groups_l2'][0]['articles_group'])\n",
    "        new_lst = []\n",
    "        for sublist in articles_ids:\n",
    "            for element in sublist:\n",
    "                new_lst.append(element)\n",
    "        my_list = list(set(new_lst))\n",
    "        synopse_articles_t_v3_article_groups_l2_updates_loc.append({\n",
    "            \"where\": {\"id\" : { \"_eq\": func_response_data1['data']['synopse_articles_t_v3_article_groups_l2'][0]['id'] }},\n",
    "            \"_set\": {\"articles_group\": my_list, 'articles_in_group': len(my_list)}\n",
    "            })\n",
    "        synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "            \"where\": {\"id\" : { \"_eq\": response['id'] }},\n",
    "            \"_set\": {\"is_grouped\": 2}\n",
    "            })\n",
    "        \n",
    "\n",
    "mutation_variables = {\n",
    "\"objects\": synopse_articles_t_v3_article_groups_l2_insert_input_loc,\n",
    "\"updates\": synopse_articles_t_v1_rss1_articles_updates_loc,\n",
    "\"updates1\": synopse_articles_t_v3_article_groups_l2_updates_loc,\n",
    "}\n",
    "out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 20}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': {'affected_rows': 0}}}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 6}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}]}}\n",
      "{'data': {'insert_synopse_articles_t_v3_article_groups_l2': {'affected_rows': 0}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}], 'update_synopse_articles_t_v3_article_groups_l2_many': [{'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}, {'affected_rows': 1}]}}\n"
     ]
    }
   ],
   "source": [
    "def grouping_l2(offset1):\n",
    "    graphql_query = '''\n",
    "      query MyQuery($limit: Int!, $offset: Int!) {\n",
    "        synopse_articles_t_v3_article_groups_l1(where: {t_v1_rss1_article: {is_grouped: {_eq: 1}}, article_count: {_gt: 1}}, order_by: {updated_at: asc}, limit: $limit, offset: $offset) {\n",
    "          article_id\n",
    "        }\n",
    "      }\n",
    "      '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "        mutation MyMutation($objects: [synopse_articles_t_v3_article_groups_l2_insert_input!] = {}, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = {where: {}}, $updates1: [synopse_articles_t_v3_article_groups_l2_updates!] = {where: {}}) {\n",
    "          insert_synopse_articles_t_v3_article_groups_l2(objects: $objects, on_conflict: {constraint: t_v3_article_groups_l2_pkey}) {\n",
    "            affected_rows\n",
    "          }\n",
    "          update_synopse_articles_t_v1_rss1_articles_many(updates: $updates) {\n",
    "            affected_rows\n",
    "          }\n",
    "          update_synopse_articles_t_v3_article_groups_l2_many(updates: $updates1) {\n",
    "            affected_rows\n",
    "          }\n",
    "        }\n",
    "    \"\"\"\n",
    "    query2 = '''\n",
    "    query MyQuery($articleid: [bigint!] = [1088]) {\n",
    "        synopse_articles_t_v3_article_groups_l1(where: {initial_group: {_contains: $articleid}}) {\n",
    "        initial_group\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    query3 = '''\n",
    "    query MyQuery($articleid: [bigint!] = [1088]) {\n",
    "      synopse_articles_t_v3_article_groups_l2(where: {articles_group: {_contains: $articleid}, is_valid: {_eq: 0}}, order_by: {is_valid: desc, updated_at: desc}, limit: 1) {\n",
    "        id\n",
    "        articles_group\n",
    "        is_summerized\n",
    "        is_valid\n",
    "      }\n",
    "    }\n",
    "    '''\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 20,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        synopse_articles_t_v3_article_groups_l2_insert_input_loc=[]\n",
    "        synopse_articles_t_v1_rss1_articles_updates_loc=[]\n",
    "        synopse_articles_t_v3_article_groups_l2_updates_loc=[]\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        if len(response_data['data']['synopse_articles_t_v3_article_groups_l1']) == 0:\n",
    "            break\n",
    "        #print(json.dumps(response_data, indent=4))\n",
    "        for response in response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "            variables3 = {\n",
    "                \"articleid\": [response['article_id']]\n",
    "                }\n",
    "            func_response_data = query_hasura_graphql(endpoint, admin_key, query2, variables3)\n",
    "            #print(json.dumps(func_response_data, indent=4))\n",
    "            articles_ids = []\n",
    "            if len(func_response_data['data']['synopse_articles_t_v3_article_groups_l1']) > 0:\n",
    "                for func_response in func_response_data['data']['synopse_articles_t_v3_article_groups_l1']:\n",
    "                    articles_ids.append(func_response['initial_group'])\n",
    "            func_response_data1 = query_hasura_graphql(endpoint, admin_key, query3, variables3)\n",
    "            if len(func_response_data1['data']['synopse_articles_t_v3_article_groups_l2']) == 0:\n",
    "                new_lst = []\n",
    "                for sublist in articles_ids:\n",
    "                    for element in sublist:\n",
    "                        new_lst.append(element)\n",
    "                my_list = list(set(new_lst))\n",
    "                synopse_articles_t_v3_article_groups_l2_insert_input_loc.append({\n",
    "                    \"articles_group\": my_list,\n",
    "                    'articles_in_group': len(my_list)\n",
    "                    }\n",
    "                    )\n",
    "                synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "                    \"where\": {\"id\" : { \"_eq\": response['article_id'] }},\n",
    "                    \"_set\": {\"is_grouped\": 2}\n",
    "                    })\n",
    "            elif len(func_response_data1['data']['synopse_articles_t_v3_article_groups_l2']) == 1:\n",
    "                articles_ids.append(func_response_data1['data']['synopse_articles_t_v3_article_groups_l2'][0]['articles_group'])\n",
    "                new_lst = []\n",
    "                for sublist in articles_ids:\n",
    "                    for element in sublist:\n",
    "                        new_lst.append(element)\n",
    "                my_list = list(set(new_lst))\n",
    "                synopse_articles_t_v3_article_groups_l2_updates_loc.append({\n",
    "                    \"where\": {\"id\" : { \"_eq\": func_response_data1['data']['synopse_articles_t_v3_article_groups_l2'][0]['id'] }},\n",
    "                    \"_set\": {\"articles_group\": my_list, 'articles_in_group': len(my_list)}\n",
    "                    })\n",
    "                synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "                    \"where\": {\"id\" : { \"_eq\": response['article_id'] }},\n",
    "                    \"_set\": {\"is_grouped\": 2}\n",
    "                    })\n",
    "\n",
    "\n",
    "        mutation_variables = {\n",
    "        \"objects\": synopse_articles_t_v3_article_groups_l2_insert_input_loc,\n",
    "        \"updates\": synopse_articles_t_v1_rss1_articles_updates_loc,\n",
    "        \"updates1\": synopse_articles_t_v3_article_groups_l2_updates_loc,\n",
    "        }\n",
    "        out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "grouping_l2(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mutation_hasura_graphql' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\D\\30_git\\test123\\samples\\rss1 copy.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     synopse_articles_t_v4_tags_hierarchy_insert_input_loc\u001b[39m.\u001b[39mappend({\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtag\u001b[39m\u001b[39m\"\u001b[39m: n[\u001b[39m0\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtag_description\u001b[39m\u001b[39m\"\u001b[39m: n[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     })\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m mutation_variables \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mobjects\u001b[39m\u001b[39m\"\u001b[39m: synopse_articles_t_v4_tags_hierarchy_insert_input_loc,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/rss1%20copy.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m out1 \u001b[39m=\u001b[39m mutation_hasura_graphql(endpoint\u001b[39m=\u001b[39mendpoint, admin_key\u001b[39m=\u001b[39madmin_key, mutation_query\u001b[39m=\u001b[39mmutation_query, mutation_variables\u001b[39m=\u001b[39mmutation_variables)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mutation_hasura_graphql' is not defined"
     ]
    }
   ],
   "source": [
    "mutation_query = \"\"\"\n",
    "mutation MyMutation($objects: [synopse_articles_t_v4_tags_hierarchy_insert_input!] = {}) {\n",
    "  insert_synopse_articles_t_v4_tags_hierarchy(objects: $objects, on_conflict: {constraint: t_v4_tags_hierarchy_pkey}) {\n",
    "    affected_rows\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "synopse_articles_t_v4_tags_hierarchy_insert_input_loc=[]\n",
    "news_subcategories =  [\n",
    "    ['Politics', 'Coverage of political events, government policies, elections, and international relations'],\n",
    "    ['Business', 'Reports on financial markets, companies, mergers and acquisitions, and economic trends'],\n",
    "    ['Science and Technology', 'News related to scientific discoveries, innovations, and technological advancements'],\n",
    "    ['Health and Medicine', 'Updates on medical research, healthcare policies, and public health issues'],\n",
    "    ['Entertainment', 'Information on movies, music, celebrities, and the entertainment industry'],\n",
    "    ['Sports', 'Coverage of sporting events, scores, athletes, and sports-related news'],\n",
    "    ['Environment', 'Reports on climate change, conservation efforts, and environmental issues'],\n",
    "    ['Human Interest', 'Stories about people, personal experiences, and inspirational narratives'],\n",
    "]\n",
    "\n",
    "for n in news_subcategories:\n",
    "    synopse_articles_t_v4_tags_hierarchy_insert_input_loc.append({\n",
    "        \"tag\": n[0],\n",
    "        \"tag_description\": n[1]\n",
    "    })\n",
    "mutation_variables = {\n",
    "\"objects\": synopse_articles_t_v4_tags_hierarchy_insert_input_loc,\n",
    "}\n",
    "out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from keybert import KeyBERT\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "{'data': {'update_synopse_articles_t_v2_articles_summary_many': [{'affected_rows': 1}, {'affected_rows': 1}], 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}, {'affected_rows': 1}]}}\n"
     ]
    }
   ],
   "source": [
    "graphql_tags_query = '''\n",
    "query MyQuery {\n",
    "  synopse_articles_t_v4_tags_hierarchy(where: {is_valid: {_eq: 1}}) {\n",
    "    id\n",
    "    tag\n",
    "    tag_hierachy\n",
    "  }\n",
    "}\n",
    "'''\n",
    "tags_main = []\n",
    "tags_ids = []\n",
    "variables_tags = {\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_tags_query, variables_tags)\n",
    "tags_main = []\n",
    "for response in response_data['data']['synopse_articles_t_v4_tags_hierarchy']:\n",
    "  if response['tag_hierachy'] == 0:\n",
    "    tags_main.append(response['tag'])\n",
    "    tags_ids.append(response['id'])\n",
    "print(tags_main)\n",
    "print(tags_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1  # Use GPU if available, else CPU\n",
    "print(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=device)\n",
    "example = \"My name is Wolfgang and I live in Berlin\"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Politics', 'Business', 'Technology', 'Science', 'Health', 'Sports', 'Entertainment', 'World', 'Lifestyle', 'Environment', 'Finance']\n",
      "[274, 275, 276, 277, 278, 279, 280, 283, 284, 281, 290]\n",
      "1\n",
      "275\n",
      "['Business', 'Crypto', 'Real Estate', 'Stocks', 'Investing']\n"
     ]
    }
   ],
   "source": [
    "graphql_tags_query = '''\n",
    "query MyQuery {\n",
    "  synopse_articles_t_v4_tags_hierarchy(where: {is_valid: {_eq: 1}}) {\n",
    "    id\n",
    "    tag\n",
    "    tag_hierachy\n",
    "  }\n",
    "}\n",
    "'''\n",
    "tags_main = []\n",
    "tags_ids = []\n",
    "variables_tags = {\n",
    "}\n",
    "response_data_tags = query_hasura_graphql(endpoint, admin_key, graphql_tags_query, variables_tags)\n",
    "tags_main = []\n",
    "for response in response_data_tags['data']['synopse_articles_t_v4_tags_hierarchy']:\n",
    "  if response['tag_hierachy'] == 0:\n",
    "    tags_main.append(response['tag'])\n",
    "    tags_ids.append(response['id'])\n",
    "print(tags_main)\n",
    "print(tags_ids)\n",
    "index = tags_main.index(\"Business\")\n",
    "print(index)\n",
    "print(tags_ids[index])\n",
    "tags_sub = []\n",
    "for response in response_data_tags['data']['synopse_articles_t_v4_tags_hierarchy']:\n",
    "  if response['tag_hierachy'] == tags_ids[index]:\n",
    "    tags_sub.append(response['tag'])\n",
    "print(tags_sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rss1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
