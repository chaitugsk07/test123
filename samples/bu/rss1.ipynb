{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests\n",
    "import feedparser\n",
    "from datetime import datetime, timezone\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "import pyperclip\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from io import BytesIO\n",
    "from skimage.feature import match_template\n",
    "from skimage.color import rgb2gray\n",
    "from transformers import pipeline\n",
    "import os\n",
    "import torch\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "import numpy\n",
    "# Enable device-side assertions\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cuda.use_deterministic_algorithms = True\n",
    "torch.backends.cuda.cufft_plan_cache.clear()\n",
    "torch.backends.cudnn.cache_enabled = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cuda.deterministic = True\n",
    "torch.backends.cuda.flags = {\n",
    "    'assert': str(int(True)),\n",
    "    'allow_tf32': str(int(False)),\n",
    "    'cudnn_deterministic': str(int(True)),\n",
    "    'cudnn_benchmark': str(int(False)),\n",
    "    'use_deterministic_algorithms': str(int(True)),\n",
    "    'cufft_plan_cache_clear': str(int(True)),\n",
    "    'cudnn_cache_enabled': str(int(False)),\n",
    "    'cudnn_allow_tf32': str(int(False)),\n",
    "    'cudnn_enabled': str(int(True)),\n",
    "    'cudnn_deterministic': str(int(True)),\n",
    "}\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "endpoint = \"http://hasura.192.168.0.100.nip.io/v1/graphql\"\n",
    "admin_key = \"arrive@AD123\"\n",
    "\n",
    "def query_hasura_graphql(endpoint, admin_key, query, variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'query': query,\n",
    "        'variables': variables\n",
    "    }\n",
    "    response = requests.post(endpoint, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def is_valid_timezone_format(published):\n",
    "    try:\n",
    "        # Attempt to parse the string\n",
    "        date_format = \"%a, %d %b %Y %H:%M:%S %z\"\n",
    "        date_object = datetime.strptime(published, date_format)\n",
    "        \n",
    "        hasura_timestamp = date_object.astimezone(timezone.utc).isoformat()\n",
    "        return True, hasura_timestamp\n",
    "    except ValueError:\n",
    "        # If parsing fails, the string is not in the correct format\n",
    "        return False, None\n",
    "\n",
    "def check_date_format(date_string):\n",
    "    try:\n",
    "        datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "        \n",
    "def mutation_hasura_graphql(endpoint, admin_key, mutation_query, mutation_variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "    response = requests.post(endpoint, json={'query': mutation_query, 'variables': mutation_variables}, headers=headers)\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "        return True, data\n",
    "    else:\n",
    "        print(f\"Mutation failed with status code {response.status_code}: {response.text}\")\n",
    "        return False, None\n",
    "\n",
    "def update_articles_toi():\n",
    "    graphql_query = '''\n",
    "    query MyQuery($outlet: String!, $link_type: Int!) {\n",
    "    rss1_links(where: {rss1_link_type: {_eq: $link_type}, outlet: {_eq: $outlet}}) {\n",
    "        rss1_link\n",
    "    }\n",
    "    }\n",
    "    '''\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"link_type\": 11,\n",
    "        \"outlet\": \"timesofindia\"\n",
    "    }\n",
    "    rss1_links_array = []\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    if response_data:\n",
    "        rss1_links_array = [item[\"rss1_link\"] for item in response_data[\"data\"][\"rss1_links\"]]\n",
    "    #print(rss1_links_array)\n",
    "    graphql_query = \"\"\"\n",
    "    query MyQuery($outlet: String!) {\n",
    "        rss1_outlets(where: {outlet: {_eq: $outlet}}) {\n",
    "            logo_url\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"outlet\": \"timesofindia\"\n",
    "    }\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articals_insert_input!] = {}) {\n",
    "    insert_rss1_articals(objects: $objects, on_conflict: {constraint: rss1_articals_post_link_key}) {\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    for feed_link in rss1_links_array:\n",
    "        NewsFeed = feedparser.parse(feed_link)\n",
    "        is_default_image = 0\n",
    "        logo_url = response_data['data']['rss1_outlets'][0]['logo_url']\n",
    "        print(\"############################################################\")\n",
    "        print(feed_link)\n",
    "        articles = []\n",
    "        for entry in NewsFeed.entries:\n",
    "            # print(entry.link)\n",
    "            is_default_image = 0\n",
    "            title = entry.title\n",
    "            summary_nofil = entry.summary\n",
    "            summary = re.sub('<[^<]+?>', '', summary_nofil)\n",
    "            image_url = logo_url\n",
    "            for link in entry.links:\n",
    "                if link.type == \"image/jpeg\":\n",
    "                    image_url= link.href\n",
    "                    is_default_image = 1\n",
    "                    break\n",
    "            post_link = entry.link\n",
    "            published = entry.published\n",
    "            datevalidation = is_valid_timezone_format(published)\n",
    "            if datevalidation[0]:\n",
    "                hasura_timestamp = datevalidation[1]\n",
    "            if check_date_format(published):\n",
    "                hasura_timestamp = published\n",
    "            else:\n",
    "                hasura_timestamp = datetime.now().astimezone(timezone.utc).isoformat()\n",
    "            if \"author\" in entry:\n",
    "                author = entry.author\n",
    "            else:\n",
    "                author = \"na\"\n",
    "            articles.append({\n",
    "                    \"rss1_link\": feed_link,\n",
    "                    \"post_link\": post_link,\n",
    "                    \"title\": title,\n",
    "                    \"summary\": summary,\n",
    "                    \"author\": author,\n",
    "                    \"image_link\" : image_url,\n",
    "                    \"post_published\": hasura_timestamp,\n",
    "                    \"is_default_image\": is_default_image,\n",
    "                }\n",
    "            )\n",
    "            #print(feed_link, post_link, title, summary, author, image_url, hasura_timestamp, is_default_image)\n",
    "        mutation_variables = {\n",
    "            \"objects\": articles\n",
    "        }\n",
    "        #print({'query': mutation_query, 'variables': mutation_variables})\n",
    "        out1 = mutation_hasura_graphql(endpoint = endpoint, admin_key = admin_key, mutation_query = mutation_query, mutation_variables = mutation_variables)\n",
    "\n",
    "def update_articles_thehindu():\n",
    "    graphql_query = '''\n",
    "    query MyQuery($outlet: String!, $link_type: Int!) {\n",
    "    rss1_links(where: {rss1_link_type: {_eq: $link_type}, outlet: {_eq: $outlet}}) {\n",
    "        rss1_link\n",
    "    }\n",
    "    }\n",
    "    '''\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"link_type\": 11,\n",
    "        \"outlet\": \"thehindu\"\n",
    "    }\n",
    "    rss1_links_array = []\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    if response_data:\n",
    "        rss1_links_array = [item[\"rss1_link\"] for item in response_data[\"data\"][\"rss1_links\"]]\n",
    "    #print(rss1_links_array)\n",
    "    graphql_query = \"\"\"\n",
    "    query MyQuery($outlet: String!) {\n",
    "        rss1_outlets(where: {outlet: {_eq: $outlet}}) {\n",
    "            logo_url\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"outlet\": \"thehindu\"\n",
    "    }\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articals_insert_input!] = {}) {\n",
    "    insert_rss1_articals(objects: $objects, on_conflict: {constraint: rss1_articals_post_link_key}) {\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    for feed_link in rss1_links_array:\n",
    "        NewsFeed = feedparser.parse(feed_link)\n",
    "        is_default_image = 0\n",
    "        logo_url = response_data['data']['rss1_outlets'][0]['logo_url']\n",
    "        print(\"############################################################\")\n",
    "        print(feed_link)\n",
    "        articles = []\n",
    "        for entry in NewsFeed.entries:\n",
    "            # print(entry.link)\n",
    "            is_default_image = 0\n",
    "            title = entry.title\n",
    "            summary_nofil = entry.summary\n",
    "            summary = re.sub('<[^<]+?>', '', summary_nofil)\n",
    "            image_url = logo_url\n",
    "            for link in entry.links:\n",
    "                if link.type == \"image/jpeg\":\n",
    "                    image_url= link.href\n",
    "                    is_default_image = 1\n",
    "                    break\n",
    "            post_link = entry.link\n",
    "            published = entry.published\n",
    "            datevalidation = is_valid_timezone_format(published)\n",
    "            if datevalidation[0]:\n",
    "                hasura_timestamp = datevalidation[1]\n",
    "            if check_date_format(published):\n",
    "                hasura_timestamp = published\n",
    "            else:\n",
    "                hasura_timestamp = datetime.now().astimezone(timezone.utc).isoformat()\n",
    "            if \"author\" in entry:\n",
    "                author = entry.author\n",
    "            else:\n",
    "                author = \"na\"\n",
    "            articles.append({\n",
    "                    \"rss1_link\": feed_link,\n",
    "                    \"post_link\": post_link,\n",
    "                    \"title\": title,\n",
    "                    \"summary\": summary,\n",
    "                    \"author\": author,\n",
    "                    \"image_link\" : image_url,\n",
    "                    \"post_published\": hasura_timestamp,\n",
    "                    \"is_default_image\": is_default_image,\n",
    "                }\n",
    "            )\n",
    "            #print(feed_link, post_link, title, summary, author, image_url, hasura_timestamp, is_default_image)\n",
    "        mutation_variables = {\n",
    "            \"objects\": articles\n",
    "        }\n",
    "        #print({'query': mutation_query, 'variables': mutation_variables})\n",
    "        out1 = mutation_hasura_graphql(endpoint = endpoint, admin_key = admin_key, mutation_query = mutation_query, mutation_variables = mutation_variables)\n",
    "\n",
    "def update_articles_cnn():\n",
    "    graphql_query = '''\n",
    "    query MyQuery($outlet: String!, $link_type: Int!) {\n",
    "    rss1_links(where: {rss1_link_type: {_eq: $link_type}, outlet: {_eq: $outlet}}) {\n",
    "        rss1_link\n",
    "    }\n",
    "    }\n",
    "    '''\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"link_type\": 11,\n",
    "        \"outlet\": \"cnn\"\n",
    "    }\n",
    "    rss1_links_array = []\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    if response_data:\n",
    "        rss1_links_array = [item[\"rss1_link\"] for item in response_data[\"data\"][\"rss1_links\"]]\n",
    "    #print(rss1_links_array)\n",
    "    graphql_query = \"\"\"\n",
    "    query MyQuery($outlet: String!) {\n",
    "        rss1_outlets(where: {outlet: {_eq: $outlet}}) {\n",
    "            logo_url\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"outlet\": \"cnn\"\n",
    "    }\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articals_insert_input!] = {}) {\n",
    "    insert_rss1_articals(objects: $objects, on_conflict: {constraint: rss1_articals_post_link_key}) {\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    for feed_link in rss1_links_array:\n",
    "        NewsFeed = feedparser.parse(feed_link)\n",
    "        is_default_image = 0\n",
    "        logo_url = response_data['data']['rss1_outlets'][0]['logo_url']\n",
    "        print(\"############################################################\")\n",
    "        print(feed_link)\n",
    "        articles = []\n",
    "        for entry in NewsFeed.entries:\n",
    "            # print(entry.link)\n",
    "            is_default_image = 0\n",
    "            title = entry.title\n",
    "            summary = ''\n",
    "            if 'summary' in entry:\n",
    "                summary_nofil = entry.summary\n",
    "                summary = re.sub('<[^<]+?>', '', summary_nofil)\n",
    "            image_url = logo_url\n",
    "            if 'media_content' in entry:\n",
    "                image_url = entry['media_content'][0]['url']\n",
    "                is_default_image = 1\n",
    "            for link in entry.links:\n",
    "                if link.type == \"image/jpeg\":\n",
    "                    image_url= link.href\n",
    "                    is_default_image = 1\n",
    "                    break\n",
    "            post_link = entry.link\n",
    "            published = datetime.now(timezone.utc).isoformat()\n",
    "            if 'published' in entry:\n",
    "                published = entry.published\n",
    "            datevalidation = is_valid_timezone_format(published)\n",
    "            if datevalidation[0]:\n",
    "                hasura_timestamp = datevalidation[1]\n",
    "            if check_date_format(published):\n",
    "                hasura_timestamp = published\n",
    "            else:\n",
    "                hasura_timestamp = datetime.now().astimezone(timezone.utc).isoformat()\n",
    "            if \"author\" in entry:\n",
    "                author = entry.author\n",
    "            else:\n",
    "                author = \"na\"\n",
    "            articles.append({\n",
    "                    \"rss1_link\": feed_link,\n",
    "                    \"post_link\": post_link,\n",
    "                    \"title\": title,\n",
    "                    \"summary\": summary,\n",
    "                    \"author\": author,\n",
    "                    \"image_link\" : image_url,\n",
    "                    \"post_published\": hasura_timestamp,\n",
    "                    \"is_default_image\": is_default_image,\n",
    "                }\n",
    "            )\n",
    "            #print(feed_link, post_link, title, summary, author, image_url, hasura_timestamp, is_default_image)\n",
    "        mutation_variables = {\n",
    "            \"objects\": articles\n",
    "        }\n",
    "        #print({'query': mutation_query, 'variables': mutation_variables})\n",
    "        out1 = mutation_hasura_graphql(endpoint = endpoint, admin_key = admin_key, mutation_query = mutation_query, mutation_variables = mutation_variables)\n",
    "\n",
    "def update_articles_foxnews():\n",
    "    graphql_query = '''\n",
    "    query MyQuery($outlet: String!, $link_type: Int!) {\n",
    "    rss1_links(where: {rss1_link_type: {_eq: $link_type}, outlet: {_eq: $outlet}}) {\n",
    "        rss1_link\n",
    "    }\n",
    "    }\n",
    "    '''\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"link_type\": 11,\n",
    "        \"outlet\": \"foxnews\"\n",
    "    }\n",
    "    rss1_links_array = []\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    if response_data:\n",
    "        rss1_links_array = [item[\"rss1_link\"] for item in response_data[\"data\"][\"rss1_links\"]]\n",
    "    #print(rss1_links_array)\n",
    "    graphql_query = \"\"\"\n",
    "    query MyQuery($outlet: String!) {\n",
    "        rss1_outlets(where: {outlet: {_eq: $outlet}}) {\n",
    "            logo_url\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"outlet\": \"foxnews\"\n",
    "    }\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articals_insert_input!] = {}) {\n",
    "    insert_rss1_articals(objects: $objects, on_conflict: {constraint: rss1_articals_post_link_key}) {\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    for feed_link in rss1_links_array:\n",
    "        NewsFeed = feedparser.parse(feed_link)\n",
    "        is_default_image = 0\n",
    "        logo_url = response_data['data']['rss1_outlets'][0]['logo_url']\n",
    "        print(\"############################################################\")\n",
    "        print(feed_link)\n",
    "        articles = []\n",
    "        for entry in NewsFeed.entries:\n",
    "            # print(entry.link)\n",
    "            is_default_image = 0\n",
    "            title = entry.title\n",
    "            summary = ''\n",
    "            if 'summary' in entry:\n",
    "                summary_nofil = entry.summary\n",
    "                summary = re.sub('<[^<]+?>', '', summary_nofil)\n",
    "            image_url = logo_url\n",
    "            if 'media_content' in entry:\n",
    "                image_url = entry['media_content'][0]['url']\n",
    "                is_default_image = 1\n",
    "            if 'links' in entry:\n",
    "                for link in entry.links:\n",
    "                    if link.type == \"image/jpeg\":\n",
    "                        image_url= link.href\n",
    "                        is_default_image = 1\n",
    "                        break\n",
    "            post_link = entry.link\n",
    "            published = datetime.now(timezone.utc).isoformat()\n",
    "            if 'published' in entry:\n",
    "                published = entry.published\n",
    "            datevalidation = is_valid_timezone_format(published)\n",
    "            if datevalidation[0]:\n",
    "                hasura_timestamp = datevalidation[1]\n",
    "            if check_date_format(published):\n",
    "                hasura_timestamp = published\n",
    "            else:\n",
    "                hasura_timestamp = datetime.now().astimezone(timezone.utc).isoformat()\n",
    "            if \"author\" in entry:\n",
    "                author = entry.author\n",
    "            else:\n",
    "                author = \"na\"\n",
    "            articles.append({\n",
    "                    \"rss1_link\": feed_link,\n",
    "                    \"post_link\": post_link,\n",
    "                    \"title\": title,\n",
    "                    \"summary\": summary,\n",
    "                    \"author\": author,\n",
    "                    \"image_link\" : image_url,\n",
    "                    \"post_published\": hasura_timestamp,\n",
    "                    \"is_default_image\": is_default_image,\n",
    "                }\n",
    "            )\n",
    "            #print(feed_link, post_link, title, summary, author, image_url, hasura_timestamp, is_default_image)\n",
    "        mutation_variables = {\n",
    "            \"objects\": articles\n",
    "        }\n",
    "        #print({'query': mutation_query, 'variables': mutation_variables})\n",
    "        out1 = mutation_hasura_graphql(endpoint = endpoint, admin_key = admin_key, mutation_query = mutation_query, mutation_variables = mutation_variables)\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return cv2.imdecode(np.frombuffer(response.content, np.uint8), -1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def update_article_detail_toi_with_images():\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "        rss1_articals(offset: $offset, limit: $limit, where: {is_in_detail: {_eq: 0}, rss1LinkByRss1Link: {outlet: {_eq: \"timesofindia\"}}}, order_by: {post_published: desc}) {\n",
    "            post_link\n",
    "            is_default_image\n",
    "            image_link\n",
    "            id\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    offset = 0\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articles_detail_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}) {\n",
    "    insert_rss1_articles_detail(objects: $objects, on_conflict: {constraint: rss1_articles_detail_post_link_key}) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    update_rss1_articals_many(updates: $updates) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"    \n",
    "    options = webdriver.EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    options.add_argument('--enable-immersive-reader')\n",
    "    driver = webdriver.Edge(options=options)\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 2,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        #print(variables, response_data)\n",
    "        #print(response_data)\n",
    "        post_links_array = []\n",
    "        ids=[]\n",
    "        if response_data:\n",
    "            post_links_array = [item[\"post_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            is_default_image_array = [item[\"is_default_image\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            image_link_array = [item[\"image_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            ids=[item[\"id\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "        articles_detail = []\n",
    "        articles_update = []\n",
    "        if len(post_links_array) == 0:\n",
    "            break\n",
    "        try:\n",
    "            for a in range(len(post_links_array)):\n",
    "                main_link = post_links_array[a]\n",
    "                print(main_link)\n",
    "                read_link= \"read://\"+main_link\n",
    "                driver.get(read_link)\n",
    "                time.sleep(5)\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('a').key_up(Keys.CONTROL).perform()\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('c').key_up(Keys.CONTROL).perform()\n",
    "                text = pyperclip.paste()\n",
    "                text2 = text\n",
    "                text3 = text2.split('\\n')\n",
    "                text3 = [s.replace('\\r', '') for s in text3]\n",
    "                special_chars = set(\"!@#$%^&*()_+[]{}|;:'\\\",<>?\")\n",
    "                text4 = [s for s in text3 if len(s) > 0 and (s[0] not in special_chars or s[-1] not in special_chars)]\n",
    "                my_list = text4\n",
    "                my_set = set()\n",
    "                desription = []\n",
    "                for item in my_list:\n",
    "                    if item not in my_set:\n",
    "                        desription.append(item)\n",
    "                        my_set.add(item)\n",
    "                #print(desription)\n",
    "                driver.get(main_link)\n",
    "                time.sleep(5)\n",
    "                try: \n",
    "                    xpath = f\"\"\"//*/img[@alt=\"{desription[0]}\"]\"\"\"\n",
    "                    elements = driver.find_elements(By.XPATH, xpath)\n",
    "                    #print(elements)\n",
    "                    images = [element.get_attribute(\"src\") for element in elements]\n",
    "                    #print(images)\n",
    "                except:\n",
    "                    images = []\n",
    "                if is_default_image_array[a] == 1:\n",
    "                    images_1 = [image_link_array[a]] + images\n",
    "                else:\n",
    "                    images_1 = images\n",
    "                images_final = list(set(images_1))\n",
    "                images_to_remove = []\n",
    "                if len(images_final) > 1:\n",
    "                    image_urls = images_final\n",
    "                    for i in range(len(image_urls)):\n",
    "                        for j in range(i+1, len(image_urls)):\n",
    "                            image1 = load_image_from_url(image_urls[i])\n",
    "                            image2 = load_image_from_url(image_urls[j])\n",
    "\n",
    "                            if image1 is None or image2 is None:\n",
    "                                print(f\"Failed to load one or both images for comparison between image {i+1} and image {j+1}.\")\n",
    "                                continue\n",
    "\n",
    "                            # Resize the images to the same dimensions for comparison\n",
    "                            height, width, _ = image1.shape\n",
    "                            image3 = cv2.resize(image2, (width, height))\n",
    "\n",
    "                            # Convert the images to grayscale\n",
    "                            gray_image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "                            gray_image2 = cv2.cvtColor(image3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                            # Calculate the structural similarity\n",
    "                            result = match_template(gray_image1, gray_image2)\n",
    "                            ssim = np.max(result)\n",
    "\n",
    "                            # Display the SSIM value (a higher value indicates more similarity)\n",
    "                            #print(f\"SSIM between image {i+1} and image {j+1}: {ssim}\")\n",
    "                            height1, width1, _ = image1.shape\n",
    "                            height2, width2, _ = image2.shape\n",
    "                            height1, width1, _ = image1.shape\n",
    "                            height2, width2, _ = image2.shape\n",
    "                            if height1 * width1 >= height2 * width2 and ssim > 0.8:\n",
    "                                images_to_remove.append(image_urls[i+1])\n",
    "                            elif height1 * width1 < height2 * width2 and ssim > 0.8:\n",
    "                                images_to_remove.append(image_urls[i])\n",
    "\n",
    "                    # Remove the images that were marked for removal\n",
    "                    for image_url in images_to_remove:\n",
    "                        if image_url in images_final:\n",
    "                            images_final.remove(image_url)\n",
    "                #print(images_final)\n",
    "                articles_detail.append({\n",
    "                    \"article_id\": ids[a],\n",
    "                    \"title\": desription[0],\n",
    "                    \"discription\": desription[1:],\n",
    "                    \"image_link\": images_final,\n",
    "                }\n",
    "                )\n",
    "                if (is_default_image_array[a] == 0 and len(images_final) > 0):\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1 , \"image_link\": images_final[0], \"is_default_image\": 1}\n",
    "                    })\n",
    "                else:\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1}\n",
    "                    })\n",
    "                \n",
    "                #print(main_link, desription[0], desription[1:], images_final)\n",
    "            #print(articles_update)\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        except:\n",
    "            offset = offset + 1\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        \n",
    "    driver.quit() \n",
    "\n",
    "def update_article_detail_toi():\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "        rss1_articals(offset: $offset, limit: $limit, where: {is_in_detail: {_eq: 0}, rss1LinkByRss1Link: {outlet: {_eq: \"timesofindia\"}}}, order_by: {post_published: desc}) {\n",
    "            post_link\n",
    "            is_default_image\n",
    "            image_link\n",
    "            id\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    offset = 0\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articles_detail_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}) {\n",
    "    insert_rss1_articles_detail(objects: $objects, on_conflict: {constraint: rss1_articles_detail_article_id_key}) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    update_rss1_articals_many(updates: $updates) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"    \n",
    "    options = webdriver.EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    options.add_argument('--enable-immersive-reader')\n",
    "    driver = webdriver.Edge(options=options)\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 20,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        #print(variables, response_data)\n",
    "        #print(response_data)\n",
    "        post_links_array = []\n",
    "        ids=[]\n",
    "        if response_data:\n",
    "            post_links_array = [item[\"post_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            is_default_image_array = [item[\"is_default_image\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            image_link_array = [item[\"image_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            ids=[item[\"id\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "        articles_detail = []\n",
    "        articles_update = []\n",
    "        if len(post_links_array) == 0:\n",
    "            break\n",
    "        try:\n",
    "            for a in range(len(post_links_array)):\n",
    "                main_link = post_links_array[a]\n",
    "                print(main_link)\n",
    "                read_link= \"read://\"+main_link\n",
    "                driver.get(read_link)\n",
    "                time.sleep(5)\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('a').key_up(Keys.CONTROL).perform()\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('c').key_up(Keys.CONTROL).perform()\n",
    "                text = pyperclip.paste()\n",
    "                text2 = text\n",
    "                text3 = text2.split('\\n')\n",
    "                text3 = [s.replace('\\r', '') for s in text3]\n",
    "                special_chars = set(\"!@#$%^&*()_+[]{}|;:'\\\",<>?\")\n",
    "                text4 = [s for s in text3 if len(s) > 0 and (s[0] not in special_chars or s[-1] not in special_chars)]\n",
    "                my_list = text4\n",
    "                my_set = set()\n",
    "                desription = []\n",
    "                for item in my_list:\n",
    "                    if item not in my_set:\n",
    "                        desription.append(item)\n",
    "                        my_set.add(item)\n",
    "                #print(desription)\n",
    "                images_final = []\n",
    "                articles_detail.append({\n",
    "                    \"article_id\": ids[a],\n",
    "                    \"title\": desription[0],\n",
    "                    \"description\": desription[1:],\n",
    "                    \"image_link\": images_final,\n",
    "                }\n",
    "                )\n",
    "                if (is_default_image_array[a] == 0 and len(images_final) > 0):\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1 , \"image_link\": images_final[0], \"is_default_image\": 1}\n",
    "                    })\n",
    "                else:\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1}\n",
    "                    })\n",
    "                \n",
    "                #print(main_link, desription[0], desription[1:], images_final)\n",
    "            #print(articles_update)\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        except:\n",
    "            offset = offset + 1\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        \n",
    "    driver.quit() \n",
    "\n",
    "def update_article_detail_cnn(offset1):\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "        rss1_articals(offset: $offset, limit: $limit, where: {is_in_detail: {_eq: 0}, rss1LinkByRss1Link: {outlet: {_eq: \"cnn\"}}}, order_by: {post_published: desc}) {\n",
    "            post_link\n",
    "            is_default_image\n",
    "            image_link\n",
    "            id\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articles_detail_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}) {\n",
    "    insert_rss1_articles_detail(objects: $objects, on_conflict: {constraint: rss1_articles_detail_article_id_key}) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    update_rss1_articals_many(updates: $updates) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"    \n",
    "    options = webdriver.EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    options.add_argument('--enable-immersive-reader')\n",
    "    driver = webdriver.Edge(options=options)\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 2,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        #print(variables, response_data)\n",
    "        #print(response_data)\n",
    "        post_links_array = []\n",
    "        ids=[]\n",
    "        if response_data:\n",
    "            post_links_array = [item[\"post_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            is_default_image_array = [item[\"is_default_image\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            image_link_array = [item[\"image_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            ids=[item[\"id\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "        articles_detail = []\n",
    "        articles_update = []\n",
    "        if len(post_links_array) == 0:\n",
    "            break\n",
    "        try:\n",
    "            for a in range(len(post_links_array)):\n",
    "                main_link = post_links_array[a]\n",
    "                print(main_link)\n",
    "                driver.get(main_link)\n",
    "                get_url = driver.current_url\n",
    "                read_link= \"read://\"+get_url\n",
    "                driver.get(read_link)\n",
    "                time.sleep(5)\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('a').key_up(Keys.CONTROL).perform()\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('c').key_up(Keys.CONTROL).perform()\n",
    "                text = pyperclip.paste()\n",
    "                text2 = text\n",
    "                text3 = text2.split('\\n')\n",
    "                text3 = [s.replace('\\r', '') for s in text3]\n",
    "                special_chars = set(\"!@#$%^&*()_+[]{}|;:'\\\",<>?\")\n",
    "                text4 = [s for s in text3 if len(s) > 0 and (s[0] not in special_chars or s[-1] not in special_chars)]\n",
    "                my_list = text4\n",
    "                my_set = set()\n",
    "                desription = []\n",
    "                for item in my_list:\n",
    "                    if item not in my_set:\n",
    "                        desription.append(item)\n",
    "                        my_set.add(item)\n",
    "                #print(desription)\n",
    "                images_final = []\n",
    "                articles_detail.append({\n",
    "                    \"article_id\": ids[a],\n",
    "                    \"title\": desription[0],\n",
    "                    \"description\": desription[1:],\n",
    "                    \"image_link\": images_final,\n",
    "                }\n",
    "                )\n",
    "                if (is_default_image_array[a] == 0 and len(images_final) > 0):\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1 , \"image_link\": images_final[0], \"is_default_image\": 1}\n",
    "                    })\n",
    "                else:\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1}\n",
    "                    })\n",
    "                \n",
    "                #print(main_link, desription[0], desription[1:], images_final)\n",
    "            #print(articles_update)\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        except:\n",
    "            offset = offset + 1\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        \n",
    "    driver.quit() \n",
    "\n",
    "def update_article_detail_foxnews(offset1):\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "        rss1_articals(offset: $offset, limit: $limit, where: {is_in_detail: {_eq: 0}, rss1LinkByRss1Link: {outlet: {_eq: \"thehindu\"}}}, order_by: {post_published: desc}) {\n",
    "            post_link\n",
    "            is_default_image\n",
    "            image_link\n",
    "            id\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articles_detail_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}) {\n",
    "    insert_rss1_articles_detail(objects: $objects, on_conflict: {constraint: rss1_articles_detail_article_id_key}) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    update_rss1_articals_many(updates: $updates) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"    \n",
    "    options = webdriver.EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    options.add_argument('--enable-immersive-reader')\n",
    "    driver = webdriver.Edge(options=options)\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 2,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        #print(variables, response_data)\n",
    "        #print(response_data)\n",
    "        post_links_array = []\n",
    "        ids=[]\n",
    "        if response_data:\n",
    "            post_links_array = [item[\"post_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            is_default_image_array = [item[\"is_default_image\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            image_link_array = [item[\"image_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            ids=[item[\"id\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "        articles_detail = []\n",
    "        articles_update = []\n",
    "        if len(post_links_array) == 0:\n",
    "            break\n",
    "        try:\n",
    "            for a in range(len(post_links_array)):\n",
    "                main_link = post_links_array[a]\n",
    "                print(main_link)\n",
    "                driver.get(main_link)\n",
    "                get_url = driver.current_url\n",
    "                read_link= \"read://\"+get_url\n",
    "                driver.get(read_link)\n",
    "                time.sleep(5)\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('a').key_up(Keys.CONTROL).perform()\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('c').key_up(Keys.CONTROL).perform()\n",
    "                text = pyperclip.paste()\n",
    "                text2 = text\n",
    "                text3 = text2.split('\\n')\n",
    "                text3 = [s.replace('\\r', '') for s in text3]\n",
    "                special_chars = set(\"!@#$%^&*()_+[]{}|;:'\\\",<>?\")\n",
    "                text4 = [s for s in text3 if len(s) > 0 and (s[0] not in special_chars or s[-1] not in special_chars)]\n",
    "                my_list = text4\n",
    "                my_set = set()\n",
    "                desription = []\n",
    "                for item in my_list:\n",
    "                    if item not in my_set:\n",
    "                        desription.append(item)\n",
    "                        my_set.add(item)\n",
    "                #print(desription)\n",
    "                images_final = []\n",
    "                articles_detail.append({\n",
    "                    \"article_id\": ids[a],\n",
    "                    \"title\": desription[0],\n",
    "                    \"description\": desription[1:],\n",
    "                    \"image_link\": images_final,\n",
    "                }\n",
    "                )\n",
    "                if (is_default_image_array[a] == 0 and len(images_final) > 0):\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1 , \"image_link\": images_final[0], \"is_default_image\": 1}\n",
    "                    })\n",
    "                else:\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1}\n",
    "                    })\n",
    "                \n",
    "                #print(main_link, desription[0], desription[1:], images_final)\n",
    "            #print(articles_update)\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        except:\n",
    "            offset = offset + 1\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        \n",
    "    driver.quit() \n",
    "\n",
    "def summerizer(offset1): \n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0)\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    rss1_articles_detail(limit: $limit, offset: $offset, where: {summary: {_is_null: true}}) {\n",
    "        title\n",
    "        description\n",
    "        rss1_artical {\n",
    "        title\n",
    "        summary\n",
    "        }\n",
    "        article_id\n",
    "    }\n",
    "    }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($updates: [rss1_articles_detail_updates!] = {where: {}}) {\n",
    "        update_rss1_articles_detail_many(updates: $updates) {\n",
    "            affected_rows\n",
    "            returning {\n",
    "            id\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 2,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        rss1_articles_detail_updates = []\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        if len(response_data['data']['rss1_articles_detail']) == 0:\n",
    "            break\n",
    "        for response in response_data['data']['rss1_articles_detail']:\n",
    "            print(response['title'])\n",
    "            article=\"\"\n",
    "            article = article + response['title'] + \" \" +  response['rss1_artical']['title'] + \" \" +  response['rss1_artical']['summary'] + ', '.join(response['description'])\n",
    "            chunks=[]\n",
    "            max_length = 0\n",
    "            min_length = 0\n",
    "            if len(article) < 1000:\n",
    "                max_length = 150\n",
    "                min_length = 100\n",
    "                chunks.append(article)\n",
    "            elif len(article) < 3000:\n",
    "                max_length = 300\n",
    "                min_length = 200\n",
    "                chunks.append(article)\n",
    "            elif len(article) < 4000:\n",
    "                max_length = 400\n",
    "                min_length = 250\n",
    "                chunks.append(article)\n",
    "            elif len(article) < 8000:\n",
    "                max_length = 200\n",
    "                min_length = 150\n",
    "                midpoint = len(article) // 2\n",
    "                chunks.append(article[:midpoint])\n",
    "                chunks.append(article[midpoint:])\n",
    "            else:\n",
    "                article=article[:8000]\n",
    "                max_length = 200\n",
    "                min_length = 150\n",
    "                midpoint = len(article) // 2\n",
    "                chunks.append(article[:midpoint])\n",
    "                chunks.append(article[midpoint:])\n",
    "\n",
    "            summerize=\"\"\n",
    "            for chunk in chunks:\n",
    "                summerize=summerize + summarizer(chunk, max_length=max_length, min_length=min_length, do_sample=False)[0]['summary_text']+ \" \"\n",
    "            if len(summerize) > 0:\n",
    "                rss1_articles_detail_updates.append({\n",
    "                    \"where\": {\"article_id\" : { \"_eq\": response['article_id'] }},\n",
    "                    \"_set\": {\"summary\": summerize }\n",
    "                })\n",
    "        mutation_variables = {\n",
    "            \"updates\": rss1_articles_detail_updates,\n",
    "            }\n",
    "        out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "\n",
    "def vectorize(offset1):\n",
    "    model = INSTRUCTOR('hkunlp/instructor-xl', device=0)\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    rss1_articals(limit: $limit, offset: $offset, where: {is_vectorized: {_eq: 0}, is_in_detail: {_eq: 1}}) {\n",
    "        id\n",
    "        title\n",
    "        summary\n",
    "        rss1_articles_details {\n",
    "        summary\n",
    "        tags\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [articles_vector1_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}) {\n",
    "    insert_articles_vector1(objects: $objects, on_conflict: {constraint: articles_vector1_article_id_key}) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        article_id\n",
    "        }\n",
    "    }\n",
    "    update_rss1_articals_many(updates: $updates) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 1,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        articles_vector1_insert_input_loc=[]\n",
    "        rss1_articals_updates_loc=[]\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        if len(response_data['data']['rss1_articals']) == 0:\n",
    "            break\n",
    "        #print(json.dumps(response_data, indent=4))\n",
    "        s1= []\n",
    "        ids=[]\n",
    "        for response in response_data['data']['rss1_articals']:\n",
    "            article=\"\"\n",
    "            tags=\"\"\n",
    "            if (response['rss1_articles_details'][0]['tags']) is None:\n",
    "                tags = \" \"\n",
    "            else:\n",
    "                tags = \", \".join(response['rss1_articles_details'][0]['tags'])\n",
    "            article = article + response['title'] + \" \" +  response['summary'] + \" \" +  response['rss1_articles_details'][0]['summary'] + tags\n",
    "            s1.append([['Represent the news article for custering and retrieval:  ', article]])\n",
    "            ids.append(response['id'])\n",
    "        embeddings = []\n",
    "        for s in s1:\n",
    "            list_embeddings = numpy.ravel(model.encode(s)).tolist()\n",
    "            embeddings.append(list_embeddings)\n",
    "        for i in range(0,len(ids)):\n",
    "            articles_vector1_insert_input_loc.append({\n",
    "                \"article_id\": ids[i],\n",
    "                \"embedding\": str(embeddings[i]),\n",
    "                }\n",
    "                )\n",
    "            rss1_articals_updates_loc.append({\n",
    "                \"where\": {\"id\" : { \"_eq\": ids[i] }},\n",
    "                \"_set\": {\"is_vectorized\": 1}\n",
    "                })\n",
    "\n",
    "        mutation_variables = {\n",
    "        \"objects\": articles_vector1_insert_input_loc,\n",
    "        \"updates\": rss1_articals_updates_loc,\n",
    "        }\n",
    "        out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "      \n",
    "def grouping(offset1):\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "        rss1_articals(limit: $limit, offset: $offset, where: {is_vectorized: {_eq: 1}, is_in_detail: {_eq: 1}, is_grouped: {_eq: 0}}) {\n",
    "            id\n",
    "            articles_vector1 {\n",
    "            embedding\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [articles_groups_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}) {\n",
    "        insert_articles_groups(objects: $objects, on_conflict: {constraint: articles_groups_pkey}) {\n",
    "            affected_rows\n",
    "            returning {\n",
    "            article_id\n",
    "            }\n",
    "        }\n",
    "        update_rss1_articals_many(updates: $updates) {\n",
    "            affected_rows\n",
    "            returning {\n",
    "            id\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "    \"\"\"\n",
    "    func_query = '''\n",
    "    query MyQuery($p_article_id: bigint!) {\n",
    "        get_similar_articles_en(args: {p_article_id: $p_article_id}) {\n",
    "            article_id\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 20,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        articles_groups_insert_input_loc=[]\n",
    "        rss1_articals_updates_loc=[]\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        if len(response_data['data']['rss1_articals']) == 0:\n",
    "            break\n",
    "        #print(json.dumps(response_data, indent=4))\n",
    "        s1= []\n",
    "        ids=[]\n",
    "        for response in response_data['data']['rss1_articals']:\n",
    "            article_embed = response['articles_vector1']['embedding']\n",
    "            func_variables = {\n",
    "                \"p_article_id\": response['id']\n",
    "                }\n",
    "            func_response_data = query_hasura_graphql(endpoint, admin_key, func_query, func_variables)\n",
    "            article_group = []\n",
    "            if len(func_response_data['data']['get_similar_articles_en']) > 0:\n",
    "                for func_response in func_response_data['data']['get_similar_articles_en']:\n",
    "                    article_group.append(func_response['article_id'])\n",
    "            \n",
    "            articles_groups_insert_input_loc.append({\n",
    "                \"article_id\": response['id'],\n",
    "                \"initial_group\": article_group,\n",
    "                }\n",
    "                )\n",
    "            rss1_articals_updates_loc.append({\n",
    "                \"where\": {\"id\" : { \"_eq\": response['id'] }},\n",
    "                \"_set\": {\"is_grouped\": 1}\n",
    "                })\n",
    "\n",
    "        mutation_variables = {\n",
    "        \"objects\": articles_groups_insert_input_loc,\n",
    "        \"updates\": rss1_articals_updates_loc,\n",
    "        }\n",
    "        out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "\n",
    "def grouping_l1(offset1):\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "          rss1_articals(where: {is_grouped: {_eq: 1}}, limit: $limit, offset: $offset) {\n",
    "            id\n",
    "            articles_group {\n",
    "            initial_group\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "        mutation MyMutation($objects: [articles_grouped_l1_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}, $updates1: [articles_grouped_l1_updates!] = {where: {}}) {\n",
    "        insert_articles_grouped_l1(objects: $objects) {\n",
    "            affected_rows\n",
    "        }\n",
    "        update_rss1_articals_many(updates: $updates) {\n",
    "            affected_rows\n",
    "        }\n",
    "        update_articles_grouped_l1_many(updates: $updates1) {\n",
    "            affected_rows\n",
    "        }\n",
    "        }\n",
    "    \"\"\"\n",
    "    func_query = '''\n",
    "    query MyQuery($arg_1: bigint!) {\n",
    "        get_articles_groups(args: {arg_1: $arg_1}) {\n",
    "            initial_group\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    func_query1 = '''\n",
    "    query MyQuery($arg_1: bigint!) {\n",
    "        get_articles_grouped_l1(args: {arg_1: $arg_1}) {\n",
    "            article_ids,\n",
    "            id\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 1,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        articles_grouped_l1_insert_input_loc=[]\n",
    "        rss1_articals_updates_loc=[]\n",
    "        articles_grouped_l1_updates=[]\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        if len(response_data['data']['rss1_articals']) == 0:\n",
    "            break\n",
    "        #print(json.dumps(response_data, indent=4))\n",
    "        for response in response_data['data']['rss1_articals']:\n",
    "\n",
    "            func_variables = {\n",
    "                \"arg_1\": response['id']\n",
    "                }\n",
    "            func_response_data = query_hasura_graphql(endpoint, admin_key, func_query, func_variables)\n",
    "            articles_ids = []\n",
    "            print(response['id'])\n",
    "            if len(func_response_data['data']['get_articles_groups']) > 0:\n",
    "                for func_response in func_response_data['data']['get_articles_groups']:\n",
    "                    articles_ids.append(func_response['initial_group'])\n",
    "            \n",
    "            func_response_data1 = query_hasura_graphql(endpoint, admin_key, func_query1, func_variables)\n",
    "            \n",
    "            \n",
    "            if (len(func_response_data1['data']['get_articles_grouped_l1']) == 0):\n",
    "                new_lst = []\n",
    "                for sublist in articles_ids:\n",
    "                    for element in sublist:\n",
    "                        new_lst.append(element)\n",
    "                my_list = list(set(new_lst))\n",
    "                print(my_list)\n",
    "                articles_grouped_l1_insert_input_loc.append({\n",
    "                    \"article_ids\": my_list,\n",
    "                    'articles_in_group': len(my_list)\n",
    "                    }\n",
    "                    )\n",
    "                rss1_articals_updates_loc.append({\n",
    "                    \"where\": {\"id\" : { \"_eq\": response['id'] }},\n",
    "                    \"_set\": {\"is_grouped\": 2}\n",
    "                    })\n",
    "            else:\n",
    "                articles_ids.append(func_response_data1['data']['get_articles_grouped_l1'][0]['article_ids'])\n",
    "                new_lst = []\n",
    "                for sublist in articles_ids:\n",
    "                    for element in sublist:\n",
    "                        new_lst.append(element)\n",
    "                my_list = list(set(new_lst))\n",
    "                articles_grouped_l1_updates.append({\n",
    "                    \"where\": {\"id\" : { \"_eq\": func_response_data1['data']['get_articles_grouped_l1'][0]['id'] }},\n",
    "                    \"_set\": {\"article_ids\": my_list, 'articles_in_group': len(my_list)}\n",
    "                    })\n",
    "                rss1_articals_updates_loc.append({\n",
    "                    \"where\": {\"id\" : { \"_eq\": response['id'] }},\n",
    "                    \"_set\": {\"is_grouped\": 2}\n",
    "                    })\n",
    "                print(my_list)     \n",
    "\n",
    "\n",
    "        mutation_variables = {\n",
    "        \"objects\": articles_grouped_l1_insert_input_loc,\n",
    "        \"updates\": rss1_articals_updates_loc,\n",
    "        \"updates1\": articles_grouped_l1_updates,\n",
    "        }\n",
    "        out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update_articles_toi()\n",
    "#update_articles_thehindu()\n",
    "#update_articles_cnn()\n",
    "#update_articles_foxnews()\n",
    "\n",
    "#update_article_detail_toi()\n",
    "#update_article_detail_cnn(0)\n",
    "#update_article_detail_foxnews(0)\n",
    "#summerizer(0)\n",
    "#vectorize(0)\n",
    "grouping(0)\n",
    "grouping_l1(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665\n",
      "1243\n",
      "\n",
      "Vietnam detains energy policy think-tank chief, human rights group says\n",
      "Ngo Thi To Nhien, the executive director for Vietnam Initiative for Energy Transition was arrested on Sept. 15, according to The 88 Project, a group that advocates for freedom of expression in Vietnam\n",
      "Ngo Thi To Nhien, the executive director for Vietnam Initiative for Energy Transition was arrested on Sept. 15, according to The 88 Project, a group that advocates for freedom of expression in Vietnam. Police also raided and searched the offices of the think tank and interrogated staff members, it said. Police have said the earlier arrests of other energy experts were on suspicion of tax evasion. Vietnam is one of a few remaining communist single-party states that tolerate no dissent. In 2022, Human Rights Watch said that more than 170 activists had been put under house arrest, blocked from traveling or in some cases assaulted by agents of the Vietnamese government in a little-noticed campaign to silence its critics. The German government said in June that it was concerned by the earlier detention of a prominent environmental campaigner in Vietnam, warning that the JETP deal requires the involvement of civil society activists. The U.N. Development Program is helping Vietnam phase out use of fossil fuels with $15.5 billion in support from the Group of Seven advanced economies. \n",
      "Vietnamese energy think tank director arrested, marking sixth detention of climate expert in 2 years\n",
      "Vietnam authorities detained an energy think tank director on September 15, making it the sixth detention of a climate expert in the last two years, according to rights group.\n",
      "Ngo Thi To Nhien, the executive director for Vietnam Initiative for Energy Transition (VIET) was arrested on Sept. 15. Police also raided and searched the offices of the think tank and interrogated staff members. Police have said the earlier arrests of other energy experts were on suspicion of tax evasion. The German government said in June that it was concerned by the earlier detention of a prominent environmental campaigner in Vietnam, warning that the JETP deal requires the involvement of civil society activists. Vietnam is one of a few remaining communist single-party states that tolerate no dissent. In 2022, Human Rights Watch said that more than 170 activists had been put under house arrest, blocked from traveling or in some cases assaulted by agents of the Vietnamese government in a little-noticed campaign to silence its critics. The 88 Project, a group that advocates for freedom of expression in Vietnam said the detention is significant as it signals that research on energy policy is now off limits. It is the sixth expert working on environmental and climate issues that authorities have taken into custody in the past two years, a rights group said Wednesday. The U.N. Development Program was working with VIET to help implement the Just Energy Transition Partnership (JETP) — a deal designed to help the Southeast Asian nation phase out use of fossil fuels. \n",
      "1\n",
      "590\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a unbiased professional news article for:\n",
      "\n",
      "\n",
      "    Vietnam detains energy policy think-tank chief, human rights group says\n",
      "Ngo Thi To Nhien, the executive director for Vietnam Initiative for Energy Transition was arrested on Sept. 15, according to The 88 Project, a group that advocates for freedom of expression in Vietnam\n",
      "Ngo Thi To Nhien, the executive director for Vietnam Initiative for Energy Transition was arrested on Sept. 15, according to The 88 Project, a group that advocates for freedom of expression in Vietnam. Police also raided and searched the offices of the think tank and interrogated staff members, it said. Police have said the earlier arrests of other energy experts were on suspicion of tax evasion. Vietnam is one of a few remaining communist single-party states that tolerate no dissent. In 2022, Human Rights Watch said that more than 170 activists had been put under house arrest, blocked from traveling or in some cases assaulted by agents of the Vietnamese government in a little-noticed campaign to silence its critics. The German government said in June that it was concerned by the earlier detention of a prominent environmental campaigner in Vietnam, warning that the JETP deal requires the involvement of civil society activists. The U.N. Development Program is helping Vietnam phase out use of fossil fuels with $15.5 billion in support from the Group of Seven advanced economies. \n",
      "Vietnamese energy think tank director arrested, marking sixth detention of climate expert in 2 years\n",
      "Vietnam authorities detained an energy think tank director on September 15, making it the sixth detention of a climate expert in the last two years, according to rights group.\n",
      "Ngo Thi To Nhien, the executive director for Vietnam Initiative for Energy Transition (VIET) was arrested on Sept. 15. Police also raided and searched the offices of the think tank and interrogated staff members. Police have said the earlier arrests of other energy experts were on suspicion of tax evasion. The German government said in June that it was concerned by the earlier detention of a prominent environmental campaigner in Vietnam, warning that the JETP deal requires the involvement of civil society activists. Vietnam is one of a few remaining communist single-party states that tolerate no dissent. In 2022, Human Rights Watch said that more than 170 activists had been put under house arrest, blocked from traveling or in some cases assaulted by agents of the Vietnamese government in a little-noticed campaign to silence its critics. The 88 Project, a group that advocates for freedom of expression in Vietnam said the detention is significant as it signals that research on energy policy is now off limits. It is the sixth expert working on environmental and climate issues that authorities have taken into custody in the past two years, a rights group said Wednesday. The U.N. Development Program was working with VIET to help implement the Just Energy Transition Partnership (JETP) — a deal designed to help the Southeast Asian nation phase out use of fossil fuels.\n",
      "\n",
      "\n",
      "    CONSCISE UNBIASED detailed news article with at least 500 words:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Chain type: StuffDocumentsChain\n",
      "Run time: 30.485000000000582\n",
      "Summary: Vietnam Detains Energy Policy Think-Tank Chief, Human Rights Group Says  Ngo Thi To Nhien, the\n",
      "executive director for Vietnam Initiative for Energy Transition (VIET), was arrested on September\n",
      "15, according to The 88 Project, a group that advocates for freedom of expression in Vietnam. This\n",
      "marks the sixth detention of a climate expert in the country in the past two years, raising concerns\n",
      "about the government's treatment of environmental activists.  The arrest of Ngo Thi To Nhien was\n",
      "accompanied by a raid and search of the VIET offices, as well as the interrogation of staff members,\n",
      "according to The 88 Project. The Vietnamese police have stated that the earlier arrests of other\n",
      "energy experts were made on suspicion of tax evasion. However, human rights organizations and\n",
      "activists argue that these detentions are part of a broader campaign to silence dissent and stifle\n",
      "criticism of the government's policies.  Vietnam is known for being one of the few remaining\n",
      "communist single-party states that tolerate no dissent. In 2022, Human Rights Watch reported that\n",
      "more than 170 activists had been put under house arrest, blocked from traveling, or even assaulted\n",
      "by agents of the Vietnamese government. This campaign to silence critics has largely gone unnoticed\n",
      "by the international community.  The German government expressed concern in June over the detention\n",
      "of a prominent environmental campaigner in Vietnam, highlighting the importance of civil society\n",
      "activists in the implementation of the Just Energy Transition Partnership (JETP) deal. The JETP,\n",
      "supported by the United Nations Development Program and the Group of Seven advanced economies, aims\n",
      "to help Vietnam phase out the use of fossil fuels.  The arrest of Ngo Thi To Nhien is particularly\n",
      "significant as it signals that research on energy policy is now off-limits in Vietnam. The 88\n",
      "Project, which advocates for freedom of expression in the country, emphasized that this is the sixth\n",
      "detention of an expert working on environmental and climate issues in the past two years. This\n",
      "pattern raises concerns about the government's commitment to addressing climate change and\n",
      "transitioning to cleaner energy sources.  The United Nations Development Program has been working\n",
      "with VIET to implement the JETP, providing $15.5 billion in support from the Group of Seven advanced\n",
      "economies. The program's goal is to assist Vietnam in reducing its reliance on fossil fuels and\n",
      "promoting sustainable energy solutions. However, with the detention of Ngo Thi To Nhien and other\n",
      "climate experts, there are concerns about the government's willingness to engage with civil society\n",
      "and allow for open dialogue on energy policy.  The international community must pay attention to the\n",
      "situation in Vietnam and urge the government to respect freedom of expression and human rights. The\n",
      "detention of Ngo Thi To Nhien and other climate experts not only stifles important research and\n",
      "advocacy but also undermines efforts to address climate change and promote sustainable development\n",
      "in the country.  As the world faces the urgent challenges of climate change, it is crucial that\n",
      "governments support and encourage the work of experts and activists who are dedicated to finding\n",
      "solutions. The arrest of Ngo Thi To Nhien and the ongoing detention of climate experts in Vietnam is\n",
      "a step in the wrong direction and must be addressed by the international community.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "import tiktoken\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap\n",
    "from time import monotonic\n",
    "\n",
    "\n",
    "gpt_35_turbo_max_tokens = 4097\n",
    "verbose = True\n",
    "prompt_template = \"\"\"Write a unbiased professional news article for:\n",
    "\n",
    "\n",
    "    {text}\n",
    "\n",
    "\n",
    "    CONSCISE UNBIASED detailed news article with at least 500 words:\"\"\"\n",
    "OPENAI_API_KEY= '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'\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY, model_name=model_name)\n",
    "\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:    \n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    articles_grouped_l1(where: {articles_in_group: {_gt: 1}, _and: {articles_in_group: {_lt: 10}}}, limit: $limit, offset: $offset) {\n",
    "        article_ids\n",
    "    }\n",
    "    }\n",
    "'''\n",
    "graphql_grquery_article = '''\n",
    "query MyQuery($article_id: bigint!) {\n",
    "  rss1_articals(where: {id: {_eq: $article_id}}) {\n",
    "    title\n",
    "    summary\n",
    "    rss1_articles_detail {\n",
    "      summary\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "offset = 0\n",
    "variables = {\n",
    "\"limit\": 1,\n",
    "\"offset\": offset\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "for response in response_data['data']['articles_grouped_l1']:\n",
    "    llm_text = ''\n",
    "    for article in response['article_ids']:\n",
    "        print(article)\n",
    "        article_variables = {\n",
    "        \"article_id\": article\n",
    "        }\n",
    "        article_response_data = query_hasura_graphql(endpoint, admin_key, graphql_grquery_article, article_variables)\n",
    "        llm_text = llm_text + \"\\n\" +article_response_data['data']['rss1_articals'][0]['title'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['summary'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['rss1_articles_detail']['summary']\n",
    "    print(llm_text)\n",
    "\n",
    "\n",
    "    texts = text_splitter.split_text(llm_text)\n",
    "\n",
    "    docs = [Document(page_content=t) for t in texts]\n",
    "    print(len(docs))\n",
    "    \n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "    num_tokens = num_tokens_from_string(llm_text, model_name)\n",
    "    print(num_tokens)\n",
    "    if num_tokens < gpt_35_turbo_max_tokens:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt, verbose=verbose)\n",
    "    else:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=prompt, combine_prompt=prompt, verbose=verbose)\n",
    "\n",
    "    start_time = monotonic()\n",
    "    summary = chain.run(docs)\n",
    "\n",
    "    print(f\"Chain type: {chain.__class__.__name__}\")\n",
    "    print(f\"Run time: {monotonic() - start_time}\")\n",
    "    print(f\"Summary: {textwrap.fill(summary, width=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "145\n",
      "\n",
      "3 Idiots actor Akhil Mishra passes away in an accident\n",
      "Renowned actor Akhil Mishra, widely recognized for his portrayal of librarian Dubey in the Aamir Khan starrer \"3 Idiots,\" has passed away. ETimes TV has exclusively learnt about his demise. Sources have revealed that his wife, the actress Suzanne Bernert, was away in Hyderabad for a film shoot when this tragic incident occurred.\n",
      "Akhil Mishra, who played Librarian Dubey in Aamir Khan starrer ‘3 Idiots’ passes away in a SHOCKING incident. His wife and actress Suzanne Bernert was in Hyderabad for a shoot when the incident happened. Suzanna shared, ‘My heart is broken, my second half is gone’ His last rites are going to be held at 3.30 pm today (September 21) at Indralok near Golden Nest. His body has been sent for post-mortem and wife Suzanne has been in shock since then. Akhil has also been a part of several TV shows like Bhanwar, Uttaran (Umed Singh Bundela), Udaan, CID, Shrimaan Shrimati, Bharat Ek Koj, Rajani, and many others. His film work includes Don, Well Don Abba, Hazaaron Khwaishein Aisi and more. He also made a mark by taking on the character of Umed Singh bundela in the popular show \"Uttaran.\" \n",
      "Akhil was my soulmate, my better half... I don't know what I'll do without him: Wife Suzanne Bernert\n",
      "Actor Akhil Mishra, known for his roles in films like 3 Idiots and Don, passed away at the age of 67. Mishra's wife, actress Suzanne Bernert, confirmed that he fell from a stool in their home.\n",
      "Akhil Mishra's wife, actress Suzanne Bernert, confirmed that he fell from a stool in their home. He is known for films like 3 Idiots, Don and has also been part of TV shows like Do Dil Bandhe Ek Dori Se, Uttaran and Sea Hawks. The Yeh Rishta Kya Kehlata Hain actress and Akhil tied the knot in 2009. He was still communicating and was telling them, 'I love Suzanne and I don't want to go to the hospital', but in the hospital, we got to know that he had an internal haemorrhage and there was a lot of blood loss and the doctors couldn't save him. A postmortem was done after which the last rites were performed. \"I don't know what I will do without him, I feel very lost,\" she said. He had stopped helping with household chores when he was unwell but as he felt better, he insisted on helping me. \n",
      "1\n",
      "588\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a unbiased professional news article for:\n",
      "\n",
      "\n",
      "    3 Idiots actor Akhil Mishra passes away in an accident\n",
      "Renowned actor Akhil Mishra, widely recognized for his portrayal of librarian Dubey in the Aamir Khan starrer \"3 Idiots,\" has passed away. ETimes TV has exclusively learnt about his demise. Sources have revealed that his wife, the actress Suzanne Bernert, was away in Hyderabad for a film shoot when this tragic incident occurred.\n",
      "Akhil Mishra, who played Librarian Dubey in Aamir Khan starrer ‘3 Idiots’ passes away in a SHOCKING incident. His wife and actress Suzanne Bernert was in Hyderabad for a shoot when the incident happened. Suzanna shared, ‘My heart is broken, my second half is gone’ His last rites are going to be held at 3.30 pm today (September 21) at Indralok near Golden Nest. His body has been sent for post-mortem and wife Suzanne has been in shock since then. Akhil has also been a part of several TV shows like Bhanwar, Uttaran (Umed Singh Bundela), Udaan, CID, Shrimaan Shrimati, Bharat Ek Koj, Rajani, and many others. His film work includes Don, Well Don Abba, Hazaaron Khwaishein Aisi and more. He also made a mark by taking on the character of Umed Singh bundela in the popular show \"Uttaran.\" \n",
      "Akhil was my soulmate, my better half... I don't know what I'll do without him: Wife Suzanne Bernert\n",
      "Actor Akhil Mishra, known for his roles in films like 3 Idiots and Don, passed away at the age of 67. Mishra's wife, actress Suzanne Bernert, confirmed that he fell from a stool in their home.\n",
      "Akhil Mishra's wife, actress Suzanne Bernert, confirmed that he fell from a stool in their home. He is known for films like 3 Idiots, Don and has also been part of TV shows like Do Dil Bandhe Ek Dori Se, Uttaran and Sea Hawks. The Yeh Rishta Kya Kehlata Hain actress and Akhil tied the knot in 2009. He was still communicating and was telling them, 'I love Suzanne and I don't want to go to the hospital', but in the hospital, we got to know that he had an internal haemorrhage and there was a lot of blood loss and the doctors couldn't save him. A postmortem was done after which the last rites were performed. \"I don't know what I will do without him, I feel very lost,\" she said. He had stopped helping with household chores when he was unwell but as he felt better, he insisted on helping me.\n",
      "\n",
      "\n",
      "    CONSCISE UNBIASED detailed news article with at least 500 words:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Chain type: StuffDocumentsChain\n",
      "Run time: 36.07800000000134\n",
      "Summary: Renowned actor Akhil Mishra, best known for his role as librarian Dubey in the blockbuster film \"3\n",
      "Idiots,\" has tragically passed away in an accident. The news of his demise was exclusively reported\n",
      "by ETimes TV. According to sources, Mishra's wife, actress Suzanne Bernert, was away in Hyderabad\n",
      "for a film shoot when the incident occurred.  Akhil Mishra, who portrayed the memorable character of\n",
      "Librarian Dubey in the critically acclaimed film \"3 Idiots,\" has left his fans and the film industry\n",
      "in shock with his sudden demise. The actor's wife, Suzanne Bernert, who is also an actress, was away\n",
      "in Hyderabad for a shoot when the tragic incident took place. Devastated by the news, Bernert\n",
      "shared, \"My heart is broken, my second half is gone.\"  The last rites of Akhil Mishra are scheduled\n",
      "to be held at 3.30 pm today (September 21) at Indralok near Golden Nest. His body has been sent for\n",
      "post-mortem, and his wife Suzanne has been in a state of shock since the incident occurred. Mishra's\n",
      "contributions to the entertainment industry extend beyond his role in \"3 Idiots.\" He has also\n",
      "appeared in popular TV shows like \"Bhanwar,\" \"Uttaran,\" \"Udaan,\" \"CID,\" \"Shrimaan Shrimati,\" \"Bharat\n",
      "Ek Koj,\" \"Rajani,\" and many others. His filmography includes notable movies such as \"Don,\" \"Well Don\n",
      "Abba,\" and \"Hazaaron Khwaishein Aisi.\"  One of Mishra's most memorable roles was that of Umed Singh\n",
      "Bundela in the popular TV show \"Uttaran.\" His portrayal of the character left a lasting impact on\n",
      "the audience and showcased his versatility as an actor. Mishra's talent and dedication to his craft\n",
      "earned him a special place in the hearts of his fans and colleagues.  The circumstances surrounding\n",
      "Mishra's untimely demise are both shocking and heartbreaking. According to his wife Suzanne Bernert,\n",
      "Mishra fell from a stool in their home, leading to his tragic accident. The couple had been married\n",
      "since 2009 and shared a deep bond. Bernert expressed her grief, saying, \"Akhil was my soulmate, my\n",
      "better half... I don't know what I'll do without him.\"  Mishra's filmography and television\n",
      "appearances speak volumes about his talent and versatility as an actor. He effortlessly portrayed a\n",
      "wide range of characters, leaving a lasting impression on the audience. His performances in films\n",
      "like \"3 Idiots\" and \"Don\" showcased his ability to bring depth and authenticity to his roles.  In\n",
      "addition to his successful acting career, Mishra was known for his humility and dedication to his\n",
      "craft. Colleagues and friends remember him as a warm and kind-hearted individual who always brought\n",
      "positivity to the sets. His sudden departure has left a void in the industry that will be difficult\n",
      "to fill.  The news of Akhil Mishra's passing has sent shockwaves through the entertainment industry,\n",
      "with fans and colleagues expressing their condolences and sharing fond memories of the talented\n",
      "actor. The loss of such a talented individual is a reminder of the fragility of life and the\n",
      "importance of cherishing every moment.  As the industry mourns the loss of Akhil Mishra, his legacy\n",
      "as a versatile actor and a kind-hearted individual will continue to live on. His contributions to\n",
      "the world of entertainment will be remembered and celebrated for years to come. Our thoughts and\n",
      "prayers go out to his family and loved ones during this difficult time.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "gpt_35_turbo_max_tokens = 4097\n",
    "verbose = True\n",
    "prompt_template = \"\"\"Write a unbiased professional news article for:\n",
    "\n",
    "\n",
    "    {text}\n",
    "\n",
    "\n",
    "    CONSCISE UNBIASED detailed news article with at least 500 words:\"\"\"\n",
    "OPENAI_API_KEY= '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'\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY, model_name=model_name)\n",
    "\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:    \n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    articles_grouped_l1(where: {articles_in_group: {_gt: 1}, _and: {articles_in_group: {_lt: 10}}}, limit: $limit, offset: $offset) {\n",
    "        article_ids\n",
    "    }\n",
    "    }\n",
    "'''\n",
    "graphql_grquery_article = '''\n",
    "query MyQuery($article_id: bigint!) {\n",
    "  rss1_articals(where: {id: {_eq: $article_id}}) {\n",
    "    title\n",
    "    summary\n",
    "    rss1_articles_detail {\n",
    "      summary\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "offset = 1\n",
    "variables = {\n",
    "\"limit\": 1,\n",
    "\"offset\": offset\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "for response in response_data['data']['articles_grouped_l1']:\n",
    "    llm_text = ''\n",
    "    for article in response['article_ids']:\n",
    "        print(article)\n",
    "        article_variables = {\n",
    "        \"article_id\": article\n",
    "        }\n",
    "        article_response_data = query_hasura_graphql(endpoint, admin_key, graphql_grquery_article, article_variables)\n",
    "        llm_text = llm_text + \"\\n\" +article_response_data['data']['rss1_articals'][0]['title'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['summary'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['rss1_articles_detail']['summary']\n",
    "    print(llm_text)\n",
    "\n",
    "\n",
    "    texts = text_splitter.split_text(llm_text)\n",
    "\n",
    "    docs = [Document(page_content=t) for t in texts]\n",
    "    print(len(docs))\n",
    "    \n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "    num_tokens = num_tokens_from_string(llm_text, model_name)\n",
    "    print(num_tokens)\n",
    "    if num_tokens < gpt_35_turbo_max_tokens:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt, verbose=verbose)\n",
    "    else:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=prompt, combine_prompt=prompt, verbose=verbose)\n",
    "\n",
    "    start_time = monotonic()\n",
    "    summary = chain.run(docs)\n",
    "\n",
    "    print(f\"Chain type: {chain.__class__.__name__}\")\n",
    "    print(f\"Run time: {monotonic() - start_time}\")\n",
    "    print(f\"Summary: {textwrap.fill(summary, width=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "689\n",
      "61\n",
      "694\n",
      "\n",
      "Putin to meet China's foreign minister in Russia: Kremlin\n",
      "According to the Kremlin, Russian President Vladimir Putin will host China's foreign minister Wang Yi for discussions in Saint Petersburg on Wednesday. The senior Chinese ambassador is in Russia for a four-day visit, the latest in a series of high-level meetings between Moscow and Beijing.\n",
      "Vladimir Putin will host China's foreign minister Wang Yi for discussions in Saint Petersburg. The senior Chinese ambassador is in Russia for a four-day visit. It is the latest in a series of high-level meetings between Moscow and Beijing. The Kremlin has sought to deepen ties with China after the start of its Ukraine offensive, which has thrown Moscow into increasing isolation. China has tried to position itself as a neutral party in the Ukraine conflict, while offering Moscow a vital diplomatic and financial lifeline. In March, China's leader Xi Jinping made a state visit to Moscow, where he and Putin sought to showcase a united front against Western countries. The top Chinese diplomat met Russian Foreign Minister Sergei Lavrov on Monday. According to a Chinese state media readout, Wang reiterated Beijing's position paper on the Ukraine Conflict. It called for peace talks but was met with scepticism by the United States and NATO when it was released earlier this year. Russia and China frequently tout their \"no limits\" partnership and economic and military cooperation. \n",
      "Russia hails ‘similarity’ of China’s position on U.S., Ukraine\n",
      "Russia and China frequently tout their \"no limits\" partnership and economic and military cooperation\n",
      "Russia hails ‘similarity’ of China’s position on U.S., Ukraine. Russia and China frequently tout their \"no limits\" partnership and economic and military cooperation. China's Wang Yi kicked off a four-day visit to Moscow with a meeting with Russian Foreign Minister Sergei Lavrov. Wang reiterated Beijing's position paper on the Ukraine conflict, which called for peace talks but was met with scepticism by the United States and NATO when it was released earlier this year. During his visit, Mr. Wang is due to hold security consultations at the invitation of Nikolai Patrushev, secretary of Russia's security council. President Xi Jinping made a state Visit to Moscow in March and declared that relations between the two countries were entering a new era. An aide to Vladimir Putin said in July that the Russian President was planning to visit China in October. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. For support in the UK, call the National Suicide Prevention Lifeline at 1-800-273-8255 or visit www.suicidepreventionlifeline.org. For help in the U.K., contact the National suicide Prevention Line on 1-844-788-88 or click here. \n",
      "Beijing, Moscow must deepen cooperation: China foreign minister\n",
      "Beijing's top diplomat told President Vladimir Putin that China and Russia must work to strengthen cooperation in the face of a \"complex international situation\", Chinese state media reported Thursday. \"Both sides need to strengthen their multilateral strategic cooperation, protect their legitimate rights and interests, and make new efforts to promote the international order toward fairness and justice,\" he added.\n",
      "Beijing's top diplomat told President Vladimir Putin that China and Russia must work to strengthen cooperation in the face of a \"complex international situation\" Wang Yi said the \"world is rapidly moving toward multipolarity\" Putin, in response, told Wang \"our positions coincide regarding the emergence of a multipolar world\", according to a readout from the Kremlin. The Kremlin has sought to deepen ties with China after the start of its Ukraine offensive, which has thrown Moscow into increasing isolation. China has tried to position itself as a neutral party in the Ukraine conflict, while offering Moscow a vital diplomatic and financial lifeline. The two countries describe each other as strategic allies, with both countries frequently touting their \"no limits\" partnership and economic and military cooperation. They came even closer after the started of Russia's offensive in Ukraine in February last year, which China has refused to condemn. The Russian leader accepted an invitation to visit China next month, at which the Chinese foreign minister said he was looking forward to meeting him. \n",
      "Putin and Xi to meet in Beijing in October, Russia says\n",
      "In Beijing, Vladimir Putin will take part in a forum on China's Belt and Road Initiative\n",
      "Russian President Vladimir Putin will travel to Beijing in October for talks with China's Xi Jinping. In Beijing, Mr. Putin will take part in a forum on China's Belt and Road Initiative. \"We look forward to thorough bilateral talks,\" Russia's Security Council secretary says in a meeting in Moscow with China’s top diplomat, Wang Yi. The two leaders will meet in October, the secretary of the Security Council says. The talks will take place at the Diaoyutai State Guest House in Beijing. \n",
      "1\n",
      "988\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a unbiased professional news article for:\n",
      "\n",
      "\n",
      "    Putin to meet China's foreign minister in Russia: Kremlin\n",
      "According to the Kremlin, Russian President Vladimir Putin will host China's foreign minister Wang Yi for discussions in Saint Petersburg on Wednesday. The senior Chinese ambassador is in Russia for a four-day visit, the latest in a series of high-level meetings between Moscow and Beijing.\n",
      "Vladimir Putin will host China's foreign minister Wang Yi for discussions in Saint Petersburg. The senior Chinese ambassador is in Russia for a four-day visit. It is the latest in a series of high-level meetings between Moscow and Beijing. The Kremlin has sought to deepen ties with China after the start of its Ukraine offensive, which has thrown Moscow into increasing isolation. China has tried to position itself as a neutral party in the Ukraine conflict, while offering Moscow a vital diplomatic and financial lifeline. In March, China's leader Xi Jinping made a state visit to Moscow, where he and Putin sought to showcase a united front against Western countries. The top Chinese diplomat met Russian Foreign Minister Sergei Lavrov on Monday. According to a Chinese state media readout, Wang reiterated Beijing's position paper on the Ukraine Conflict. It called for peace talks but was met with scepticism by the United States and NATO when it was released earlier this year. Russia and China frequently tout their \"no limits\" partnership and economic and military cooperation. \n",
      "Russia hails ‘similarity’ of China’s position on U.S., Ukraine\n",
      "Russia and China frequently tout their \"no limits\" partnership and economic and military cooperation\n",
      "Russia hails ‘similarity’ of China’s position on U.S., Ukraine. Russia and China frequently tout their \"no limits\" partnership and economic and military cooperation. China's Wang Yi kicked off a four-day visit to Moscow with a meeting with Russian Foreign Minister Sergei Lavrov. Wang reiterated Beijing's position paper on the Ukraine conflict, which called for peace talks but was met with scepticism by the United States and NATO when it was released earlier this year. During his visit, Mr. Wang is due to hold security consultations at the invitation of Nikolai Patrushev, secretary of Russia's security council. President Xi Jinping made a state Visit to Moscow in March and declared that relations between the two countries were entering a new era. An aide to Vladimir Putin said in July that the Russian President was planning to visit China in October. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. For support in the UK, call the National Suicide Prevention Lifeline at 1-800-273-8255 or visit www.suicidepreventionlifeline.org. For help in the U.K., contact the National suicide Prevention Line on 1-844-788-88 or click here. \n",
      "Beijing, Moscow must deepen cooperation: China foreign minister\n",
      "Beijing's top diplomat told President Vladimir Putin that China and Russia must work to strengthen cooperation in the face of a \"complex international situation\", Chinese state media reported Thursday. \"Both sides need to strengthen their multilateral strategic cooperation, protect their legitimate rights and interests, and make new efforts to promote the international order toward fairness and justice,\" he added.\n",
      "Beijing's top diplomat told President Vladimir Putin that China and Russia must work to strengthen cooperation in the face of a \"complex international situation\" Wang Yi said the \"world is rapidly moving toward multipolarity\" Putin, in response, told Wang \"our positions coincide regarding the emergence of a multipolar world\", according to a readout from the Kremlin. The Kremlin has sought to deepen ties with China after the start of its Ukraine offensive, which has thrown Moscow into increasing isolation. China has tried to position itself as a neutral party in the Ukraine conflict, while offering Moscow a vital diplomatic and financial lifeline. The two countries describe each other as strategic allies, with both countries frequently touting their \"no limits\" partnership and economic and military cooperation. They came even closer after the started of Russia's offensive in Ukraine in February last year, which China has refused to condemn. The Russian leader accepted an invitation to visit China next month, at which the Chinese foreign minister said he was looking forward to meeting him. \n",
      "Putin and Xi to meet in Beijing in October, Russia says\n",
      "In Beijing, Vladimir Putin will take part in a forum on China's Belt and Road Initiative\n",
      "Russian President Vladimir Putin will travel to Beijing in October for talks with China's Xi Jinping. In Beijing, Mr. Putin will take part in a forum on China's Belt and Road Initiative. \"We look forward to thorough bilateral talks,\" Russia's Security Council secretary says in a meeting in Moscow with China’s top diplomat, Wang Yi. The two leaders will meet in October, the secretary of the Security Council says. The talks will take place at the Diaoyutai State Guest House in Beijing.\n",
      "\n",
      "\n",
      "    CONSCISE UNBIASED detailed news article with at least 500 words:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Chain type: StuffDocumentsChain\n",
      "Run time: 27.625\n",
      "Summary: Putin to meet China's foreign minister in Russia: Kremlin  Russian President Vladimir Putin is set\n",
      "to host China's foreign minister Wang Yi for discussions in Saint Petersburg on Wednesday, according\n",
      "to the Kremlin. Wang is in Russia for a four-day visit, marking the latest in a series of high-level\n",
      "meetings between Moscow and Beijing.  The Kremlin has been actively seeking to deepen ties with\n",
      "China following the start of its Ukraine offensive, which has resulted in increasing isolation for\n",
      "Moscow. China, on the other hand, has positioned itself as a neutral party in the Ukraine conflict\n",
      "while offering diplomatic and financial support to Russia.  In March, Chinese leader Xi Jinping made\n",
      "a state visit to Moscow, during which he and Putin aimed to showcase a united front against Western\n",
      "countries. This visit further solidified the partnership between the two nations.  Wang's visit to\n",
      "Russia includes a meeting with Russian Foreign Minister Sergei Lavrov, where he reiterated Beijing's\n",
      "position paper on the Ukraine conflict. The paper called for peace talks but was met with skepticism\n",
      "by the United States and NATO when it was released earlier this year.  Russia and China frequently\n",
      "emphasize their \"no limits\" partnership, highlighting their economic and military cooperation. This\n",
      "partnership has become even more significant since Russia's offensive in Ukraine, as China has\n",
      "refused to condemn Russia's actions.  The meeting between Putin and Wang is expected to further\n",
      "strengthen the cooperation between Russia and China. Both leaders have expressed the need for closer\n",
      "ties in the face of a complex international situation. Wang emphasized the importance of protecting\n",
      "their legitimate rights and interests and promoting a fair and just international order.  The\n",
      "Kremlin has been actively working to deepen its relationship with China, as it seeks to counter the\n",
      "increasing isolation resulting from its actions in Ukraine. China, on the other hand, sees an\n",
      "opportunity to strengthen its position on the global stage by aligning itself with Russia.  The two\n",
      "countries describe each other as strategic allies and have been actively promoting their economic\n",
      "and military cooperation. This partnership has been further solidified by their shared opposition to\n",
      "Western countries' actions and their desire for a multipolar world.  In October, Putin is set to\n",
      "travel to Beijing for talks with Chinese President Xi Jinping. The meeting will take place during a\n",
      "forum on China's Belt and Road Initiative, a major infrastructure project aimed at enhancing\n",
      "connectivity and trade between Asia, Europe, and Africa.  The upcoming meeting between Putin and Xi\n",
      "is expected to further deepen the cooperation between Russia and China. Both leaders have expressed\n",
      "their eagerness for thorough bilateral talks and are looking forward to discussing various issues of\n",
      "mutual interest.  Overall, the meeting between Putin and Wang, as well as the upcoming meeting\n",
      "between Putin and Xi, highlight the growing partnership between Russia and China. Both countries see\n",
      "the need to strengthen their cooperation in the face of a complex international situation and are\n",
      "actively working towards that goal.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "import tiktoken\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap\n",
    "from time import monotonic\n",
    "\n",
    "\n",
    "gpt_35_turbo_max_tokens = 4097\n",
    "verbose = True\n",
    "prompt_template = \"\"\"Write a unbiased professional news article for:\n",
    "\n",
    "\n",
    "    {text}\n",
    "\n",
    "\n",
    "    CONSCISE UNBIASED detailed news article with at least 500 words:\"\"\"\n",
    "OPENAI_API_KEY= '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'\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY, model_name=model_name)\n",
    "\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:    \n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    articles_grouped_l1(where: {articles_in_group: {_gt: 3}, _and: {articles_in_group: {_lt: 10}}}, limit: $limit, offset: $offset) {\n",
    "        article_ids\n",
    "    }\n",
    "    }\n",
    "'''\n",
    "graphql_grquery_article = '''\n",
    "query MyQuery($article_id: bigint!) {\n",
    "  rss1_articals(where: {id: {_eq: $article_id}}) {\n",
    "    title\n",
    "    summary\n",
    "    rss1_articles_detail {\n",
    "      summary\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "offset = 0\n",
    "variables = {\n",
    "\"limit\": 1,\n",
    "\"offset\": offset\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "for response in response_data['data']['articles_grouped_l1']:\n",
    "    llm_text = ''\n",
    "    for article in response['article_ids']:\n",
    "        print(article)\n",
    "        article_variables = {\n",
    "        \"article_id\": article\n",
    "        }\n",
    "        article_response_data = query_hasura_graphql(endpoint, admin_key, graphql_grquery_article, article_variables)\n",
    "        llm_text = llm_text + \"\\n\" +article_response_data['data']['rss1_articals'][0]['title'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['summary'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['rss1_articles_detail']['summary']\n",
    "    print(llm_text)\n",
    "\n",
    "\n",
    "    texts = text_splitter.split_text(llm_text)\n",
    "\n",
    "    docs = [Document(page_content=t) for t in texts]\n",
    "    print(len(docs))\n",
    "    \n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "    num_tokens = num_tokens_from_string(llm_text, model_name)\n",
    "    print(num_tokens)\n",
    "    if num_tokens < gpt_35_turbo_max_tokens:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt, verbose=verbose)\n",
    "    else:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=prompt, combine_prompt=prompt, verbose=verbose)\n",
    "\n",
    "    start_time = monotonic()\n",
    "    summary = chain.run(docs)\n",
    "\n",
    "    print(f\"Chain type: {chain.__class__.__name__}\")\n",
    "    print(f\"Run time: {monotonic() - start_time}\")\n",
    "    print(f\"Summary: {textwrap.fill(summary, width=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "import tiktoken\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap\n",
    "from time import monotonic\n",
    "\n",
    "\n",
    "gpt_35_turbo_max_tokens = 4097\n",
    "verbose = True\n",
    "prompt_template = \"\"\"Write a unbiased professional news article for:\n",
    "\n",
    "\n",
    "    {text}\n",
    "\n",
    "\n",
    "    CONSCISE UNBIASED detailed news article with at least 500 words:\"\"\"\n",
    "OPENAI_API_KEY= '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'\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY, model_name=model_name)\n",
    "\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:    \n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    articles_grouped_l1(where: {articles_in_group: {_gt: 4}, _and: {articles_in_group: {_lt: 10}}}, limit: $limit, offset: $offset) {\n",
    "        article_ids\n",
    "    }\n",
    "    }\n",
    "'''\n",
    "graphql_grquery_article = '''\n",
    "query MyQuery($article_id: bigint!) {\n",
    "  rss1_articals(where: {id: {_eq: $article_id}}) {\n",
    "    title\n",
    "    summary\n",
    "    rss1_articles_detail {\n",
    "      summary\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "offset = 1\n",
    "variables = {\n",
    "\"limit\": 1,\n",
    "\"offset\": offset\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "for response in response_data['data']['articles_grouped_l1']:\n",
    "    llm_text = ''\n",
    "    for article in response['article_ids']:\n",
    "        print(article)\n",
    "        article_variables = {\n",
    "        \"article_id\": article\n",
    "        }\n",
    "        article_response_data = query_hasura_graphql(endpoint, admin_key, graphql_grquery_article, article_variables)\n",
    "        llm_text = llm_text + \"\\n\" +article_response_data['data']['rss1_articals'][0]['title'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['summary'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['rss1_articles_detail']['summary']\n",
    "    print(llm_text)\n",
    "\n",
    "\n",
    "    texts = text_splitter.split_text(llm_text)\n",
    "\n",
    "    docs = [Document(page_content=t) for t in texts]\n",
    "    print(len(docs))\n",
    "    \n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "    num_tokens = num_tokens_from_string(llm_text, model_name)\n",
    "    print(num_tokens)\n",
    "    if num_tokens < gpt_35_turbo_max_tokens:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt, verbose=verbose)\n",
    "    else:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=prompt, combine_prompt=prompt, verbose=verbose)\n",
    "\n",
    "    start_time = monotonic()\n",
    "    summary = chain.run(docs)\n",
    "\n",
    "    print(f\"Chain type: {chain.__class__.__name__}\")\n",
    "    print(f\"Run time: {monotonic() - start_time}\")\n",
    "    print(f\"Summary: {textwrap.fill(summary, width=100)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "Como a fruta mais fedida do mundo pode ajudar a gerar energia para seu telefone\n",
      "\n",
      "Elas são o coração da tecnologia portátil moderna. As baterias de íon de lítio transformaram nossa capacidade de armazenar e transportar energia e, por sua vez, revolucionaram os dispositivos que usamos.\n",
      "\n",
      "Comercializadas pela Sony em 1991, quando a empresa buscava uma solução para a duração limitada da bateria de suas câmeras de vídeo portáteis, elas fornecem energia a muitos dos gadgets que usamos hoje - de smartphones e laptops a escovas de dente elétricas e aspiradores de pó de mão. No fim do ano passado, os três cientistas por trás de sua invenção ganharam o Prêmio Nobel de Química por possibilitar essa revolução técnica.\n",
      "\n",
      "E nossa necessidade por elas só tende a crescer. Os veículos elétricos dependem de baterias de íon-lítio como um substituto para os combustíveis fósseis que usamos atualmente para abastecer nossos carros. Como as fontes de energia renováveis constituem a maior parte do suprimento de eletricidade em todo o mundo, é provável que sejam necessários enormes bancos de baterias para armazenar o excesso de energia quando o vento não sopra ou o Sol não está brilhando.\n",
      "\n",
      "Em todo o mundo, mais de 7 bilhões de baterias de íon-lítio são vendidas a cada ano e espera-se que esse número cresça para mais de 15 bilhões até 2027.\n",
      "\n",
      "Mas, como sabemos por nossos telefones, que armazenam cada vez menos energia à medida que envelhecem, as baterias de íon de lítio apresentam limitações. Com o tempo, sua capacidade de reter uma carga diminui, o que significa que elas armazenam menos energia.\n",
      "\n",
      "Em climas extremamente quentes ou frios, seu desempenho também cai. E também existem preocupações em torno de sua segurança e sustentabilidade - elas podem pegar fogo e explodir sob certas condições, enquanto a mineração dos metais necessários para fabricá-las tem um alto custo social e ambiental.\n",
      "\n",
      "Isso vem estimulando cientistas de todo o mundo a tentar desenvolver novos tipos de bateria que possam superar esses obstáculos. Ao aproveitar uma variedade de materiais, de diamantes a frutas super fedidas, eles esperam encontrar novas maneiras de impulsionar as tecnologias do futuro.\n",
      "\n",
      "As baterias de íon-lítio funcionam permitindo que partículas (íons) de lítio carregadas movam eletricidade de uma extremidade à outra, passando por um eletrólito líquido no meio. Uma das coisas que torna as baterias de íon de lítio tão atraentes é sua \"densidade de energia\" - a energia máxima que uma bateria pode armazenar proporcionalmente a seu volume - que é uma das mais altas de qualquer bateria disponível comercialmente no mercado. Elas também podem fornecer tensões mais altas do que outras tecnologias de bateria.\n",
      "\n",
      "As baterias são essencialmente feitas de três componentes principais - um eletrodo negativo (ânodo), um eletrodo positivo (cátodo) e um eletrólito entre eles. As funções dos eletrodos alternam entre cátodo e ânodo, dependendo se a bateria está carregando ou descarregando.\n",
      "\n",
      "Em baterias de íon de lítio, o cátodo é normalmente feito de um óxido de metal e outro metal. Ao carregar, os íons de lítio e elétrons se movem do cátodo para o ânodo, onde são \"armazenados\" como potencial eletroquímico. Isso ocorre por meio de uma série de reações químicas no eletrólito que são acionadas pela energia elétrica que flui do circuito de carga.\n",
      "\n",
      "Quando uma bateria está em uso, os íons de lítio fluem na direção oposta do ânodo para o cátodo através do eletrólito, enquanto os elétrons fluem através do circuito elétrico do dispositivo em que a bateria está instalada, fornecendo energia.\n",
      "\n",
      "Ao longo dos anos, ajustes nos materiais usados no cátodo e no ânodo ajudaram a melhorar a capacidade e a densidade de energia das baterias de íons de lítio, mas as melhorias mais substanciais foram na queda do custo das baterias.\n",
      "\n",
      "\"Chegou a um ponto em que a química desenvolvida 35 anos atrás se estabilizou\", diz Mauro Pasta, professor-associado de materiais da Universidade de Oxford, no Reino Unido, e líder de projeto na The Faraday Institution, que está trabalhando na próxima fase das baterias de íon-lítio.\n",
      "\n",
      "Seu objetivo é aumentar a densidade de energia das baterias de íon de lítio e, ao mesmo tempo, ampliar sua eficiência para que não percam energia com cargas e descargas repetidas.\n",
      "\n",
      "Para fazer isso, o professor Pasta está focado em substituir o fluido eletrolítico altamente inflamável encontrado em baterias de íon-lítio modernas por um sólido feito de cerâmica. O uso de um sólido reduz o risco de combustão de eletrólitos no caso de uma célula curta ou instável, que estava por trás do recall de 2017 da Samsung de 2,5 milhões de Galaxy Note 7s após uma série de incêndios por problemas na bateria.\n",
      "\n",
      "Isso é importante para a segurança do usuário e de seu entorno, pois até mesmo o eletrólito de gel de polímero encontrado na maioria de nossos eletrônicos portáteis ainda é inflamável.\n",
      "\n",
      "Essa bateria de estado sólido também possibilita o uso de metal de lítio denso em vez do ânodo de grafite, o que aumenta significativamente a quantidade de energia que pode armazenar no processo. Neste sentido, pode ter implicações enormes no futuro dos automóveis.\n",
      "\n",
      "No momento, todo veículo elétrico contém o equivalente a milhares de baterias de iPhone. Como os veículos elétricos parecem destinados a substituir aqueles movidos a combustíveis fósseis em muitos países nos próximos anos, a mudança para baterias de estado sólido significaria viagens mais longas e mais tempo entre as recargas.\n",
      "\n",
      "Nossa sede por bateria só tende a crescer nos próximos anos, ao passo que cada vez mais meios de transporte se tornam elétricos e a variedade de parafernálias eletrônicas portáteis em nossas vidas só aumenta. Sendo assim, devemos procurar alternativas ao lítio que possam diminuir o impacto no meio ambiente?\n",
      "\n",
      "A região do \"Triângulo de Lítio\" dos Andes - que inclui partes da Argentina, Bolívia e Chile - contém pouco mais da metade dos recursos naturais mundiais do metal. Mas extraí-lo requer água - muita água. Na região do Salar de Atacama, no Chile, cerca de 1 milhão de litros de água são usados no processo de mineração para produzir apenas 900 kg de lítio. O processo envolve a purificação dos sais ricos em metais dissolvendo-os progressivamente em água, filtrando e evaporando a salmoura até que o sal de lítio puro seja obtido. Órgãos ambientais administrados pelo governo chileno, no entanto, alertaram que a mineração de metais - principalmente de lítio e cobre - na região está usando mais água do que é substituída por neve e chuva.\n",
      "\n",
      "Para contornar isso, pesquisadores do Instituto de Tecnologia de Karlsruhe estão trabalhando em baterias que usam diferentes metais no ânodo, como cálcio ou magnésio. O cálcio é o quinto elemento mais abundante na crosta terrestre e é improvável que sofra dos mesmos problemas de abastecimento que o lítio, mas as pesquisas para melhorar o desempenho das baterias que o utilizam ainda estão engatinhando. O magnésio também apresenta resultados iniciais promissores, principalmente em termos de densidade energética, e há planos de comercialização no futuro.\n",
      "\n",
      "Mas há quem esteja buscando alternativas em materiais mais amplamente disponíveis, incluindo a madeira, por exemplo.\n",
      "\n",
      "Liangbing Hu, diretor do Centro de Inovação de Materiais da Universidade de Maryland, nos Estados Unidos, construiu recentemente uma bateria usando pedaços de madeira porosos e furados como eletrodos, dentro dos quais íons metálicos reagem para gerar uma carga elétrica. A madeira é abundante, de baixo custo e leve, e apresenta alto potencial de desempenho em baterias. As baterias mais recentes foram produzidas após anos de pesquisa sobre a capacidade desse material de armazenar energia, incluindo o revestimento de fibras de celulose de madeira em estanho.\n",
      "\n",
      "Como a madeira evoluiu naturalmente para ser permeável aos nutrientes conforme eles são transportados pela planta, o material faz eletrodos com a capacidade de armazenar íons de metal sem o risco de se espandir ou encolher perigosamente, como pode ocorrer com os eletrodos de bateria de íon de lítio.\n",
      "\n",
      "Embora a equipe de Hu preveja que as baterias à base de madeira vão poder ser usadas em nossos eletrônicos portáteis, bem como no armazenamento de energia em grande escala em determinado momento, ainda não poderemos carregar nossos laptops com elas, pois ainda estão sendo testadas em laboratórios.\n",
      "\n",
      "Essas baterias perdem a capacidade de armazenar uma carga relativamente rápida - um protótipo só conseguia manter 61% de sua capacidade inicial após 100 ciclos de recarga. No momento, a quantidade de madeira usada é de vários centímetros de largura e comprimento, e as baterias podem ser empilhadas ou conectadas para aplicações em larga escala, o que pode eventualmente ser útil para armazenar energia em casas ou outros edifícios.\n",
      "\n",
      "O lítio não é o único metal encontrado na maioria das baterias modernas - a maioria também usa cobalto em combinação com lítio no cátodo. A mineração de cobalto gera um impacto tóxico que afeta a saúde das comunidades que vivem no entorno das minas e também o meio ambiente. A mineração de cobalto também é prejudicada pelo uso de trabalho infantil, especialmente na República Democrática do Congo, na África, país que abriga mais da metade das minas de cobalto do mundo. As principais empresas de tecnologia, incluindo Apple, Tesla e Microsoft, foram recentemente processadas por mortes na mineração de cobalto.\n",
      "\n",
      "\"Todo mundo está carregando uma bateria de íon de lítio extraída por crianças\", diz Jodie Lutkenhaus, engenheira química da Texas A&M University, nos Estados Unidos.\n",
      "\n",
      "Isso a inspirou a desenvolver alternativas para essas \"baterias de sangue\" usando proteínas, as moléculas complexas criadas e usadas por organismos vivos. Os ânodos das baterias tendem a ser feitos de grafite e os cátodos são feitos de óxidos de metal que contêm elementos como o cobalto. Se eles puderem ser substituídos por materiais orgânicos para ambos os eletrodos ativos, isso significa que o cobalto não precisará mais ser extraído.\n",
      "\n",
      "Isso não apenas descarta a necessidade de metais tóxicos que precisam ser extraídos do solo, mas também lança luz sobre outro legado ambiental das baterias de íon-lítio. Se eliminados após o uso em aterros sanitários, os metais e eletrólitos do íon de lítio podem vazar para o meio ambiente, causando mais danos. Atualmente, apenas cerca de 5% das baterias de íon-lítio usadas nos 1,5 bilhão de smartphones vendidos a cada ano são recicladas.\n",
      "\n",
      "Desenvolvida em colaboração com sua colega Karen Wooley, na Texas A&M University, a bateria de proteína de Lutkenhaus é a primeira célula de energia do mundo que se degrada a partir de sua dissolução em um ácido, o que significa que pode ser facilmente quebrada e usada novamente.\n",
      "\n",
      "Embora ela ainda não possa competir com o íon de lítio - só fornece até 1,5 V por cerca de 50 ciclos de recarga antes de perder potência - faz parte de uma série de iniciativas sobre como a sustentabilidade está sendo levada em conta para o design de novas baterias.\n",
      "\n",
      "Super fruta\n",
      "Em outro desdobramento, um grupo de pesquisadores não está apenas tentando encontrar novas maneiras de fornecer energia a nossos dispositivos, mas também lidar com o problema do desperdício de alimentos ao mesmo tempo.\n",
      "\n",
      "Vincent Gomes, engenheiro químico da Universidade de Sydney, e sua equipe, incluindo Labna Shabnam, estão transformando os resíduos da fruta mais fedorenta do mundo, o durião, e da maior fruta do mundo, a jaca, em um supercapacitor que pode carregar telefones celulares, tablets e laptops em minutos.\n",
      "\n",
      "Os supercapacitores são uma forma alternativa de armazenamento de energia. Eles agem como reservatórios, capazes de carregar rapidamente e, em seguida, descarregar energia em rajadas. Eles tendem a ser feitos de materiais caros como o grafeno, mas a equipe de Gomes transformou partes não comestíveis de durião e jaca em aerogéis de carbono - sólidos superleves porosos - com propriedades \"excepcionais\" de armazenamento natural de energia. Eles aqueceram, liofilizaram e depois assaram o núcleo esponjoso não comestível de cada fruta em um forno a temperaturas de mais de 1.500 °C. As estruturas pretas, altamente porosas e ultraleves que resultaram desse processo poderiam ser transformadas em eletrodos de um supercapacitor de baixo custo.\n",
      "\n",
      "Os supercapacitores podem ser carregados em 30 segundos e usados para alimentar uma variedade de dispositivos.\n",
      "\n",
      "\"Ser capaz de carregar um telefone celular em um minuto é incrível\", diz Shabnam.\n",
      "\n",
      "O sonho dos pesquisadores é usar esses supercapacitores sustentáveis para armazenar eletricidade de fontes renováveis de energia para uso em veículos e residências.\n",
      "\n",
      "E isso antes de considerar os benefícios de encontrar um uso verde para o durião, já que mais de 70% dessas frutas tendem a ser jogadas fora.\n",
      "\n",
      "Em 2018, o mau cheiro impediu temporariamente a decolagem de um avião na Indonésia. Também levou a uma evacuação em massa de uma biblioteca da Universidade de Canberra, na Austrália, no ano passado.\n",
      "\n",
      "Nos estágios iniciais de sua pesquisa, o fedor se tornou um desafio para a mulher de Gomes, que retirou todos os restos da fruta fedorenta do freezer depois de apenas uma noite.\n",
      "\n",
      "Outros tipos de resíduos de plantas também podem ser usados para alimentar os dispositivos do futuro. Mikhail Astakhov, físico químico da Universidade Nacional de Ciência e Tecnologia (MISiS) em Moscou, na Rússia, transformou a hogweed, uma erva daninha de seiva tóxica que pode provocar bolhas quando em contato com a pele humana, em uma matéria-prima para um supercapacitor tecnicamente capaz de carregar um telefone.\n",
      "\n",
      "Baterias são para sempre\n",
      "Embora o impacto ambiental das baterias de íon-lítio concentre as atenções da comunidade científica, outros pesquisadores vêm se dedicando a enfrentar outras limitações desse dispositivo.\n",
      "\n",
      "Tom Scott, professor de materiais da Universidade de Bristol, no Reino Unido, diz não acreditar que as baterias de íon-lítio vão perder espaço em seu uso convencional no próximo século. Mas, segundo ele, existem oportunidades quando se trata de armazenar energia em ambientes mais extremos.\n",
      "\n",
      "\n",
      "CONSCISE SUMMARY IN PORTUGUESE:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "Baterias são para sempre\n",
      "Embora o impacto ambiental das baterias de íon-lítio concentre as atenções da comunidade científica, outros pesquisadores vêm se dedicando a enfrentar outras limitações desse dispositivo.\n",
      "\n",
      "Tom Scott, professor de materiais da Universidade de Bristol, no Reino Unido, diz não acreditar que as baterias de íon-lítio vão perder espaço em seu uso convencional no próximo século. Mas, segundo ele, existem oportunidades quando se trata de armazenar energia em ambientes mais extremos.\n",
      "\n",
      "Junto com sua equipe, Scott tem desenvolvido baterias feitas de diamantes. Ao produzir diamantes artificiais que contêm carbono-14 radioativo, os pesquisadores conseguiram criar \"baterias betavoltaicas\" que produzem uma corrente constante e podem durar milhares de anos.\n",
      "\n",
      "Presos dentro da rede de diamante, os isótopos radioativos disparam elétrons de energia superalta à medida que sofrem decaimento nuclear. Isso, por sua vez, cria uma chuva de elétrons através da estrutura do diamante que pode ser aproveitada para produzir uma corrente elétrica.\n",
      "\n",
      "Do lado de fora, a radioatividade permaneceria em níveis seguros, dizem os pesquisadores.\n",
      "\n",
      "A equipe já criou um protótipo de \"bateria de diamante\" usando diamantes artificiais colocados dentro de um campo radioativo produzido pelo isótopo Níquel-63, que dispara um fluxo de elétrons através do diamante. Mas agora eles estão trabalhando em uma versão que usa carbono-14 extraído de blocos de grafite usados em usinas nucleares. Ao transformar esse lixo nuclear em uma bateria de longa duração, Scott e seus colegas esperam encontrar novo uso para o resíduo dessas usinas à medida que elas são desativadas.\n",
      "\n",
      "\"Trata-se de uma reviravolta\", diz Sophie Osbourne, que integra a equipe de Scott. \"Por muito tempo, coletamos lixo nuclear e agora não estamos mais falando sobre armazenamento de longo prazo, mas sim reaproveitá-lo para produzir eletricidade.\"\n",
      "\n",
      "Apesar de as baterias químicas como o íon-lítio não terem bom desempenho em altas temperaturas, as de diamante podem funcionar em ambientes mais extremos onde não faltam alternativas, como no espaço, no fundo do mar ou talvez no topo de um vulcão. Elas seriam perfeitas para manter satélites e sensores computadorizados funcionando, por exemplo.\n",
      "\n",
      "\"As baterias são absolutamente minúsculas\", diz Scott. Até agora, os pesquisadores conseguiram gerar baterias de diamante que produzem 1,8 volts - semelhante a uma bateria AA - embora tenha uma corrente muito mais baixa. Elas também são tecnicamente recarregáveis, mas exigiriam algumas horas dentro de um núcleo de reator para atingir sua potência original, diz Scott.\n",
      "\n",
      "Embora o fluxo constante de corrente criado à medida que o material radioativo decai signifique que elas irão emitir eletricidade por um tempo incrivelmente longo - o carbono tem meia-vida de 5.730 anos, acrescentam os pesquisadores.\n",
      "\n",
      "Apesar de serem feitas de diamante, é improvável que, uma vez comercializadas, essas baterias sejam caras, diz Scott.\n",
      "\n",
      "\"Você ficaria surpreso com quão pouco os diamantes artificiais podem custar\".\n",
      "\n",
      "Nas próximas duas décadas, Scott diz acreditar que poderíamos até mesmo começar a ver baterias de diamante de ultra-longa duração aparecerem em nossas casas, talvez em detectores de fumaça ou controles remotos de TV, ou em dispositivos médicos, como aparelhos auditivos ou marca-passos.\n",
      "\n",
      "\n",
      "CONSCISE SUMMARY IN PORTUGUESE:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "Cientistas estão buscando alternativas para as baterias de íon-lítio, que apresentam limitações em termos de capacidade de retenção de carga, desempenho em climas extremos, segurança e sustentabilidade. Alguns pesquisadores estão desenvolvendo baterias de estado sólido, que substituem o eletrólito líquido inflamável por um sólido feito de cerâmica, aumentando a segurança. Outros estão explorando o uso de materiais mais abundantes, como cálcio e magnésio, em vez de lítio, para reduzir o impacto ambiental da mineração. Além disso, estão sendo desenvolvidas baterias feitas de materiais orgânicos, como\n",
      "\n",
      "Pesquisadores da Universidade de Bristol, no Reino Unido, estão desenvolvendo baterias feitas de diamantes que podem durar milhares de anos. Essas \"baterias betavoltaicas\" utilizam diamantes artificiais contendo carbono-14 radioativo, que produzem uma corrente constante através do decaimento nuclear. A equipe está trabalhando em uma versão que utiliza carbono-14 extraído de blocos de grafite usados em usinas nucleares, transformando esse lixo nuclear em uma bateria de longa duração. Essas baterias de diamante podem ser usadas em ambientes extremos, como no espaço ou no fundo do mar, e podem ser aplicadas em satélites, sensores computadorizados e dispositivos médicos. Apesar de serem feitas de diamante, espera-se que essas baterias sejam acessíveis quando comercializadas.\n",
      "\n",
      "\n",
      "CONSCISE SUMMARY IN PORTUGUESE:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Chain type: MapReduceDocumentsChain\n",
      "Run time: 28.235000000000582\n",
      "Summary: Cientistas estão desenvolvendo alternativas para as baterias de íon-lítio, como baterias de estado\n",
      "sólido e o uso de materiais mais abundantes, como cálcio e magnésio. Pesquisadores da Universidade\n",
      "de Bristol estão trabalhando em baterias feitas de diamantes contendo carbono-14 radioativo, que\n",
      "podem durar milhares de anos. Essas baterias podem ser usadas em ambientes extremos e têm potencial\n",
      "aplicação em satélites, sensores e dispositivos médicos. Espera-se que sejam acessíveis quando\n",
      "comercializadas.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rss1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
