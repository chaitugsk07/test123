{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests\n",
    "import feedparser\n",
    "from datetime import datetime, timezone\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "import pyperclip\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from io import BytesIO\n",
    "from skimage.feature import match_template\n",
    "from skimage.color import rgb2gray\n",
    "from transformers import pipeline\n",
    "import os\n",
    "import torch\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "import numpy\n",
    "# Enable device-side assertions\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cuda.use_deterministic_algorithms = True\n",
    "torch.backends.cuda.cufft_plan_cache.clear()\n",
    "torch.backends.cudnn.cache_enabled = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cuda.deterministic = True\n",
    "torch.backends.cuda.flags = {\n",
    "    'assert': str(int(True)),\n",
    "    'allow_tf32': str(int(False)),\n",
    "    'cudnn_deterministic': str(int(True)),\n",
    "    'cudnn_benchmark': str(int(False)),\n",
    "    'use_deterministic_algorithms': str(int(True)),\n",
    "    'cufft_plan_cache_clear': str(int(True)),\n",
    "    'cudnn_cache_enabled': str(int(False)),\n",
    "    'cudnn_allow_tf32': str(int(False)),\n",
    "    'cudnn_enabled': str(int(True)),\n",
    "    'cudnn_deterministic': str(int(True)),\n",
    "}\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "endpoint = \"http://hasura.192.168.0.100.nip.io/v1/graphql\"\n",
    "admin_key = \"arrive@AD123\"\n",
    "\n",
    "def query_hasura_graphql(endpoint, admin_key, query, variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'query': query,\n",
    "        'variables': variables\n",
    "    }\n",
    "    response = requests.post(endpoint, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def is_valid_timezone_format(published):\n",
    "    try:\n",
    "        # Attempt to parse the string\n",
    "        date_format = \"%a, %d %b %Y %H:%M:%S %z\"\n",
    "        date_object = datetime.strptime(published, date_format)\n",
    "        \n",
    "        hasura_timestamp = date_object.astimezone(timezone.utc).isoformat()\n",
    "        return True, hasura_timestamp\n",
    "    except ValueError:\n",
    "        # If parsing fails, the string is not in the correct format\n",
    "        return False, None\n",
    "\n",
    "def check_date_format(date_string):\n",
    "    try:\n",
    "        datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "        \n",
    "def mutation_hasura_graphql(endpoint, admin_key, mutation_query, mutation_variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "    response = requests.post(endpoint, json={'query': mutation_query, 'variables': mutation_variables}, headers=headers)\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "        return True, data\n",
    "    else:\n",
    "        print(f\"Mutation failed with status code {response.status_code}: {response.text}\")\n",
    "        return False, None\n",
    "\n",
    "def update_articles_toi():\n",
    "    graphql_query = '''\n",
    "    query MyQuery($outlet: String!, $link_type: Int!) {\n",
    "    rss1_links(where: {rss1_link_type: {_eq: $link_type}, outlet: {_eq: $outlet}}) {\n",
    "        rss1_link\n",
    "    }\n",
    "    }\n",
    "    '''\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"link_type\": 11,\n",
    "        \"outlet\": \"timesofindia\"\n",
    "    }\n",
    "    rss1_links_array = []\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    if response_data:\n",
    "        rss1_links_array = [item[\"rss1_link\"] for item in response_data[\"data\"][\"rss1_links\"]]\n",
    "    #print(rss1_links_array)\n",
    "    graphql_query = \"\"\"\n",
    "    query MyQuery($outlet: String!) {\n",
    "        rss1_outlets(where: {outlet: {_eq: $outlet}}) {\n",
    "            logo_url\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"outlet\": \"timesofindia\"\n",
    "    }\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articals_insert_input!] = {}) {\n",
    "    insert_rss1_articals(objects: $objects, on_conflict: {constraint: rss1_articals_post_link_key}) {\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    for feed_link in rss1_links_array:\n",
    "        NewsFeed = feedparser.parse(feed_link)\n",
    "        is_default_image = 0\n",
    "        logo_url = response_data['data']['rss1_outlets'][0]['logo_url']\n",
    "        print(\"############################################################\")\n",
    "        print(feed_link)\n",
    "        articles = []\n",
    "        for entry in NewsFeed.entries:\n",
    "            # print(entry.link)\n",
    "            is_default_image = 0\n",
    "            title = entry.title\n",
    "            summary_nofil = entry.summary\n",
    "            summary = re.sub('<[^<]+?>', '', summary_nofil)\n",
    "            image_url = logo_url\n",
    "            for link in entry.links:\n",
    "                if link.type == \"image/jpeg\":\n",
    "                    image_url= link.href\n",
    "                    is_default_image = 1\n",
    "                    break\n",
    "            post_link = entry.link\n",
    "            published = entry.published\n",
    "            datevalidation = is_valid_timezone_format(published)\n",
    "            if datevalidation[0]:\n",
    "                hasura_timestamp = datevalidation[1]\n",
    "            if check_date_format(published):\n",
    "                hasura_timestamp = published\n",
    "            else:\n",
    "                hasura_timestamp = datetime.now().astimezone(timezone.utc).isoformat()\n",
    "            if \"author\" in entry:\n",
    "                author = entry.author\n",
    "            else:\n",
    "                author = \"na\"\n",
    "            articles.append({\n",
    "                    \"rss1_link\": feed_link,\n",
    "                    \"post_link\": post_link,\n",
    "                    \"title\": title,\n",
    "                    \"summary\": summary,\n",
    "                    \"author\": author,\n",
    "                    \"image_link\" : image_url,\n",
    "                    \"post_published\": hasura_timestamp,\n",
    "                    \"is_default_image\": is_default_image,\n",
    "                }\n",
    "            )\n",
    "            #print(feed_link, post_link, title, summary, author, image_url, hasura_timestamp, is_default_image)\n",
    "        mutation_variables = {\n",
    "            \"objects\": articles\n",
    "        }\n",
    "        #print({'query': mutation_query, 'variables': mutation_variables})\n",
    "        out1 = mutation_hasura_graphql(endpoint = endpoint, admin_key = admin_key, mutation_query = mutation_query, mutation_variables = mutation_variables)\n",
    "\n",
    "def update_articles_thehindu():\n",
    "    graphql_query = '''\n",
    "    query MyQuery($outlet: String!, $link_type: Int!) {\n",
    "    rss1_links(where: {rss1_link_type: {_eq: $link_type}, outlet: {_eq: $outlet}}) {\n",
    "        rss1_link\n",
    "    }\n",
    "    }\n",
    "    '''\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"link_type\": 11,\n",
    "        \"outlet\": \"thehindu\"\n",
    "    }\n",
    "    rss1_links_array = []\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    if response_data:\n",
    "        rss1_links_array = [item[\"rss1_link\"] for item in response_data[\"data\"][\"rss1_links\"]]\n",
    "    #print(rss1_links_array)\n",
    "    graphql_query = \"\"\"\n",
    "    query MyQuery($outlet: String!) {\n",
    "        rss1_outlets(where: {outlet: {_eq: $outlet}}) {\n",
    "            logo_url\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"outlet\": \"thehindu\"\n",
    "    }\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articals_insert_input!] = {}) {\n",
    "    insert_rss1_articals(objects: $objects, on_conflict: {constraint: rss1_articals_post_link_key}) {\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    for feed_link in rss1_links_array:\n",
    "        NewsFeed = feedparser.parse(feed_link)\n",
    "        is_default_image = 0\n",
    "        logo_url = response_data['data']['rss1_outlets'][0]['logo_url']\n",
    "        print(\"############################################################\")\n",
    "        print(feed_link)\n",
    "        articles = []\n",
    "        for entry in NewsFeed.entries:\n",
    "            # print(entry.link)\n",
    "            is_default_image = 0\n",
    "            title = entry.title\n",
    "            summary_nofil = entry.summary\n",
    "            summary = re.sub('<[^<]+?>', '', summary_nofil)\n",
    "            image_url = logo_url\n",
    "            for link in entry.links:\n",
    "                if link.type == \"image/jpeg\":\n",
    "                    image_url= link.href\n",
    "                    is_default_image = 1\n",
    "                    break\n",
    "            post_link = entry.link\n",
    "            published = entry.published\n",
    "            datevalidation = is_valid_timezone_format(published)\n",
    "            if datevalidation[0]:\n",
    "                hasura_timestamp = datevalidation[1]\n",
    "            if check_date_format(published):\n",
    "                hasura_timestamp = published\n",
    "            else:\n",
    "                hasura_timestamp = datetime.now().astimezone(timezone.utc).isoformat()\n",
    "            if \"author\" in entry:\n",
    "                author = entry.author\n",
    "            else:\n",
    "                author = \"na\"\n",
    "            articles.append({\n",
    "                    \"rss1_link\": feed_link,\n",
    "                    \"post_link\": post_link,\n",
    "                    \"title\": title,\n",
    "                    \"summary\": summary,\n",
    "                    \"author\": author,\n",
    "                    \"image_link\" : image_url,\n",
    "                    \"post_published\": hasura_timestamp,\n",
    "                    \"is_default_image\": is_default_image,\n",
    "                }\n",
    "            )\n",
    "            #print(feed_link, post_link, title, summary, author, image_url, hasura_timestamp, is_default_image)\n",
    "        mutation_variables = {\n",
    "            \"objects\": articles\n",
    "        }\n",
    "        #print({'query': mutation_query, 'variables': mutation_variables})\n",
    "        out1 = mutation_hasura_graphql(endpoint = endpoint, admin_key = admin_key, mutation_query = mutation_query, mutation_variables = mutation_variables)\n",
    "\n",
    "def update_articles_cnn():\n",
    "    graphql_query = '''\n",
    "    query MyQuery($outlet: String!, $link_type: Int!) {\n",
    "    rss1_links(where: {rss1_link_type: {_eq: $link_type}, outlet: {_eq: $outlet}}) {\n",
    "        rss1_link\n",
    "    }\n",
    "    }\n",
    "    '''\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"link_type\": 11,\n",
    "        \"outlet\": \"cnn\"\n",
    "    }\n",
    "    rss1_links_array = []\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    if response_data:\n",
    "        rss1_links_array = [item[\"rss1_link\"] for item in response_data[\"data\"][\"rss1_links\"]]\n",
    "    #print(rss1_links_array)\n",
    "    graphql_query = \"\"\"\n",
    "    query MyQuery($outlet: String!) {\n",
    "        rss1_outlets(where: {outlet: {_eq: $outlet}}) {\n",
    "            logo_url\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"outlet\": \"cnn\"\n",
    "    }\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articals_insert_input!] = {}) {\n",
    "    insert_rss1_articals(objects: $objects, on_conflict: {constraint: rss1_articals_post_link_key}) {\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    for feed_link in rss1_links_array:\n",
    "        NewsFeed = feedparser.parse(feed_link)\n",
    "        is_default_image = 0\n",
    "        logo_url = response_data['data']['rss1_outlets'][0]['logo_url']\n",
    "        print(\"############################################################\")\n",
    "        print(feed_link)\n",
    "        articles = []\n",
    "        for entry in NewsFeed.entries:\n",
    "            # print(entry.link)\n",
    "            is_default_image = 0\n",
    "            title = entry.title\n",
    "            summary = ''\n",
    "            if 'summary' in entry:\n",
    "                summary_nofil = entry.summary\n",
    "                summary = re.sub('<[^<]+?>', '', summary_nofil)\n",
    "            image_url = logo_url\n",
    "            if 'media_content' in entry:\n",
    "                image_url = entry['media_content'][0]['url']\n",
    "                is_default_image = 1\n",
    "            for link in entry.links:\n",
    "                if link.type == \"image/jpeg\":\n",
    "                    image_url= link.href\n",
    "                    is_default_image = 1\n",
    "                    break\n",
    "            post_link = entry.link\n",
    "            published = datetime.now(timezone.utc).isoformat()\n",
    "            if 'published' in entry:\n",
    "                published = entry.published\n",
    "            datevalidation = is_valid_timezone_format(published)\n",
    "            if datevalidation[0]:\n",
    "                hasura_timestamp = datevalidation[1]\n",
    "            if check_date_format(published):\n",
    "                hasura_timestamp = published\n",
    "            else:\n",
    "                hasura_timestamp = datetime.now().astimezone(timezone.utc).isoformat()\n",
    "            if \"author\" in entry:\n",
    "                author = entry.author\n",
    "            else:\n",
    "                author = \"na\"\n",
    "            articles.append({\n",
    "                    \"rss1_link\": feed_link,\n",
    "                    \"post_link\": post_link,\n",
    "                    \"title\": title,\n",
    "                    \"summary\": summary,\n",
    "                    \"author\": author,\n",
    "                    \"image_link\" : image_url,\n",
    "                    \"post_published\": hasura_timestamp,\n",
    "                    \"is_default_image\": is_default_image,\n",
    "                }\n",
    "            )\n",
    "            #print(feed_link, post_link, title, summary, author, image_url, hasura_timestamp, is_default_image)\n",
    "        mutation_variables = {\n",
    "            \"objects\": articles\n",
    "        }\n",
    "        #print({'query': mutation_query, 'variables': mutation_variables})\n",
    "        out1 = mutation_hasura_graphql(endpoint = endpoint, admin_key = admin_key, mutation_query = mutation_query, mutation_variables = mutation_variables)\n",
    "\n",
    "def update_articles_foxnews():\n",
    "    graphql_query = '''\n",
    "    query MyQuery($outlet: String!, $link_type: Int!) {\n",
    "    rss1_links(where: {rss1_link_type: {_eq: $link_type}, outlet: {_eq: $outlet}}) {\n",
    "        rss1_link\n",
    "    }\n",
    "    }\n",
    "    '''\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"link_type\": 11,\n",
    "        \"outlet\": \"foxnews\"\n",
    "    }\n",
    "    rss1_links_array = []\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    if response_data:\n",
    "        rss1_links_array = [item[\"rss1_link\"] for item in response_data[\"data\"][\"rss1_links\"]]\n",
    "    #print(rss1_links_array)\n",
    "    graphql_query = \"\"\"\n",
    "    query MyQuery($outlet: String!) {\n",
    "        rss1_outlets(where: {outlet: {_eq: $outlet}}) {\n",
    "            logo_url\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "        \"outlet\": \"foxnews\"\n",
    "    }\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articals_insert_input!] = {}) {\n",
    "    insert_rss1_articals(objects: $objects, on_conflict: {constraint: rss1_articals_post_link_key}) {\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    for feed_link in rss1_links_array:\n",
    "        NewsFeed = feedparser.parse(feed_link)\n",
    "        is_default_image = 0\n",
    "        logo_url = response_data['data']['rss1_outlets'][0]['logo_url']\n",
    "        print(\"############################################################\")\n",
    "        print(feed_link)\n",
    "        articles = []\n",
    "        for entry in NewsFeed.entries:\n",
    "            # print(entry.link)\n",
    "            is_default_image = 0\n",
    "            title = entry.title\n",
    "            summary = ''\n",
    "            if 'summary' in entry:\n",
    "                summary_nofil = entry.summary\n",
    "                summary = re.sub('<[^<]+?>', '', summary_nofil)\n",
    "            image_url = logo_url\n",
    "            if 'media_content' in entry:\n",
    "                image_url = entry['media_content'][0]['url']\n",
    "                is_default_image = 1\n",
    "            if 'links' in entry:\n",
    "                for link in entry.links:\n",
    "                    if link.type == \"image/jpeg\":\n",
    "                        image_url= link.href\n",
    "                        is_default_image = 1\n",
    "                        break\n",
    "            post_link = entry.link\n",
    "            published = datetime.now(timezone.utc).isoformat()\n",
    "            if 'published' in entry:\n",
    "                published = entry.published\n",
    "            datevalidation = is_valid_timezone_format(published)\n",
    "            if datevalidation[0]:\n",
    "                hasura_timestamp = datevalidation[1]\n",
    "            if check_date_format(published):\n",
    "                hasura_timestamp = published\n",
    "            else:\n",
    "                hasura_timestamp = datetime.now().astimezone(timezone.utc).isoformat()\n",
    "            if \"author\" in entry:\n",
    "                author = entry.author\n",
    "            else:\n",
    "                author = \"na\"\n",
    "            articles.append({\n",
    "                    \"rss1_link\": feed_link,\n",
    "                    \"post_link\": post_link,\n",
    "                    \"title\": title,\n",
    "                    \"summary\": summary,\n",
    "                    \"author\": author,\n",
    "                    \"image_link\" : image_url,\n",
    "                    \"post_published\": hasura_timestamp,\n",
    "                    \"is_default_image\": is_default_image,\n",
    "                }\n",
    "            )\n",
    "            #print(feed_link, post_link, title, summary, author, image_url, hasura_timestamp, is_default_image)\n",
    "        mutation_variables = {\n",
    "            \"objects\": articles\n",
    "        }\n",
    "        #print({'query': mutation_query, 'variables': mutation_variables})\n",
    "        out1 = mutation_hasura_graphql(endpoint = endpoint, admin_key = admin_key, mutation_query = mutation_query, mutation_variables = mutation_variables)\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return cv2.imdecode(np.frombuffer(response.content, np.uint8), -1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def update_article_detail_toi_with_images():\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "        rss1_articals(offset: $offset, limit: $limit, where: {is_in_detail: {_eq: 0}, rss1LinkByRss1Link: {outlet: {_eq: \"timesofindia\"}}}, order_by: {post_published: desc}) {\n",
    "            post_link\n",
    "            is_default_image\n",
    "            image_link\n",
    "            id\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    offset = 0\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articles_detail_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}) {\n",
    "    insert_rss1_articles_detail(objects: $objects, on_conflict: {constraint: rss1_articles_detail_post_link_key}) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    update_rss1_articals_many(updates: $updates) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"    \n",
    "    options = webdriver.EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    options.add_argument('--enable-immersive-reader')\n",
    "    driver = webdriver.Edge(options=options)\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 2,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        #print(variables, response_data)\n",
    "        #print(response_data)\n",
    "        post_links_array = []\n",
    "        ids=[]\n",
    "        if response_data:\n",
    "            post_links_array = [item[\"post_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            is_default_image_array = [item[\"is_default_image\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            image_link_array = [item[\"image_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            ids=[item[\"id\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "        articles_detail = []\n",
    "        articles_update = []\n",
    "        if len(post_links_array) == 0:\n",
    "            break\n",
    "        try:\n",
    "            for a in range(len(post_links_array)):\n",
    "                main_link = post_links_array[a]\n",
    "                print(main_link)\n",
    "                read_link= \"read://\"+main_link\n",
    "                driver.get(read_link)\n",
    "                time.sleep(5)\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('a').key_up(Keys.CONTROL).perform()\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('c').key_up(Keys.CONTROL).perform()\n",
    "                text = pyperclip.paste()\n",
    "                text2 = text\n",
    "                text3 = text2.split('\\n')\n",
    "                text3 = [s.replace('\\r', '') for s in text3]\n",
    "                special_chars = set(\"!@#$%^&*()_+[]{}|;:'\\\",<>?\")\n",
    "                text4 = [s for s in text3 if len(s) > 0 and (s[0] not in special_chars or s[-1] not in special_chars)]\n",
    "                my_list = text4\n",
    "                my_set = set()\n",
    "                desription = []\n",
    "                for item in my_list:\n",
    "                    if item not in my_set:\n",
    "                        desription.append(item)\n",
    "                        my_set.add(item)\n",
    "                #print(desription)\n",
    "                driver.get(main_link)\n",
    "                time.sleep(5)\n",
    "                try: \n",
    "                    xpath = f\"\"\"//*/img[@alt=\"{desription[0]}\"]\"\"\"\n",
    "                    elements = driver.find_elements(By.XPATH, xpath)\n",
    "                    #print(elements)\n",
    "                    images = [element.get_attribute(\"src\") for element in elements]\n",
    "                    #print(images)\n",
    "                except:\n",
    "                    images = []\n",
    "                if is_default_image_array[a] == 1:\n",
    "                    images_1 = [image_link_array[a]] + images\n",
    "                else:\n",
    "                    images_1 = images\n",
    "                images_final = list(set(images_1))\n",
    "                images_to_remove = []\n",
    "                if len(images_final) > 1:\n",
    "                    image_urls = images_final\n",
    "                    for i in range(len(image_urls)):\n",
    "                        for j in range(i+1, len(image_urls)):\n",
    "                            image1 = load_image_from_url(image_urls[i])\n",
    "                            image2 = load_image_from_url(image_urls[j])\n",
    "\n",
    "                            if image1 is None or image2 is None:\n",
    "                                print(f\"Failed to load one or both images for comparison between image {i+1} and image {j+1}.\")\n",
    "                                continue\n",
    "\n",
    "                            # Resize the images to the same dimensions for comparison\n",
    "                            height, width, _ = image1.shape\n",
    "                            image3 = cv2.resize(image2, (width, height))\n",
    "\n",
    "                            # Convert the images to grayscale\n",
    "                            gray_image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "                            gray_image2 = cv2.cvtColor(image3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                            # Calculate the structural similarity\n",
    "                            result = match_template(gray_image1, gray_image2)\n",
    "                            ssim = np.max(result)\n",
    "\n",
    "                            # Display the SSIM value (a higher value indicates more similarity)\n",
    "                            #print(f\"SSIM between image {i+1} and image {j+1}: {ssim}\")\n",
    "                            height1, width1, _ = image1.shape\n",
    "                            height2, width2, _ = image2.shape\n",
    "                            height1, width1, _ = image1.shape\n",
    "                            height2, width2, _ = image2.shape\n",
    "                            if height1 * width1 >= height2 * width2 and ssim > 0.8:\n",
    "                                images_to_remove.append(image_urls[i+1])\n",
    "                            elif height1 * width1 < height2 * width2 and ssim > 0.8:\n",
    "                                images_to_remove.append(image_urls[i])\n",
    "\n",
    "                    # Remove the images that were marked for removal\n",
    "                    for image_url in images_to_remove:\n",
    "                        if image_url in images_final:\n",
    "                            images_final.remove(image_url)\n",
    "                #print(images_final)\n",
    "                articles_detail.append({\n",
    "                    \"article_id\": ids[a],\n",
    "                    \"title\": desription[0],\n",
    "                    \"discription\": desription[1:],\n",
    "                    \"image_link\": images_final,\n",
    "                }\n",
    "                )\n",
    "                if (is_default_image_array[a] == 0 and len(images_final) > 0):\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1 , \"image_link\": images_final[0], \"is_default_image\": 1}\n",
    "                    })\n",
    "                else:\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1}\n",
    "                    })\n",
    "                \n",
    "                #print(main_link, desription[0], desription[1:], images_final)\n",
    "            #print(articles_update)\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        except:\n",
    "            offset = offset + 1\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        \n",
    "    driver.quit() \n",
    "\n",
    "def update_article_detail_toi():\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "        rss1_articals(offset: $offset, limit: $limit, where: {is_in_detail: {_eq: 0}, rss1LinkByRss1Link: {outlet: {_eq: \"timesofindia\"}}}, order_by: {post_published: desc}) {\n",
    "            post_link\n",
    "            is_default_image\n",
    "            image_link\n",
    "            id\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    offset = 0\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articles_detail_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}) {\n",
    "    insert_rss1_articles_detail(objects: $objects, on_conflict: {constraint: rss1_articles_detail_article_id_key}) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    update_rss1_articals_many(updates: $updates) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"    \n",
    "    options = webdriver.EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    options.add_argument('--enable-immersive-reader')\n",
    "    driver = webdriver.Edge(options=options)\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 20,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        #print(variables, response_data)\n",
    "        #print(response_data)\n",
    "        post_links_array = []\n",
    "        ids=[]\n",
    "        if response_data:\n",
    "            post_links_array = [item[\"post_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            is_default_image_array = [item[\"is_default_image\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            image_link_array = [item[\"image_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            ids=[item[\"id\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "        articles_detail = []\n",
    "        articles_update = []\n",
    "        if len(post_links_array) == 0:\n",
    "            break\n",
    "        try:\n",
    "            for a in range(len(post_links_array)):\n",
    "                main_link = post_links_array[a]\n",
    "                print(main_link)\n",
    "                read_link= \"read://\"+main_link\n",
    "                driver.get(read_link)\n",
    "                time.sleep(5)\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('a').key_up(Keys.CONTROL).perform()\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('c').key_up(Keys.CONTROL).perform()\n",
    "                text = pyperclip.paste()\n",
    "                text2 = text\n",
    "                text3 = text2.split('\\n')\n",
    "                text3 = [s.replace('\\r', '') for s in text3]\n",
    "                special_chars = set(\"!@#$%^&*()_+[]{}|;:'\\\",<>?\")\n",
    "                text4 = [s for s in text3 if len(s) > 0 and (s[0] not in special_chars or s[-1] not in special_chars)]\n",
    "                my_list = text4\n",
    "                my_set = set()\n",
    "                desription = []\n",
    "                for item in my_list:\n",
    "                    if item not in my_set:\n",
    "                        desription.append(item)\n",
    "                        my_set.add(item)\n",
    "                #print(desription)\n",
    "                images_final = []\n",
    "                articles_detail.append({\n",
    "                    \"article_id\": ids[a],\n",
    "                    \"title\": desription[0],\n",
    "                    \"description\": desription[1:],\n",
    "                    \"image_link\": images_final,\n",
    "                }\n",
    "                )\n",
    "                if (is_default_image_array[a] == 0 and len(images_final) > 0):\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1 , \"image_link\": images_final[0], \"is_default_image\": 1}\n",
    "                    })\n",
    "                else:\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1}\n",
    "                    })\n",
    "                \n",
    "                #print(main_link, desription[0], desription[1:], images_final)\n",
    "            #print(articles_update)\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        except:\n",
    "            offset = offset + 1\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        \n",
    "    driver.quit() \n",
    "\n",
    "def update_article_detail_cnn(offset1):\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "        rss1_articals(offset: $offset, limit: $limit, where: {is_in_detail: {_eq: 0}, rss1LinkByRss1Link: {outlet: {_eq: \"cnn\"}}}, order_by: {post_published: desc}) {\n",
    "            post_link\n",
    "            is_default_image\n",
    "            image_link\n",
    "            id\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articles_detail_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}) {\n",
    "    insert_rss1_articles_detail(objects: $objects, on_conflict: {constraint: rss1_articles_detail_article_id_key}) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    update_rss1_articals_many(updates: $updates) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"    \n",
    "    options = webdriver.EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    options.add_argument('--enable-immersive-reader')\n",
    "    driver = webdriver.Edge(options=options)\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 2,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        #print(variables, response_data)\n",
    "        #print(response_data)\n",
    "        post_links_array = []\n",
    "        ids=[]\n",
    "        if response_data:\n",
    "            post_links_array = [item[\"post_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            is_default_image_array = [item[\"is_default_image\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            image_link_array = [item[\"image_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            ids=[item[\"id\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "        articles_detail = []\n",
    "        articles_update = []\n",
    "        if len(post_links_array) == 0:\n",
    "            break\n",
    "        try:\n",
    "            for a in range(len(post_links_array)):\n",
    "                main_link = post_links_array[a]\n",
    "                print(main_link)\n",
    "                driver.get(main_link)\n",
    "                get_url = driver.current_url\n",
    "                read_link= \"read://\"+get_url\n",
    "                driver.get(read_link)\n",
    "                time.sleep(5)\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('a').key_up(Keys.CONTROL).perform()\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('c').key_up(Keys.CONTROL).perform()\n",
    "                text = pyperclip.paste()\n",
    "                text2 = text\n",
    "                text3 = text2.split('\\n')\n",
    "                text3 = [s.replace('\\r', '') for s in text3]\n",
    "                special_chars = set(\"!@#$%^&*()_+[]{}|;:'\\\",<>?\")\n",
    "                text4 = [s for s in text3 if len(s) > 0 and (s[0] not in special_chars or s[-1] not in special_chars)]\n",
    "                my_list = text4\n",
    "                my_set = set()\n",
    "                desription = []\n",
    "                for item in my_list:\n",
    "                    if item not in my_set:\n",
    "                        desription.append(item)\n",
    "                        my_set.add(item)\n",
    "                #print(desription)\n",
    "                images_final = []\n",
    "                articles_detail.append({\n",
    "                    \"article_id\": ids[a],\n",
    "                    \"title\": desription[0],\n",
    "                    \"description\": desription[1:],\n",
    "                    \"image_link\": images_final,\n",
    "                }\n",
    "                )\n",
    "                if (is_default_image_array[a] == 0 and len(images_final) > 0):\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1 , \"image_link\": images_final[0], \"is_default_image\": 1}\n",
    "                    })\n",
    "                else:\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1}\n",
    "                    })\n",
    "                \n",
    "                #print(main_link, desription[0], desription[1:], images_final)\n",
    "            #print(articles_update)\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        except:\n",
    "            offset = offset + 1\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        \n",
    "    driver.quit() \n",
    "\n",
    "def update_article_detail_foxnews(offset1):\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "        rss1_articals(offset: $offset, limit: $limit, where: {is_in_detail: {_eq: 0}, rss1LinkByRss1Link: {outlet: {_eq: \"thehindu\"}}}, order_by: {post_published: desc}) {\n",
    "            post_link\n",
    "            is_default_image\n",
    "            image_link\n",
    "            id\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [rss1_articles_detail_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}) {\n",
    "    insert_rss1_articles_detail(objects: $objects, on_conflict: {constraint: rss1_articles_detail_article_id_key}) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    update_rss1_articals_many(updates: $updates) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"    \n",
    "    options = webdriver.EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    options.add_argument('--enable-immersive-reader')\n",
    "    driver = webdriver.Edge(options=options)\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 2,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        #print(variables, response_data)\n",
    "        #print(response_data)\n",
    "        post_links_array = []\n",
    "        ids=[]\n",
    "        if response_data:\n",
    "            post_links_array = [item[\"post_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            is_default_image_array = [item[\"is_default_image\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            image_link_array = [item[\"image_link\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "            ids=[item[\"id\"] for item in response_data[\"data\"][\"rss1_articals\"]]\n",
    "        articles_detail = []\n",
    "        articles_update = []\n",
    "        if len(post_links_array) == 0:\n",
    "            break\n",
    "        try:\n",
    "            for a in range(len(post_links_array)):\n",
    "                main_link = post_links_array[a]\n",
    "                print(main_link)\n",
    "                driver.get(main_link)\n",
    "                get_url = driver.current_url\n",
    "                read_link= \"read://\"+get_url\n",
    "                driver.get(read_link)\n",
    "                time.sleep(5)\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('a').key_up(Keys.CONTROL).perform()\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('c').key_up(Keys.CONTROL).perform()\n",
    "                text = pyperclip.paste()\n",
    "                text2 = text\n",
    "                text3 = text2.split('\\n')\n",
    "                text3 = [s.replace('\\r', '') for s in text3]\n",
    "                special_chars = set(\"!@#$%^&*()_+[]{}|;:'\\\",<>?\")\n",
    "                text4 = [s for s in text3 if len(s) > 0 and (s[0] not in special_chars or s[-1] not in special_chars)]\n",
    "                my_list = text4\n",
    "                my_set = set()\n",
    "                desription = []\n",
    "                for item in my_list:\n",
    "                    if item not in my_set:\n",
    "                        desription.append(item)\n",
    "                        my_set.add(item)\n",
    "                #print(desription)\n",
    "                images_final = []\n",
    "                articles_detail.append({\n",
    "                    \"article_id\": ids[a],\n",
    "                    \"title\": desription[0],\n",
    "                    \"description\": desription[1:],\n",
    "                    \"image_link\": images_final,\n",
    "                }\n",
    "                )\n",
    "                if (is_default_image_array[a] == 0 and len(images_final) > 0):\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1 , \"image_link\": images_final[0], \"is_default_image\": 1}\n",
    "                    })\n",
    "                else:\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1}\n",
    "                    })\n",
    "                \n",
    "                #print(main_link, desription[0], desription[1:], images_final)\n",
    "            #print(articles_update)\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        except:\n",
    "            offset = offset + 1\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "        \n",
    "    driver.quit() \n",
    "\n",
    "def summerizer(offset1): \n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0)\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    rss1_articles_detail(limit: $limit, offset: $offset, where: {summary: {_is_null: true}}) {\n",
    "        title\n",
    "        description\n",
    "        rss1_artical {\n",
    "        title\n",
    "        summary\n",
    "        }\n",
    "        article_id\n",
    "    }\n",
    "    }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($updates: [rss1_articles_detail_updates!] = {where: {}}) {\n",
    "        update_rss1_articles_detail_many(updates: $updates) {\n",
    "            affected_rows\n",
    "            returning {\n",
    "            id\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 2,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        rss1_articles_detail_updates = []\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        if len(response_data['data']['rss1_articles_detail']) == 0:\n",
    "            break\n",
    "        for response in response_data['data']['rss1_articles_detail']:\n",
    "            print(response['title'])\n",
    "            article=\"\"\n",
    "            article = article + response['title'] + \" \" +  response['rss1_artical']['title'] + \" \" +  response['rss1_artical']['summary'] + ', '.join(response['description'])\n",
    "            chunks=[]\n",
    "            max_length = 0\n",
    "            min_length = 0\n",
    "            if len(article) < 1000:\n",
    "                max_length = 150\n",
    "                min_length = 100\n",
    "                chunks.append(article)\n",
    "            elif len(article) < 3000:\n",
    "                max_length = 300\n",
    "                min_length = 200\n",
    "                chunks.append(article)\n",
    "            elif len(article) < 4000:\n",
    "                max_length = 400\n",
    "                min_length = 250\n",
    "                chunks.append(article)\n",
    "            elif len(article) < 8000:\n",
    "                max_length = 200\n",
    "                min_length = 150\n",
    "                midpoint = len(article) // 2\n",
    "                chunks.append(article[:midpoint])\n",
    "                chunks.append(article[midpoint:])\n",
    "            else:\n",
    "                article=article[:8000]\n",
    "                max_length = 200\n",
    "                min_length = 150\n",
    "                midpoint = len(article) // 2\n",
    "                chunks.append(article[:midpoint])\n",
    "                chunks.append(article[midpoint:])\n",
    "\n",
    "            summerize=\"\"\n",
    "            for chunk in chunks:\n",
    "                summerize=summerize + summarizer(chunk, max_length=max_length, min_length=min_length, do_sample=False)[0]['summary_text']+ \" \"\n",
    "            if len(summerize) > 0:\n",
    "                rss1_articles_detail_updates.append({\n",
    "                    \"where\": {\"article_id\" : { \"_eq\": response['article_id'] }},\n",
    "                    \"_set\": {\"summary\": summerize }\n",
    "                })\n",
    "        mutation_variables = {\n",
    "            \"updates\": rss1_articles_detail_updates,\n",
    "            }\n",
    "        out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "\n",
    "def vectorize(offset1):\n",
    "    model = INSTRUCTOR('hkunlp/instructor-xl', device=0)\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    rss1_articals(limit: $limit, offset: $offset, where: {is_vectorized: {_eq: 0}, is_in_detail: {_eq: 1}}) {\n",
    "        id\n",
    "        title\n",
    "        summary\n",
    "        rss1_articles_details {\n",
    "        summary\n",
    "        tags\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [articles_vector1_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}) {\n",
    "    insert_articles_vector1(objects: $objects, on_conflict: {constraint: articles_vector1_article_id_key}) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        article_id\n",
    "        }\n",
    "    }\n",
    "    update_rss1_articals_many(updates: $updates) {\n",
    "        affected_rows\n",
    "        returning {\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 1,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        articles_vector1_insert_input_loc=[]\n",
    "        rss1_articals_updates_loc=[]\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        if len(response_data['data']['rss1_articals']) == 0:\n",
    "            break\n",
    "        #print(json.dumps(response_data, indent=4))\n",
    "        s1= []\n",
    "        ids=[]\n",
    "        for response in response_data['data']['rss1_articals']:\n",
    "            article=\"\"\n",
    "            tags=\"\"\n",
    "            if (response['rss1_articles_details'][0]['tags']) is None:\n",
    "                tags = \" \"\n",
    "            else:\n",
    "                tags = \", \".join(response['rss1_articles_details'][0]['tags'])\n",
    "            article = article + response['title'] + \" \" +  response['summary'] + \" \" +  response['rss1_articles_details'][0]['summary'] + tags\n",
    "            s1.append([['Represent the news article for custering and retrieval:  ', article]])\n",
    "            ids.append(response['id'])\n",
    "        embeddings = []\n",
    "        for s in s1:\n",
    "            list_embeddings = numpy.ravel(model.encode(s)).tolist()\n",
    "            embeddings.append(list_embeddings)\n",
    "        for i in range(0,len(ids)):\n",
    "            articles_vector1_insert_input_loc.append({\n",
    "                \"article_id\": ids[i],\n",
    "                \"embedding\": str(embeddings[i]),\n",
    "                }\n",
    "                )\n",
    "            rss1_articals_updates_loc.append({\n",
    "                \"where\": {\"id\" : { \"_eq\": ids[i] }},\n",
    "                \"_set\": {\"is_vectorized\": 1}\n",
    "                })\n",
    "\n",
    "        mutation_variables = {\n",
    "        \"objects\": articles_vector1_insert_input_loc,\n",
    "        \"updates\": rss1_articals_updates_loc,\n",
    "        }\n",
    "        out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "      \n",
    "def grouping(offset1):\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "        rss1_articals(limit: $limit, offset: $offset, where: {is_vectorized: {_eq: 1}, is_in_detail: {_eq: 1}, is_grouped: {_eq: 0}}) {\n",
    "            id\n",
    "            articles_vector1 {\n",
    "            embedding\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [articles_groups_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}) {\n",
    "        insert_articles_groups(objects: $objects, on_conflict: {constraint: articles_groups_pkey}) {\n",
    "            affected_rows\n",
    "            returning {\n",
    "            article_id\n",
    "            }\n",
    "        }\n",
    "        update_rss1_articals_many(updates: $updates) {\n",
    "            affected_rows\n",
    "            returning {\n",
    "            id\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "    \"\"\"\n",
    "    func_query = '''\n",
    "    query MyQuery($p_article_id: bigint!) {\n",
    "        get_similar_articles_en(args: {p_article_id: $p_article_id}) {\n",
    "            article_id\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 20,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        articles_groups_insert_input_loc=[]\n",
    "        rss1_articals_updates_loc=[]\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        if len(response_data['data']['rss1_articals']) == 0:\n",
    "            break\n",
    "        #print(json.dumps(response_data, indent=4))\n",
    "        s1= []\n",
    "        ids=[]\n",
    "        for response in response_data['data']['rss1_articals']:\n",
    "            article_embed = response['articles_vector1']['embedding']\n",
    "            func_variables = {\n",
    "                \"p_article_id\": response['id']\n",
    "                }\n",
    "            func_response_data = query_hasura_graphql(endpoint, admin_key, func_query, func_variables)\n",
    "            article_group = []\n",
    "            if len(func_response_data['data']['get_similar_articles_en']) > 0:\n",
    "                for func_response in func_response_data['data']['get_similar_articles_en']:\n",
    "                    article_group.append(func_response['article_id'])\n",
    "            \n",
    "            articles_groups_insert_input_loc.append({\n",
    "                \"article_id\": response['id'],\n",
    "                \"initial_group\": article_group,\n",
    "                }\n",
    "                )\n",
    "            rss1_articals_updates_loc.append({\n",
    "                \"where\": {\"id\" : { \"_eq\": response['id'] }},\n",
    "                \"_set\": {\"is_grouped\": 1}\n",
    "                })\n",
    "\n",
    "        mutation_variables = {\n",
    "        \"objects\": articles_groups_insert_input_loc,\n",
    "        \"updates\": rss1_articals_updates_loc,\n",
    "        }\n",
    "        out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "\n",
    "def grouping_l1(offset1):\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "          rss1_articals(where: {is_grouped: {_eq: 1}}, limit: $limit, offset: $offset) {\n",
    "            id\n",
    "            articles_group {\n",
    "            initial_group\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "        mutation MyMutation($objects: [articles_grouped_l1_insert_input!] = {}, $updates: [rss1_articals_updates!] = {where: {}}, $updates1: [articles_grouped_l1_updates!] = {where: {}}) {\n",
    "        insert_articles_grouped_l1(objects: $objects) {\n",
    "            affected_rows\n",
    "        }\n",
    "        update_rss1_articals_many(updates: $updates) {\n",
    "            affected_rows\n",
    "        }\n",
    "        update_articles_grouped_l1_many(updates: $updates1) {\n",
    "            affected_rows\n",
    "        }\n",
    "        }\n",
    "    \"\"\"\n",
    "    func_query = '''\n",
    "    query MyQuery($arg_1: bigint!) {\n",
    "        get_articles_groups(args: {arg_1: $arg_1}) {\n",
    "            initial_group\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    func_query1 = '''\n",
    "    query MyQuery($arg_1: bigint!) {\n",
    "        get_articles_grouped_l1(args: {arg_1: $arg_1}) {\n",
    "            article_ids,\n",
    "            id\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 1,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        articles_grouped_l1_insert_input_loc=[]\n",
    "        rss1_articals_updates_loc=[]\n",
    "        articles_grouped_l1_updates=[]\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        if len(response_data['data']['rss1_articals']) == 0:\n",
    "            break\n",
    "        #print(json.dumps(response_data, indent=4))\n",
    "        for response in response_data['data']['rss1_articals']:\n",
    "\n",
    "            func_variables = {\n",
    "                \"arg_1\": response['id']\n",
    "                }\n",
    "            func_response_data = query_hasura_graphql(endpoint, admin_key, func_query, func_variables)\n",
    "            articles_ids = []\n",
    "            print(response['id'])\n",
    "            if len(func_response_data['data']['get_articles_groups']) > 0:\n",
    "                for func_response in func_response_data['data']['get_articles_groups']:\n",
    "                    articles_ids.append(func_response['initial_group'])\n",
    "            \n",
    "            func_response_data1 = query_hasura_graphql(endpoint, admin_key, func_query1, func_variables)\n",
    "            \n",
    "            \n",
    "            if (len(func_response_data1['data']['get_articles_grouped_l1']) == 0):\n",
    "                new_lst = []\n",
    "                for sublist in articles_ids:\n",
    "                    for element in sublist:\n",
    "                        new_lst.append(element)\n",
    "                my_list = list(set(new_lst))\n",
    "                print(my_list)\n",
    "                articles_grouped_l1_insert_input_loc.append({\n",
    "                    \"article_ids\": my_list,\n",
    "                    'articles_in_group': len(my_list)\n",
    "                    }\n",
    "                    )\n",
    "                rss1_articals_updates_loc.append({\n",
    "                    \"where\": {\"id\" : { \"_eq\": response['id'] }},\n",
    "                    \"_set\": {\"is_grouped\": 2}\n",
    "                    })\n",
    "            else:\n",
    "                articles_ids.append(func_response_data1['data']['get_articles_grouped_l1'][0]['article_ids'])\n",
    "                new_lst = []\n",
    "                for sublist in articles_ids:\n",
    "                    for element in sublist:\n",
    "                        new_lst.append(element)\n",
    "                my_list = list(set(new_lst))\n",
    "                articles_grouped_l1_updates.append({\n",
    "                    \"where\": {\"id\" : { \"_eq\": func_response_data1['data']['get_articles_grouped_l1'][0]['id'] }},\n",
    "                    \"_set\": {\"article_ids\": my_list, 'articles_in_group': len(my_list)}\n",
    "                    })\n",
    "                rss1_articals_updates_loc.append({\n",
    "                    \"where\": {\"id\" : { \"_eq\": response['id'] }},\n",
    "                    \"_set\": {\"is_grouped\": 2}\n",
    "                    })\n",
    "                print(my_list)     \n",
    "\n",
    "\n",
    "        mutation_variables = {\n",
    "        \"objects\": articles_grouped_l1_insert_input_loc,\n",
    "        \"updates\": rss1_articals_updates_loc,\n",
    "        \"updates1\": articles_grouped_l1_updates,\n",
    "        }\n",
    "        out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update_articles_toi()\n",
    "#update_articles_thehindu()\n",
    "#update_articles_cnn()\n",
    "#update_articles_foxnews()\n",
    "\n",
    "#update_article_detail_toi()\n",
    "#update_article_detail_cnn(0)\n",
    "#update_article_detail_foxnews(0)\n",
    "#summerizer(0)\n",
    "#vectorize(0)\n",
    "grouping(0)\n",
    "grouping_l1(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665\n",
      "1243\n",
      "\n",
      "Vietnam detains energy policy think-tank chief, human rights group says\n",
      "Ngo Thi To Nhien, the executive director for Vietnam Initiative for Energy Transition was arrested on Sept. 15, according to The 88 Project, a group that advocates for freedom of expression in Vietnam\n",
      "Ngo Thi To Nhien, the executive director for Vietnam Initiative for Energy Transition was arrested on Sept. 15, according to The 88 Project, a group that advocates for freedom of expression in Vietnam. Police also raided and searched the offices of the think tank and interrogated staff members, it said. Police have said the earlier arrests of other energy experts were on suspicion of tax evasion. Vietnam is one of a few remaining communist single-party states that tolerate no dissent. In 2022, Human Rights Watch said that more than 170 activists had been put under house arrest, blocked from traveling or in some cases assaulted by agents of the Vietnamese government in a little-noticed campaign to silence its critics. The German government said in June that it was concerned by the earlier detention of a prominent environmental campaigner in Vietnam, warning that the JETP deal requires the involvement of civil society activists. The U.N. Development Program is helping Vietnam phase out use of fossil fuels with $15.5 billion in support from the Group of Seven advanced economies. \n",
      "Vietnamese energy think tank director arrested, marking sixth detention of climate expert in 2 years\n",
      "Vietnam authorities detained an energy think tank director on September 15, making it the sixth detention of a climate expert in the last two years, according to rights group.\n",
      "Ngo Thi To Nhien, the executive director for Vietnam Initiative for Energy Transition (VIET) was arrested on Sept. 15. Police also raided and searched the offices of the think tank and interrogated staff members. Police have said the earlier arrests of other energy experts were on suspicion of tax evasion. The German government said in June that it was concerned by the earlier detention of a prominent environmental campaigner in Vietnam, warning that the JETP deal requires the involvement of civil society activists. Vietnam is one of a few remaining communist single-party states that tolerate no dissent. In 2022, Human Rights Watch said that more than 170 activists had been put under house arrest, blocked from traveling or in some cases assaulted by agents of the Vietnamese government in a little-noticed campaign to silence its critics. The 88 Project, a group that advocates for freedom of expression in Vietnam said the detention is significant as it signals that research on energy policy is now off limits. It is the sixth expert working on environmental and climate issues that authorities have taken into custody in the past two years, a rights group said Wednesday. The U.N. Development Program was working with VIET to help implement the Just Energy Transition Partnership (JETP)  a deal designed to help the Southeast Asian nation phase out use of fossil fuels. \n",
      "1\n",
      "590\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a unbiased professional news article for:\n",
      "\n",
      "\n",
      "    Vietnam detains energy policy think-tank chief, human rights group says\n",
      "Ngo Thi To Nhien, the executive director for Vietnam Initiative for Energy Transition was arrested on Sept. 15, according to The 88 Project, a group that advocates for freedom of expression in Vietnam\n",
      "Ngo Thi To Nhien, the executive director for Vietnam Initiative for Energy Transition was arrested on Sept. 15, according to The 88 Project, a group that advocates for freedom of expression in Vietnam. Police also raided and searched the offices of the think tank and interrogated staff members, it said. Police have said the earlier arrests of other energy experts were on suspicion of tax evasion. Vietnam is one of a few remaining communist single-party states that tolerate no dissent. In 2022, Human Rights Watch said that more than 170 activists had been put under house arrest, blocked from traveling or in some cases assaulted by agents of the Vietnamese government in a little-noticed campaign to silence its critics. The German government said in June that it was concerned by the earlier detention of a prominent environmental campaigner in Vietnam, warning that the JETP deal requires the involvement of civil society activists. The U.N. Development Program is helping Vietnam phase out use of fossil fuels with $15.5 billion in support from the Group of Seven advanced economies. \n",
      "Vietnamese energy think tank director arrested, marking sixth detention of climate expert in 2 years\n",
      "Vietnam authorities detained an energy think tank director on September 15, making it the sixth detention of a climate expert in the last two years, according to rights group.\n",
      "Ngo Thi To Nhien, the executive director for Vietnam Initiative for Energy Transition (VIET) was arrested on Sept. 15. Police also raided and searched the offices of the think tank and interrogated staff members. Police have said the earlier arrests of other energy experts were on suspicion of tax evasion. The German government said in June that it was concerned by the earlier detention of a prominent environmental campaigner in Vietnam, warning that the JETP deal requires the involvement of civil society activists. Vietnam is one of a few remaining communist single-party states that tolerate no dissent. In 2022, Human Rights Watch said that more than 170 activists had been put under house arrest, blocked from traveling or in some cases assaulted by agents of the Vietnamese government in a little-noticed campaign to silence its critics. The 88 Project, a group that advocates for freedom of expression in Vietnam said the detention is significant as it signals that research on energy policy is now off limits. It is the sixth expert working on environmental and climate issues that authorities have taken into custody in the past two years, a rights group said Wednesday. The U.N. Development Program was working with VIET to help implement the Just Energy Transition Partnership (JETP)  a deal designed to help the Southeast Asian nation phase out use of fossil fuels.\n",
      "\n",
      "\n",
      "    CONSCISE UNBIASED detailed news article with at least 500 words:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Chain type: StuffDocumentsChain\n",
      "Run time: 30.485000000000582\n",
      "Summary: Vietnam Detains Energy Policy Think-Tank Chief, Human Rights Group Says  Ngo Thi To Nhien, the\n",
      "executive director for Vietnam Initiative for Energy Transition (VIET), was arrested on September\n",
      "15, according to The 88 Project, a group that advocates for freedom of expression in Vietnam. This\n",
      "marks the sixth detention of a climate expert in the country in the past two years, raising concerns\n",
      "about the government's treatment of environmental activists.  The arrest of Ngo Thi To Nhien was\n",
      "accompanied by a raid and search of the VIET offices, as well as the interrogation of staff members,\n",
      "according to The 88 Project. The Vietnamese police have stated that the earlier arrests of other\n",
      "energy experts were made on suspicion of tax evasion. However, human rights organizations and\n",
      "activists argue that these detentions are part of a broader campaign to silence dissent and stifle\n",
      "criticism of the government's policies.  Vietnam is known for being one of the few remaining\n",
      "communist single-party states that tolerate no dissent. In 2022, Human Rights Watch reported that\n",
      "more than 170 activists had been put under house arrest, blocked from traveling, or even assaulted\n",
      "by agents of the Vietnamese government. This campaign to silence critics has largely gone unnoticed\n",
      "by the international community.  The German government expressed concern in June over the detention\n",
      "of a prominent environmental campaigner in Vietnam, highlighting the importance of civil society\n",
      "activists in the implementation of the Just Energy Transition Partnership (JETP) deal. The JETP,\n",
      "supported by the United Nations Development Program and the Group of Seven advanced economies, aims\n",
      "to help Vietnam phase out the use of fossil fuels.  The arrest of Ngo Thi To Nhien is particularly\n",
      "significant as it signals that research on energy policy is now off-limits in Vietnam. The 88\n",
      "Project, which advocates for freedom of expression in the country, emphasized that this is the sixth\n",
      "detention of an expert working on environmental and climate issues in the past two years. This\n",
      "pattern raises concerns about the government's commitment to addressing climate change and\n",
      "transitioning to cleaner energy sources.  The United Nations Development Program has been working\n",
      "with VIET to implement the JETP, providing $15.5 billion in support from the Group of Seven advanced\n",
      "economies. The program's goal is to assist Vietnam in reducing its reliance on fossil fuels and\n",
      "promoting sustainable energy solutions. However, with the detention of Ngo Thi To Nhien and other\n",
      "climate experts, there are concerns about the government's willingness to engage with civil society\n",
      "and allow for open dialogue on energy policy.  The international community must pay attention to the\n",
      "situation in Vietnam and urge the government to respect freedom of expression and human rights. The\n",
      "detention of Ngo Thi To Nhien and other climate experts not only stifles important research and\n",
      "advocacy but also undermines efforts to address climate change and promote sustainable development\n",
      "in the country.  As the world faces the urgent challenges of climate change, it is crucial that\n",
      "governments support and encourage the work of experts and activists who are dedicated to finding\n",
      "solutions. The arrest of Ngo Thi To Nhien and the ongoing detention of climate experts in Vietnam is\n",
      "a step in the wrong direction and must be addressed by the international community.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "import tiktoken\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap\n",
    "from time import monotonic\n",
    "\n",
    "\n",
    "gpt_35_turbo_max_tokens = 4097\n",
    "verbose = True\n",
    "prompt_template = \"\"\"Write a unbiased professional news article for:\n",
    "\n",
    "\n",
    "    {text}\n",
    "\n",
    "\n",
    "    CONSCISE UNBIASED detailed news article with at least 500 words:\"\"\"\n",
    "OPENAI_API_KEY= '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'\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY, model_name=model_name)\n",
    "\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:    \n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    articles_grouped_l1(where: {articles_in_group: {_gt: 1}, _and: {articles_in_group: {_lt: 10}}}, limit: $limit, offset: $offset) {\n",
    "        article_ids\n",
    "    }\n",
    "    }\n",
    "'''\n",
    "graphql_grquery_article = '''\n",
    "query MyQuery($article_id: bigint!) {\n",
    "  rss1_articals(where: {id: {_eq: $article_id}}) {\n",
    "    title\n",
    "    summary\n",
    "    rss1_articles_detail {\n",
    "      summary\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "offset = 0\n",
    "variables = {\n",
    "\"limit\": 1,\n",
    "\"offset\": offset\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "for response in response_data['data']['articles_grouped_l1']:\n",
    "    llm_text = ''\n",
    "    for article in response['article_ids']:\n",
    "        print(article)\n",
    "        article_variables = {\n",
    "        \"article_id\": article\n",
    "        }\n",
    "        article_response_data = query_hasura_graphql(endpoint, admin_key, graphql_grquery_article, article_variables)\n",
    "        llm_text = llm_text + \"\\n\" +article_response_data['data']['rss1_articals'][0]['title'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['summary'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['rss1_articles_detail']['summary']\n",
    "    print(llm_text)\n",
    "\n",
    "\n",
    "    texts = text_splitter.split_text(llm_text)\n",
    "\n",
    "    docs = [Document(page_content=t) for t in texts]\n",
    "    print(len(docs))\n",
    "    \n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "    num_tokens = num_tokens_from_string(llm_text, model_name)\n",
    "    print(num_tokens)\n",
    "    if num_tokens < gpt_35_turbo_max_tokens:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt, verbose=verbose)\n",
    "    else:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=prompt, combine_prompt=prompt, verbose=verbose)\n",
    "\n",
    "    start_time = monotonic()\n",
    "    summary = chain.run(docs)\n",
    "\n",
    "    print(f\"Chain type: {chain.__class__.__name__}\")\n",
    "    print(f\"Run time: {monotonic() - start_time}\")\n",
    "    print(f\"Summary: {textwrap.fill(summary, width=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "145\n",
      "\n",
      "3 Idiots actor Akhil Mishra passes away in an accident\n",
      "Renowned actor Akhil Mishra, widely recognized for his portrayal of librarian Dubey in the Aamir Khan starrer \"3 Idiots,\" has passed away. ETimes TV has exclusively learnt about his demise. Sources have revealed that his wife, the actress Suzanne Bernert, was away in Hyderabad for a film shoot when this tragic incident occurred.\n",
      "Akhil Mishra, who played Librarian Dubey in Aamir Khan starrer 3 Idiots passes away in a SHOCKING incident. His wife and actress Suzanne Bernert was in Hyderabad for a shoot when the incident happened. Suzanna shared, My heart is broken, my second half is gone His last rites are going to be held at 3.30 pm today (September 21) at Indralok near Golden Nest. His body has been sent for post-mortem and wife Suzanne has been in shock since then. Akhil has also been a part of several TV shows like Bhanwar, Uttaran (Umed Singh Bundela), Udaan, CID, Shrimaan Shrimati, Bharat Ek Koj, Rajani, and many others. His film work includes Don, Well Don Abba, Hazaaron Khwaishein Aisi and more. He also made a mark by taking on the character of Umed Singh bundela in the popular show \"Uttaran.\" \n",
      "Akhil was my soulmate, my better half... I don't know what I'll do without him: Wife Suzanne Bernert\n",
      "Actor Akhil Mishra, known for his roles in films like 3 Idiots and Don, passed away at the age of 67. Mishra's wife, actress Suzanne Bernert, confirmed that he fell from a stool in their home.\n",
      "Akhil Mishra's wife, actress Suzanne Bernert, confirmed that he fell from a stool in their home. He is known for films like 3 Idiots, Don and has also been part of TV shows like Do Dil Bandhe Ek Dori Se, Uttaran and Sea Hawks. The Yeh Rishta Kya Kehlata Hain actress and Akhil tied the knot in 2009. He was still communicating and was telling them, 'I love Suzanne and I don't want to go to the hospital', but in the hospital, we got to know that he had an internal haemorrhage and there was a lot of blood loss and the doctors couldn't save him. A postmortem was done after which the last rites were performed. \"I don't know what I will do without him, I feel very lost,\" she said. He had stopped helping with household chores when he was unwell but as he felt better, he insisted on helping me. \n",
      "1\n",
      "588\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a unbiased professional news article for:\n",
      "\n",
      "\n",
      "    3 Idiots actor Akhil Mishra passes away in an accident\n",
      "Renowned actor Akhil Mishra, widely recognized for his portrayal of librarian Dubey in the Aamir Khan starrer \"3 Idiots,\" has passed away. ETimes TV has exclusively learnt about his demise. Sources have revealed that his wife, the actress Suzanne Bernert, was away in Hyderabad for a film shoot when this tragic incident occurred.\n",
      "Akhil Mishra, who played Librarian Dubey in Aamir Khan starrer 3 Idiots passes away in a SHOCKING incident. His wife and actress Suzanne Bernert was in Hyderabad for a shoot when the incident happened. Suzanna shared, My heart is broken, my second half is gone His last rites are going to be held at 3.30 pm today (September 21) at Indralok near Golden Nest. His body has been sent for post-mortem and wife Suzanne has been in shock since then. Akhil has also been a part of several TV shows like Bhanwar, Uttaran (Umed Singh Bundela), Udaan, CID, Shrimaan Shrimati, Bharat Ek Koj, Rajani, and many others. His film work includes Don, Well Don Abba, Hazaaron Khwaishein Aisi and more. He also made a mark by taking on the character of Umed Singh bundela in the popular show \"Uttaran.\" \n",
      "Akhil was my soulmate, my better half... I don't know what I'll do without him: Wife Suzanne Bernert\n",
      "Actor Akhil Mishra, known for his roles in films like 3 Idiots and Don, passed away at the age of 67. Mishra's wife, actress Suzanne Bernert, confirmed that he fell from a stool in their home.\n",
      "Akhil Mishra's wife, actress Suzanne Bernert, confirmed that he fell from a stool in their home. He is known for films like 3 Idiots, Don and has also been part of TV shows like Do Dil Bandhe Ek Dori Se, Uttaran and Sea Hawks. The Yeh Rishta Kya Kehlata Hain actress and Akhil tied the knot in 2009. He was still communicating and was telling them, 'I love Suzanne and I don't want to go to the hospital', but in the hospital, we got to know that he had an internal haemorrhage and there was a lot of blood loss and the doctors couldn't save him. A postmortem was done after which the last rites were performed. \"I don't know what I will do without him, I feel very lost,\" she said. He had stopped helping with household chores when he was unwell but as he felt better, he insisted on helping me.\n",
      "\n",
      "\n",
      "    CONSCISE UNBIASED detailed news article with at least 500 words:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Chain type: StuffDocumentsChain\n",
      "Run time: 36.07800000000134\n",
      "Summary: Renowned actor Akhil Mishra, best known for his role as librarian Dubey in the blockbuster film \"3\n",
      "Idiots,\" has tragically passed away in an accident. The news of his demise was exclusively reported\n",
      "by ETimes TV. According to sources, Mishra's wife, actress Suzanne Bernert, was away in Hyderabad\n",
      "for a film shoot when the incident occurred.  Akhil Mishra, who portrayed the memorable character of\n",
      "Librarian Dubey in the critically acclaimed film \"3 Idiots,\" has left his fans and the film industry\n",
      "in shock with his sudden demise. The actor's wife, Suzanne Bernert, who is also an actress, was away\n",
      "in Hyderabad for a shoot when the tragic incident took place. Devastated by the news, Bernert\n",
      "shared, \"My heart is broken, my second half is gone.\"  The last rites of Akhil Mishra are scheduled\n",
      "to be held at 3.30 pm today (September 21) at Indralok near Golden Nest. His body has been sent for\n",
      "post-mortem, and his wife Suzanne has been in a state of shock since the incident occurred. Mishra's\n",
      "contributions to the entertainment industry extend beyond his role in \"3 Idiots.\" He has also\n",
      "appeared in popular TV shows like \"Bhanwar,\" \"Uttaran,\" \"Udaan,\" \"CID,\" \"Shrimaan Shrimati,\" \"Bharat\n",
      "Ek Koj,\" \"Rajani,\" and many others. His filmography includes notable movies such as \"Don,\" \"Well Don\n",
      "Abba,\" and \"Hazaaron Khwaishein Aisi.\"  One of Mishra's most memorable roles was that of Umed Singh\n",
      "Bundela in the popular TV show \"Uttaran.\" His portrayal of the character left a lasting impact on\n",
      "the audience and showcased his versatility as an actor. Mishra's talent and dedication to his craft\n",
      "earned him a special place in the hearts of his fans and colleagues.  The circumstances surrounding\n",
      "Mishra's untimely demise are both shocking and heartbreaking. According to his wife Suzanne Bernert,\n",
      "Mishra fell from a stool in their home, leading to his tragic accident. The couple had been married\n",
      "since 2009 and shared a deep bond. Bernert expressed her grief, saying, \"Akhil was my soulmate, my\n",
      "better half... I don't know what I'll do without him.\"  Mishra's filmography and television\n",
      "appearances speak volumes about his talent and versatility as an actor. He effortlessly portrayed a\n",
      "wide range of characters, leaving a lasting impression on the audience. His performances in films\n",
      "like \"3 Idiots\" and \"Don\" showcased his ability to bring depth and authenticity to his roles.  In\n",
      "addition to his successful acting career, Mishra was known for his humility and dedication to his\n",
      "craft. Colleagues and friends remember him as a warm and kind-hearted individual who always brought\n",
      "positivity to the sets. His sudden departure has left a void in the industry that will be difficult\n",
      "to fill.  The news of Akhil Mishra's passing has sent shockwaves through the entertainment industry,\n",
      "with fans and colleagues expressing their condolences and sharing fond memories of the talented\n",
      "actor. The loss of such a talented individual is a reminder of the fragility of life and the\n",
      "importance of cherishing every moment.  As the industry mourns the loss of Akhil Mishra, his legacy\n",
      "as a versatile actor and a kind-hearted individual will continue to live on. His contributions to\n",
      "the world of entertainment will be remembered and celebrated for years to come. Our thoughts and\n",
      "prayers go out to his family and loved ones during this difficult time.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "gpt_35_turbo_max_tokens = 4097\n",
    "verbose = True\n",
    "prompt_template = \"\"\"Write a unbiased professional news article for:\n",
    "\n",
    "\n",
    "    {text}\n",
    "\n",
    "\n",
    "    CONSCISE UNBIASED detailed news article with at least 500 words:\"\"\"\n",
    "OPENAI_API_KEY= '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'\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY, model_name=model_name)\n",
    "\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:    \n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    articles_grouped_l1(where: {articles_in_group: {_gt: 1}, _and: {articles_in_group: {_lt: 10}}}, limit: $limit, offset: $offset) {\n",
    "        article_ids\n",
    "    }\n",
    "    }\n",
    "'''\n",
    "graphql_grquery_article = '''\n",
    "query MyQuery($article_id: bigint!) {\n",
    "  rss1_articals(where: {id: {_eq: $article_id}}) {\n",
    "    title\n",
    "    summary\n",
    "    rss1_articles_detail {\n",
    "      summary\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "offset = 1\n",
    "variables = {\n",
    "\"limit\": 1,\n",
    "\"offset\": offset\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "for response in response_data['data']['articles_grouped_l1']:\n",
    "    llm_text = ''\n",
    "    for article in response['article_ids']:\n",
    "        print(article)\n",
    "        article_variables = {\n",
    "        \"article_id\": article\n",
    "        }\n",
    "        article_response_data = query_hasura_graphql(endpoint, admin_key, graphql_grquery_article, article_variables)\n",
    "        llm_text = llm_text + \"\\n\" +article_response_data['data']['rss1_articals'][0]['title'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['summary'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['rss1_articles_detail']['summary']\n",
    "    print(llm_text)\n",
    "\n",
    "\n",
    "    texts = text_splitter.split_text(llm_text)\n",
    "\n",
    "    docs = [Document(page_content=t) for t in texts]\n",
    "    print(len(docs))\n",
    "    \n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "    num_tokens = num_tokens_from_string(llm_text, model_name)\n",
    "    print(num_tokens)\n",
    "    if num_tokens < gpt_35_turbo_max_tokens:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt, verbose=verbose)\n",
    "    else:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=prompt, combine_prompt=prompt, verbose=verbose)\n",
    "\n",
    "    start_time = monotonic()\n",
    "    summary = chain.run(docs)\n",
    "\n",
    "    print(f\"Chain type: {chain.__class__.__name__}\")\n",
    "    print(f\"Run time: {monotonic() - start_time}\")\n",
    "    print(f\"Summary: {textwrap.fill(summary, width=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "689\n",
      "61\n",
      "694\n",
      "\n",
      "Putin to meet China's foreign minister in Russia: Kremlin\n",
      "According to the Kremlin, Russian President Vladimir Putin will host China's foreign minister Wang Yi for discussions in Saint Petersburg on Wednesday. The senior Chinese ambassador is in Russia for a four-day visit, the latest in a series of high-level meetings between Moscow and Beijing.\n",
      "Vladimir Putin will host China's foreign minister Wang Yi for discussions in Saint Petersburg. The senior Chinese ambassador is in Russia for a four-day visit. It is the latest in a series of high-level meetings between Moscow and Beijing. The Kremlin has sought to deepen ties with China after the start of its Ukraine offensive, which has thrown Moscow into increasing isolation. China has tried to position itself as a neutral party in the Ukraine conflict, while offering Moscow a vital diplomatic and financial lifeline. In March, China's leader Xi Jinping made a state visit to Moscow, where he and Putin sought to showcase a united front against Western countries. The top Chinese diplomat met Russian Foreign Minister Sergei Lavrov on Monday. According to a Chinese state media readout, Wang reiterated Beijing's position paper on the Ukraine Conflict. It called for peace talks but was met with scepticism by the United States and NATO when it was released earlier this year. Russia and China frequently tout their \"no limits\" partnership and economic and military cooperation. \n",
      "Russia hails similarity of Chinas position on U.S., Ukraine\n",
      "Russia and China frequently tout their \"no limits\" partnership and economic and military cooperation\n",
      "Russia hails similarity of Chinas position on U.S., Ukraine. Russia and China frequently tout their \"no limits\" partnership and economic and military cooperation. China's Wang Yi kicked off a four-day visit to Moscow with a meeting with Russian Foreign Minister Sergei Lavrov. Wang reiterated Beijing's position paper on the Ukraine conflict, which called for peace talks but was met with scepticism by the United States and NATO when it was released earlier this year. During his visit, Mr. Wang is due to hold security consultations at the invitation of Nikolai Patrushev, secretary of Russia's security council. President Xi Jinping made a state Visit to Moscow in March and declared that relations between the two countries were entering a new era. An aide to Vladimir Putin said in July that the Russian President was planning to visit China in October. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. For support in the UK, call the National Suicide Prevention Lifeline at 1-800-273-8255 or visit www.suicidepreventionlifeline.org. For help in the U.K., contact the National suicide Prevention Line on 1-844-788-88 or click here. \n",
      "Beijing, Moscow must deepen cooperation: China foreign minister\n",
      "Beijing's top diplomat told President Vladimir Putin that China and Russia must work to strengthen cooperation in the face of a \"complex international situation\", Chinese state media reported Thursday. \"Both sides need to strengthen their multilateral strategic cooperation, protect their legitimate rights and interests, and make new efforts to promote the international order toward fairness and justice,\" he added.\n",
      "Beijing's top diplomat told President Vladimir Putin that China and Russia must work to strengthen cooperation in the face of a \"complex international situation\" Wang Yi said the \"world is rapidly moving toward multipolarity\" Putin, in response, told Wang \"our positions coincide regarding the emergence of a multipolar world\", according to a readout from the Kremlin. The Kremlin has sought to deepen ties with China after the start of its Ukraine offensive, which has thrown Moscow into increasing isolation. China has tried to position itself as a neutral party in the Ukraine conflict, while offering Moscow a vital diplomatic and financial lifeline. The two countries describe each other as strategic allies, with both countries frequently touting their \"no limits\" partnership and economic and military cooperation. They came even closer after the started of Russia's offensive in Ukraine in February last year, which China has refused to condemn. The Russian leader accepted an invitation to visit China next month, at which the Chinese foreign minister said he was looking forward to meeting him. \n",
      "Putin and Xi to meet in Beijing in October, Russia says\n",
      "In Beijing, Vladimir Putin will take part in a forum on China's Belt and Road Initiative\n",
      "Russian President Vladimir Putin will travel to Beijing in October for talks with China's Xi Jinping. In Beijing, Mr. Putin will take part in a forum on China's Belt and Road Initiative. \"We look forward to thorough bilateral talks,\" Russia's Security Council secretary says in a meeting in Moscow with Chinas top diplomat, Wang Yi. The two leaders will meet in October, the secretary of the Security Council says. The talks will take place at the Diaoyutai State Guest House in Beijing. \n",
      "1\n",
      "988\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a unbiased professional news article for:\n",
      "\n",
      "\n",
      "    Putin to meet China's foreign minister in Russia: Kremlin\n",
      "According to the Kremlin, Russian President Vladimir Putin will host China's foreign minister Wang Yi for discussions in Saint Petersburg on Wednesday. The senior Chinese ambassador is in Russia for a four-day visit, the latest in a series of high-level meetings between Moscow and Beijing.\n",
      "Vladimir Putin will host China's foreign minister Wang Yi for discussions in Saint Petersburg. The senior Chinese ambassador is in Russia for a four-day visit. It is the latest in a series of high-level meetings between Moscow and Beijing. The Kremlin has sought to deepen ties with China after the start of its Ukraine offensive, which has thrown Moscow into increasing isolation. China has tried to position itself as a neutral party in the Ukraine conflict, while offering Moscow a vital diplomatic and financial lifeline. In March, China's leader Xi Jinping made a state visit to Moscow, where he and Putin sought to showcase a united front against Western countries. The top Chinese diplomat met Russian Foreign Minister Sergei Lavrov on Monday. According to a Chinese state media readout, Wang reiterated Beijing's position paper on the Ukraine Conflict. It called for peace talks but was met with scepticism by the United States and NATO when it was released earlier this year. Russia and China frequently tout their \"no limits\" partnership and economic and military cooperation. \n",
      "Russia hails similarity of Chinas position on U.S., Ukraine\n",
      "Russia and China frequently tout their \"no limits\" partnership and economic and military cooperation\n",
      "Russia hails similarity of Chinas position on U.S., Ukraine. Russia and China frequently tout their \"no limits\" partnership and economic and military cooperation. China's Wang Yi kicked off a four-day visit to Moscow with a meeting with Russian Foreign Minister Sergei Lavrov. Wang reiterated Beijing's position paper on the Ukraine conflict, which called for peace talks but was met with scepticism by the United States and NATO when it was released earlier this year. During his visit, Mr. Wang is due to hold security consultations at the invitation of Nikolai Patrushev, secretary of Russia's security council. President Xi Jinping made a state Visit to Moscow in March and declared that relations between the two countries were entering a new era. An aide to Vladimir Putin said in July that the Russian President was planning to visit China in October. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. For support in the UK, call the National Suicide Prevention Lifeline at 1-800-273-8255 or visit www.suicidepreventionlifeline.org. For help in the U.K., contact the National suicide Prevention Line on 1-844-788-88 or click here. \n",
      "Beijing, Moscow must deepen cooperation: China foreign minister\n",
      "Beijing's top diplomat told President Vladimir Putin that China and Russia must work to strengthen cooperation in the face of a \"complex international situation\", Chinese state media reported Thursday. \"Both sides need to strengthen their multilateral strategic cooperation, protect their legitimate rights and interests, and make new efforts to promote the international order toward fairness and justice,\" he added.\n",
      "Beijing's top diplomat told President Vladimir Putin that China and Russia must work to strengthen cooperation in the face of a \"complex international situation\" Wang Yi said the \"world is rapidly moving toward multipolarity\" Putin, in response, told Wang \"our positions coincide regarding the emergence of a multipolar world\", according to a readout from the Kremlin. The Kremlin has sought to deepen ties with China after the start of its Ukraine offensive, which has thrown Moscow into increasing isolation. China has tried to position itself as a neutral party in the Ukraine conflict, while offering Moscow a vital diplomatic and financial lifeline. The two countries describe each other as strategic allies, with both countries frequently touting their \"no limits\" partnership and economic and military cooperation. They came even closer after the started of Russia's offensive in Ukraine in February last year, which China has refused to condemn. The Russian leader accepted an invitation to visit China next month, at which the Chinese foreign minister said he was looking forward to meeting him. \n",
      "Putin and Xi to meet in Beijing in October, Russia says\n",
      "In Beijing, Vladimir Putin will take part in a forum on China's Belt and Road Initiative\n",
      "Russian President Vladimir Putin will travel to Beijing in October for talks with China's Xi Jinping. In Beijing, Mr. Putin will take part in a forum on China's Belt and Road Initiative. \"We look forward to thorough bilateral talks,\" Russia's Security Council secretary says in a meeting in Moscow with Chinas top diplomat, Wang Yi. The two leaders will meet in October, the secretary of the Security Council says. The talks will take place at the Diaoyutai State Guest House in Beijing.\n",
      "\n",
      "\n",
      "    CONSCISE UNBIASED detailed news article with at least 500 words:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Chain type: StuffDocumentsChain\n",
      "Run time: 27.625\n",
      "Summary: Putin to meet China's foreign minister in Russia: Kremlin  Russian President Vladimir Putin is set\n",
      "to host China's foreign minister Wang Yi for discussions in Saint Petersburg on Wednesday, according\n",
      "to the Kremlin. Wang is in Russia for a four-day visit, marking the latest in a series of high-level\n",
      "meetings between Moscow and Beijing.  The Kremlin has been actively seeking to deepen ties with\n",
      "China following the start of its Ukraine offensive, which has resulted in increasing isolation for\n",
      "Moscow. China, on the other hand, has positioned itself as a neutral party in the Ukraine conflict\n",
      "while offering diplomatic and financial support to Russia.  In March, Chinese leader Xi Jinping made\n",
      "a state visit to Moscow, during which he and Putin aimed to showcase a united front against Western\n",
      "countries. This visit further solidified the partnership between the two nations.  Wang's visit to\n",
      "Russia includes a meeting with Russian Foreign Minister Sergei Lavrov, where he reiterated Beijing's\n",
      "position paper on the Ukraine conflict. The paper called for peace talks but was met with skepticism\n",
      "by the United States and NATO when it was released earlier this year.  Russia and China frequently\n",
      "emphasize their \"no limits\" partnership, highlighting their economic and military cooperation. This\n",
      "partnership has become even more significant since Russia's offensive in Ukraine, as China has\n",
      "refused to condemn Russia's actions.  The meeting between Putin and Wang is expected to further\n",
      "strengthen the cooperation between Russia and China. Both leaders have expressed the need for closer\n",
      "ties in the face of a complex international situation. Wang emphasized the importance of protecting\n",
      "their legitimate rights and interests and promoting a fair and just international order.  The\n",
      "Kremlin has been actively working to deepen its relationship with China, as it seeks to counter the\n",
      "increasing isolation resulting from its actions in Ukraine. China, on the other hand, sees an\n",
      "opportunity to strengthen its position on the global stage by aligning itself with Russia.  The two\n",
      "countries describe each other as strategic allies and have been actively promoting their economic\n",
      "and military cooperation. This partnership has been further solidified by their shared opposition to\n",
      "Western countries' actions and their desire for a multipolar world.  In October, Putin is set to\n",
      "travel to Beijing for talks with Chinese President Xi Jinping. The meeting will take place during a\n",
      "forum on China's Belt and Road Initiative, a major infrastructure project aimed at enhancing\n",
      "connectivity and trade between Asia, Europe, and Africa.  The upcoming meeting between Putin and Xi\n",
      "is expected to further deepen the cooperation between Russia and China. Both leaders have expressed\n",
      "their eagerness for thorough bilateral talks and are looking forward to discussing various issues of\n",
      "mutual interest.  Overall, the meeting between Putin and Wang, as well as the upcoming meeting\n",
      "between Putin and Xi, highlight the growing partnership between Russia and China. Both countries see\n",
      "the need to strengthen their cooperation in the face of a complex international situation and are\n",
      "actively working towards that goal.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "import tiktoken\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap\n",
    "from time import monotonic\n",
    "\n",
    "\n",
    "gpt_35_turbo_max_tokens = 4097\n",
    "verbose = True\n",
    "prompt_template = \"\"\"Write a unbiased professional news article for:\n",
    "\n",
    "\n",
    "    {text}\n",
    "\n",
    "\n",
    "    CONSCISE UNBIASED detailed news article with at least 500 words:\"\"\"\n",
    "OPENAI_API_KEY= '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'\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY, model_name=model_name)\n",
    "\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:    \n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    articles_grouped_l1(where: {articles_in_group: {_gt: 3}, _and: {articles_in_group: {_lt: 10}}}, limit: $limit, offset: $offset) {\n",
    "        article_ids\n",
    "    }\n",
    "    }\n",
    "'''\n",
    "graphql_grquery_article = '''\n",
    "query MyQuery($article_id: bigint!) {\n",
    "  rss1_articals(where: {id: {_eq: $article_id}}) {\n",
    "    title\n",
    "    summary\n",
    "    rss1_articles_detail {\n",
    "      summary\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "offset = 0\n",
    "variables = {\n",
    "\"limit\": 1,\n",
    "\"offset\": offset\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "for response in response_data['data']['articles_grouped_l1']:\n",
    "    llm_text = ''\n",
    "    for article in response['article_ids']:\n",
    "        print(article)\n",
    "        article_variables = {\n",
    "        \"article_id\": article\n",
    "        }\n",
    "        article_response_data = query_hasura_graphql(endpoint, admin_key, graphql_grquery_article, article_variables)\n",
    "        llm_text = llm_text + \"\\n\" +article_response_data['data']['rss1_articals'][0]['title'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['summary'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['rss1_articles_detail']['summary']\n",
    "    print(llm_text)\n",
    "\n",
    "\n",
    "    texts = text_splitter.split_text(llm_text)\n",
    "\n",
    "    docs = [Document(page_content=t) for t in texts]\n",
    "    print(len(docs))\n",
    "    \n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "    num_tokens = num_tokens_from_string(llm_text, model_name)\n",
    "    print(num_tokens)\n",
    "    if num_tokens < gpt_35_turbo_max_tokens:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt, verbose=verbose)\n",
    "    else:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=prompt, combine_prompt=prompt, verbose=verbose)\n",
    "\n",
    "    start_time = monotonic()\n",
    "    summary = chain.run(docs)\n",
    "\n",
    "    print(f\"Chain type: {chain.__class__.__name__}\")\n",
    "    print(f\"Run time: {monotonic() - start_time}\")\n",
    "    print(f\"Summary: {textwrap.fill(summary, width=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "import tiktoken\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap\n",
    "from time import monotonic\n",
    "\n",
    "\n",
    "gpt_35_turbo_max_tokens = 4097\n",
    "verbose = True\n",
    "prompt_template = \"\"\"Write a unbiased professional news article for:\n",
    "\n",
    "\n",
    "    {text}\n",
    "\n",
    "\n",
    "    CONSCISE UNBIASED detailed news article with at least 500 words:\"\"\"\n",
    "OPENAI_API_KEY= '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'\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY, model_name=model_name)\n",
    "\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:    \n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    articles_grouped_l1(where: {articles_in_group: {_gt: 4}, _and: {articles_in_group: {_lt: 10}}}, limit: $limit, offset: $offset) {\n",
    "        article_ids\n",
    "    }\n",
    "    }\n",
    "'''\n",
    "graphql_grquery_article = '''\n",
    "query MyQuery($article_id: bigint!) {\n",
    "  rss1_articals(where: {id: {_eq: $article_id}}) {\n",
    "    title\n",
    "    summary\n",
    "    rss1_articles_detail {\n",
    "      summary\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "offset = 1\n",
    "variables = {\n",
    "\"limit\": 1,\n",
    "\"offset\": offset\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "for response in response_data['data']['articles_grouped_l1']:\n",
    "    llm_text = ''\n",
    "    for article in response['article_ids']:\n",
    "        print(article)\n",
    "        article_variables = {\n",
    "        \"article_id\": article\n",
    "        }\n",
    "        article_response_data = query_hasura_graphql(endpoint, admin_key, graphql_grquery_article, article_variables)\n",
    "        llm_text = llm_text + \"\\n\" +article_response_data['data']['rss1_articals'][0]['title'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['summary'] + \"\\n\" + article_response_data['data']['rss1_articals'][0]['rss1_articles_detail']['summary']\n",
    "    print(llm_text)\n",
    "\n",
    "\n",
    "    texts = text_splitter.split_text(llm_text)\n",
    "\n",
    "    docs = [Document(page_content=t) for t in texts]\n",
    "    print(len(docs))\n",
    "    \n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "    num_tokens = num_tokens_from_string(llm_text, model_name)\n",
    "    print(num_tokens)\n",
    "    if num_tokens < gpt_35_turbo_max_tokens:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt, verbose=verbose)\n",
    "    else:\n",
    "      chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=prompt, combine_prompt=prompt, verbose=verbose)\n",
    "\n",
    "    start_time = monotonic()\n",
    "    summary = chain.run(docs)\n",
    "\n",
    "    print(f\"Chain type: {chain.__class__.__name__}\")\n",
    "    print(f\"Run time: {monotonic() - start_time}\")\n",
    "    print(f\"Summary: {textwrap.fill(summary, width=100)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "Como a fruta mais fedida do mundo pode ajudar a gerar energia para seu telefone\n",
      "\n",
      "Elas so o corao da tecnologia porttil moderna. As baterias de on de ltio transformaram nossa capacidade de armazenar e transportar energia e, por sua vez, revolucionaram os dispositivos que usamos.\n",
      "\n",
      "Comercializadas pela Sony em 1991, quando a empresa buscava uma soluo para a durao limitada da bateria de suas cmeras de vdeo portteis, elas fornecem energia a muitos dos gadgets que usamos hoje - de smartphones e laptops a escovas de dente eltricas e aspiradores de p de mo. No fim do ano passado, os trs cientistas por trs de sua inveno ganharam o Prmio Nobel de Qumica por possibilitar essa revoluo tcnica.\n",
      "\n",
      "E nossa necessidade por elas s tende a crescer. Os veculos eltricos dependem de baterias de on-ltio como um substituto para os combustveis fsseis que usamos atualmente para abastecer nossos carros. Como as fontes de energia renovveis constituem a maior parte do suprimento de eletricidade em todo o mundo,  provvel que sejam necessrios enormes bancos de baterias para armazenar o excesso de energia quando o vento no sopra ou o Sol no est brilhando.\n",
      "\n",
      "Em todo o mundo, mais de 7 bilhes de baterias de on-ltio so vendidas a cada ano e espera-se que esse nmero cresa para mais de 15 bilhes at 2027.\n",
      "\n",
      "Mas, como sabemos por nossos telefones, que armazenam cada vez menos energia  medida que envelhecem, as baterias de on de ltio apresentam limitaes. Com o tempo, sua capacidade de reter uma carga diminui, o que significa que elas armazenam menos energia.\n",
      "\n",
      "Em climas extremamente quentes ou frios, seu desempenho tambm cai. E tambm existem preocupaes em torno de sua segurana e sustentabilidade - elas podem pegar fogo e explodir sob certas condies, enquanto a minerao dos metais necessrios para fabric-las tem um alto custo social e ambiental.\n",
      "\n",
      "Isso vem estimulando cientistas de todo o mundo a tentar desenvolver novos tipos de bateria que possam superar esses obstculos. Ao aproveitar uma variedade de materiais, de diamantes a frutas super fedidas, eles esperam encontrar novas maneiras de impulsionar as tecnologias do futuro.\n",
      "\n",
      "As baterias de on-ltio funcionam permitindo que partculas (ons) de ltio carregadas movam eletricidade de uma extremidade  outra, passando por um eletrlito lquido no meio. Uma das coisas que torna as baterias de on de ltio to atraentes  sua \"densidade de energia\" - a energia mxima que uma bateria pode armazenar proporcionalmente a seu volume - que  uma das mais altas de qualquer bateria disponvel comercialmente no mercado. Elas tambm podem fornecer tenses mais altas do que outras tecnologias de bateria.\n",
      "\n",
      "As baterias so essencialmente feitas de trs componentes principais - um eletrodo negativo (nodo), um eletrodo positivo (ctodo) e um eletrlito entre eles. As funes dos eletrodos alternam entre ctodo e nodo, dependendo se a bateria est carregando ou descarregando.\n",
      "\n",
      "Em baterias de on de ltio, o ctodo  normalmente feito de um xido de metal e outro metal. Ao carregar, os ons de ltio e eltrons se movem do ctodo para o nodo, onde so \"armazenados\" como potencial eletroqumico. Isso ocorre por meio de uma srie de reaes qumicas no eletrlito que so acionadas pela energia eltrica que flui do circuito de carga.\n",
      "\n",
      "Quando uma bateria est em uso, os ons de ltio fluem na direo oposta do nodo para o ctodo atravs do eletrlito, enquanto os eltrons fluem atravs do circuito eltrico do dispositivo em que a bateria est instalada, fornecendo energia.\n",
      "\n",
      "Ao longo dos anos, ajustes nos materiais usados no ctodo e no nodo ajudaram a melhorar a capacidade e a densidade de energia das baterias de ons de ltio, mas as melhorias mais substanciais foram na queda do custo das baterias.\n",
      "\n",
      "\"Chegou a um ponto em que a qumica desenvolvida 35 anos atrs se estabilizou\", diz Mauro Pasta, professor-associado de materiais da Universidade de Oxford, no Reino Unido, e lder de projeto na The Faraday Institution, que est trabalhando na prxima fase das baterias de on-ltio.\n",
      "\n",
      "Seu objetivo  aumentar a densidade de energia das baterias de on de ltio e, ao mesmo tempo, ampliar sua eficincia para que no percam energia com cargas e descargas repetidas.\n",
      "\n",
      "Para fazer isso, o professor Pasta est focado em substituir o fluido eletroltico altamente inflamvel encontrado em baterias de on-ltio modernas por um slido feito de cermica. O uso de um slido reduz o risco de combusto de eletrlitos no caso de uma clula curta ou instvel, que estava por trs do recall de 2017 da Samsung de 2,5 milhes de Galaxy Note 7s aps uma srie de incndios por problemas na bateria.\n",
      "\n",
      "Isso  importante para a segurana do usurio e de seu entorno, pois at mesmo o eletrlito de gel de polmero encontrado na maioria de nossos eletrnicos portteis ainda  inflamvel.\n",
      "\n",
      "Essa bateria de estado slido tambm possibilita o uso de metal de ltio denso em vez do nodo de grafite, o que aumenta significativamente a quantidade de energia que pode armazenar no processo. Neste sentido, pode ter implicaes enormes no futuro dos automveis.\n",
      "\n",
      "No momento, todo veculo eltrico contm o equivalente a milhares de baterias de iPhone. Como os veculos eltricos parecem destinados a substituir aqueles movidos a combustveis fsseis em muitos pases nos prximos anos, a mudana para baterias de estado slido significaria viagens mais longas e mais tempo entre as recargas.\n",
      "\n",
      "Nossa sede por bateria s tende a crescer nos prximos anos, ao passo que cada vez mais meios de transporte se tornam eltricos e a variedade de parafernlias eletrnicas portteis em nossas vidas s aumenta. Sendo assim, devemos procurar alternativas ao ltio que possam diminuir o impacto no meio ambiente?\n",
      "\n",
      "A regio do \"Tringulo de Ltio\" dos Andes - que inclui partes da Argentina, Bolvia e Chile - contm pouco mais da metade dos recursos naturais mundiais do metal. Mas extra-lo requer gua - muita gua. Na regio do Salar de Atacama, no Chile, cerca de 1 milho de litros de gua so usados no processo de minerao para produzir apenas 900 kg de ltio. O processo envolve a purificao dos sais ricos em metais dissolvendo-os progressivamente em gua, filtrando e evaporando a salmoura at que o sal de ltio puro seja obtido. rgos ambientais administrados pelo governo chileno, no entanto, alertaram que a minerao de metais - principalmente de ltio e cobre - na regio est usando mais gua do que  substituda por neve e chuva.\n",
      "\n",
      "Para contornar isso, pesquisadores do Instituto de Tecnologia de Karlsruhe esto trabalhando em baterias que usam diferentes metais no nodo, como clcio ou magnsio. O clcio  o quinto elemento mais abundante na crosta terrestre e  improvvel que sofra dos mesmos problemas de abastecimento que o ltio, mas as pesquisas para melhorar o desempenho das baterias que o utilizam ainda esto engatinhando. O magnsio tambm apresenta resultados iniciais promissores, principalmente em termos de densidade energtica, e h planos de comercializao no futuro.\n",
      "\n",
      "Mas h quem esteja buscando alternativas em materiais mais amplamente disponveis, incluindo a madeira, por exemplo.\n",
      "\n",
      "Liangbing Hu, diretor do Centro de Inovao de Materiais da Universidade de Maryland, nos Estados Unidos, construiu recentemente uma bateria usando pedaos de madeira porosos e furados como eletrodos, dentro dos quais ons metlicos reagem para gerar uma carga eltrica. A madeira  abundante, de baixo custo e leve, e apresenta alto potencial de desempenho em baterias. As baterias mais recentes foram produzidas aps anos de pesquisa sobre a capacidade desse material de armazenar energia, incluindo o revestimento de fibras de celulose de madeira em estanho.\n",
      "\n",
      "Como a madeira evoluiu naturalmente para ser permevel aos nutrientes conforme eles so transportados pela planta, o material faz eletrodos com a capacidade de armazenar ons de metal sem o risco de se espandir ou encolher perigosamente, como pode ocorrer com os eletrodos de bateria de on de ltio.\n",
      "\n",
      "Embora a equipe de Hu preveja que as baterias  base de madeira vo poder ser usadas em nossos eletrnicos portteis, bem como no armazenamento de energia em grande escala em determinado momento, ainda no poderemos carregar nossos laptops com elas, pois ainda esto sendo testadas em laboratrios.\n",
      "\n",
      "Essas baterias perdem a capacidade de armazenar uma carga relativamente rpida - um prottipo s conseguia manter 61% de sua capacidade inicial aps 100 ciclos de recarga. No momento, a quantidade de madeira usada  de vrios centmetros de largura e comprimento, e as baterias podem ser empilhadas ou conectadas para aplicaes em larga escala, o que pode eventualmente ser til para armazenar energia em casas ou outros edifcios.\n",
      "\n",
      "O ltio no  o nico metal encontrado na maioria das baterias modernas - a maioria tambm usa cobalto em combinao com ltio no ctodo. A minerao de cobalto gera um impacto txico que afeta a sade das comunidades que vivem no entorno das minas e tambm o meio ambiente. A minerao de cobalto tambm  prejudicada pelo uso de trabalho infantil, especialmente na Repblica Democrtica do Congo, na frica, pas que abriga mais da metade das minas de cobalto do mundo. As principais empresas de tecnologia, incluindo Apple, Tesla e Microsoft, foram recentemente processadas por mortes na minerao de cobalto.\n",
      "\n",
      "\"Todo mundo est carregando uma bateria de on de ltio extrada por crianas\", diz Jodie Lutkenhaus, engenheira qumica da Texas A&M University, nos Estados Unidos.\n",
      "\n",
      "Isso a inspirou a desenvolver alternativas para essas \"baterias de sangue\" usando protenas, as molculas complexas criadas e usadas por organismos vivos. Os nodos das baterias tendem a ser feitos de grafite e os ctodos so feitos de xidos de metal que contm elementos como o cobalto. Se eles puderem ser substitudos por materiais orgnicos para ambos os eletrodos ativos, isso significa que o cobalto no precisar mais ser extrado.\n",
      "\n",
      "Isso no apenas descarta a necessidade de metais txicos que precisam ser extrados do solo, mas tambm lana luz sobre outro legado ambiental das baterias de on-ltio. Se eliminados aps o uso em aterros sanitrios, os metais e eletrlitos do on de ltio podem vazar para o meio ambiente, causando mais danos. Atualmente, apenas cerca de 5% das baterias de on-ltio usadas nos 1,5 bilho de smartphones vendidos a cada ano so recicladas.\n",
      "\n",
      "Desenvolvida em colaborao com sua colega Karen Wooley, na Texas A&M University, a bateria de protena de Lutkenhaus  a primeira clula de energia do mundo que se degrada a partir de sua dissoluo em um cido, o que significa que pode ser facilmente quebrada e usada novamente.\n",
      "\n",
      "Embora ela ainda no possa competir com o on de ltio - s fornece at 1,5 V por cerca de 50 ciclos de recarga antes de perder potncia - faz parte de uma srie de iniciativas sobre como a sustentabilidade est sendo levada em conta para o design de novas baterias.\n",
      "\n",
      "Super fruta\n",
      "Em outro desdobramento, um grupo de pesquisadores no est apenas tentando encontrar novas maneiras de fornecer energia a nossos dispositivos, mas tambm lidar com o problema do desperdcio de alimentos ao mesmo tempo.\n",
      "\n",
      "Vincent Gomes, engenheiro qumico da Universidade de Sydney, e sua equipe, incluindo Labna Shabnam, esto transformando os resduos da fruta mais fedorenta do mundo, o durio, e da maior fruta do mundo, a jaca, em um supercapacitor que pode carregar telefones celulares, tablets e laptops em minutos.\n",
      "\n",
      "Os supercapacitores so uma forma alternativa de armazenamento de energia. Eles agem como reservatrios, capazes de carregar rapidamente e, em seguida, descarregar energia em rajadas. Eles tendem a ser feitos de materiais caros como o grafeno, mas a equipe de Gomes transformou partes no comestveis de durio e jaca em aerogis de carbono - slidos superleves porosos - com propriedades \"excepcionais\" de armazenamento natural de energia. Eles aqueceram, liofilizaram e depois assaram o ncleo esponjoso no comestvel de cada fruta em um forno a temperaturas de mais de 1.500 C. As estruturas pretas, altamente porosas e ultraleves que resultaram desse processo poderiam ser transformadas em eletrodos de um supercapacitor de baixo custo.\n",
      "\n",
      "Os supercapacitores podem ser carregados em 30 segundos e usados para alimentar uma variedade de dispositivos.\n",
      "\n",
      "\"Ser capaz de carregar um telefone celular em um minuto  incrvel\", diz Shabnam.\n",
      "\n",
      "O sonho dos pesquisadores  usar esses supercapacitores sustentveis para armazenar eletricidade de fontes renovveis de energia para uso em veculos e residncias.\n",
      "\n",
      "E isso antes de considerar os benefcios de encontrar um uso verde para o durio, j que mais de 70% dessas frutas tendem a ser jogadas fora.\n",
      "\n",
      "Em 2018, o mau cheiro impediu temporariamente a decolagem de um avio na Indonsia. Tambm levou a uma evacuao em massa de uma biblioteca da Universidade de Canberra, na Austrlia, no ano passado.\n",
      "\n",
      "Nos estgios iniciais de sua pesquisa, o fedor se tornou um desafio para a mulher de Gomes, que retirou todos os restos da fruta fedorenta do freezer depois de apenas uma noite.\n",
      "\n",
      "Outros tipos de resduos de plantas tambm podem ser usados para alimentar os dispositivos do futuro. Mikhail Astakhov, fsico qumico da Universidade Nacional de Cincia e Tecnologia (MISiS) em Moscou, na Rssia, transformou a hogweed, uma erva daninha de seiva txica que pode provocar bolhas quando em contato com a pele humana, em uma matria-prima para um supercapacitor tecnicamente capaz de carregar um telefone.\n",
      "\n",
      "Baterias so para sempre\n",
      "Embora o impacto ambiental das baterias de on-ltio concentre as atenes da comunidade cientfica, outros pesquisadores vm se dedicando a enfrentar outras limitaes desse dispositivo.\n",
      "\n",
      "Tom Scott, professor de materiais da Universidade de Bristol, no Reino Unido, diz no acreditar que as baterias de on-ltio vo perder espao em seu uso convencional no prximo sculo. Mas, segundo ele, existem oportunidades quando se trata de armazenar energia em ambientes mais extremos.\n",
      "\n",
      "\n",
      "CONSCISE SUMMARY IN PORTUGUESE:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "Baterias so para sempre\n",
      "Embora o impacto ambiental das baterias de on-ltio concentre as atenes da comunidade cientfica, outros pesquisadores vm se dedicando a enfrentar outras limitaes desse dispositivo.\n",
      "\n",
      "Tom Scott, professor de materiais da Universidade de Bristol, no Reino Unido, diz no acreditar que as baterias de on-ltio vo perder espao em seu uso convencional no prximo sculo. Mas, segundo ele, existem oportunidades quando se trata de armazenar energia em ambientes mais extremos.\n",
      "\n",
      "Junto com sua equipe, Scott tem desenvolvido baterias feitas de diamantes. Ao produzir diamantes artificiais que contm carbono-14 radioativo, os pesquisadores conseguiram criar \"baterias betavoltaicas\" que produzem uma corrente constante e podem durar milhares de anos.\n",
      "\n",
      "Presos dentro da rede de diamante, os istopos radioativos disparam eltrons de energia superalta  medida que sofrem decaimento nuclear. Isso, por sua vez, cria uma chuva de eltrons atravs da estrutura do diamante que pode ser aproveitada para produzir uma corrente eltrica.\n",
      "\n",
      "Do lado de fora, a radioatividade permaneceria em nveis seguros, dizem os pesquisadores.\n",
      "\n",
      "A equipe j criou um prottipo de \"bateria de diamante\" usando diamantes artificiais colocados dentro de um campo radioativo produzido pelo istopo Nquel-63, que dispara um fluxo de eltrons atravs do diamante. Mas agora eles esto trabalhando em uma verso que usa carbono-14 extrado de blocos de grafite usados em usinas nucleares. Ao transformar esse lixo nuclear em uma bateria de longa durao, Scott e seus colegas esperam encontrar novo uso para o resduo dessas usinas  medida que elas so desativadas.\n",
      "\n",
      "\"Trata-se de uma reviravolta\", diz Sophie Osbourne, que integra a equipe de Scott. \"Por muito tempo, coletamos lixo nuclear e agora no estamos mais falando sobre armazenamento de longo prazo, mas sim reaproveit-lo para produzir eletricidade.\"\n",
      "\n",
      "Apesar de as baterias qumicas como o on-ltio no terem bom desempenho em altas temperaturas, as de diamante podem funcionar em ambientes mais extremos onde no faltam alternativas, como no espao, no fundo do mar ou talvez no topo de um vulco. Elas seriam perfeitas para manter satlites e sensores computadorizados funcionando, por exemplo.\n",
      "\n",
      "\"As baterias so absolutamente minsculas\", diz Scott. At agora, os pesquisadores conseguiram gerar baterias de diamante que produzem 1,8 volts - semelhante a uma bateria AA - embora tenha uma corrente muito mais baixa. Elas tambm so tecnicamente recarregveis, mas exigiriam algumas horas dentro de um ncleo de reator para atingir sua potncia original, diz Scott.\n",
      "\n",
      "Embora o fluxo constante de corrente criado  medida que o material radioativo decai signifique que elas iro emitir eletricidade por um tempo incrivelmente longo - o carbono tem meia-vida de 5.730 anos, acrescentam os pesquisadores.\n",
      "\n",
      "Apesar de serem feitas de diamante,  improvvel que, uma vez comercializadas, essas baterias sejam caras, diz Scott.\n",
      "\n",
      "\"Voc ficaria surpreso com quo pouco os diamantes artificiais podem custar\".\n",
      "\n",
      "Nas prximas duas dcadas, Scott diz acreditar que poderamos at mesmo comear a ver baterias de diamante de ultra-longa durao aparecerem em nossas casas, talvez em detectores de fumaa ou controles remotos de TV, ou em dispositivos mdicos, como aparelhos auditivos ou marca-passos.\n",
      "\n",
      "\n",
      "CONSCISE SUMMARY IN PORTUGUESE:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "Cientistas esto buscando alternativas para as baterias de on-ltio, que apresentam limitaes em termos de capacidade de reteno de carga, desempenho em climas extremos, segurana e sustentabilidade. Alguns pesquisadores esto desenvolvendo baterias de estado slido, que substituem o eletrlito lquido inflamvel por um slido feito de cermica, aumentando a segurana. Outros esto explorando o uso de materiais mais abundantes, como clcio e magnsio, em vez de ltio, para reduzir o impacto ambiental da minerao. Alm disso, esto sendo desenvolvidas baterias feitas de materiais orgnicos, como\n",
      "\n",
      "Pesquisadores da Universidade de Bristol, no Reino Unido, esto desenvolvendo baterias feitas de diamantes que podem durar milhares de anos. Essas \"baterias betavoltaicas\" utilizam diamantes artificiais contendo carbono-14 radioativo, que produzem uma corrente constante atravs do decaimento nuclear. A equipe est trabalhando em uma verso que utiliza carbono-14 extrado de blocos de grafite usados em usinas nucleares, transformando esse lixo nuclear em uma bateria de longa durao. Essas baterias de diamante podem ser usadas em ambientes extremos, como no espao ou no fundo do mar, e podem ser aplicadas em satlites, sensores computadorizados e dispositivos mdicos. Apesar de serem feitas de diamante, espera-se que essas baterias sejam acessveis quando comercializadas.\n",
      "\n",
      "\n",
      "CONSCISE SUMMARY IN PORTUGUESE:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Chain type: MapReduceDocumentsChain\n",
      "Run time: 28.235000000000582\n",
      "Summary: Cientistas esto desenvolvendo alternativas para as baterias de on-ltio, como baterias de estado\n",
      "slido e o uso de materiais mais abundantes, como clcio e magnsio. Pesquisadores da Universidade\n",
      "de Bristol esto trabalhando em baterias feitas de diamantes contendo carbono-14 radioativo, que\n",
      "podem durar milhares de anos. Essas baterias podem ser usadas em ambientes extremos e tm potencial\n",
      "aplicao em satlites, sensores e dispositivos mdicos. Espera-se que sejam acessveis quando\n",
      "comercializadas.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rss1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
