{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "endpoint = \"https://active-monitor-48.hasura.app/v1/graphql\"\n",
    "admin_key = \"bAQuK7HSYvMAp6S6pnqXH0wQlyuKNUICzoW3jwecc27pwz6COLhE750s5YAec7Hz\"\n",
    "#gogole api key: AIzaSyBDO1QimPJXn-RDMbxCMc0ieHgH7_1SCXQ\n",
    "def query_hasura_graphql(endpoint, admin_key, query, variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'query': query,\n",
    "        'variables': variables\n",
    "    }\n",
    "    response = requests.post(endpoint, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def mutation_hasura_graphql(endpoint, admin_key, mutation_query, mutation_variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "    response = requests.post(endpoint, json={'query': mutation_query, 'variables': mutation_variables}, headers=headers)\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "        return True, data\n",
    "    else:\n",
    "        print(f\"Mutation failed with status code {response.status_code}: {response.text}\")\n",
    "        return False, None\n",
    "def all():\n",
    "    graphql_query = '''\n",
    "    query MyQuery {\n",
    "        synopse_articles_t_v1_outlets {\n",
    "            outlet\n",
    "            main_url\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "    }\n",
    "    mutation_query = \"\"\"\n",
    "        mutation MyMutation($objects: [synopse_articles_t_v1_rss1_feed_links_insert_input!] = {}) {\n",
    "            insert_synopse_articles_t_v1_rss1_feed_links(objects: $objects, on_conflict: {constraint: t_v1_rss1_feed_links_rss1_link_key}) {\n",
    "                affected_rows\n",
    "            }\n",
    "        }\n",
    "        \"\"\"\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    #print(response_data)\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.page_load_strategy = 'eager'\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    for response in response_data['data']['synopse_articles_t_v1_outlets']:\n",
    "        url = response['main_url']\n",
    "        print(url)\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(10)\n",
    "        SCROLL_PAUSE_TIME = 0.5  # You can set your own pause time. This is set to 0.5 seconds.\n",
    "\n",
    "        # Get scroll height\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while True:\n",
    "            # Scroll down to bottom\n",
    "            driver.execute_script(\"window.scrollBy(0, 1000);\")  # Scroll down by 1000 pixels.\n",
    "\n",
    "            # Wait to load the page\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "        print(response['outlet'])\n",
    "        feed=[]\n",
    "        if response['outlet'] == \"timesofindia\":\n",
    "            elements = driver.find_elements(By.XPATH, '//*[@id=\"main-copy\"]/p[*]/table/tbody/tr[*]/td[1]/a')\n",
    "            for element in elements:\n",
    "                feed.append({\n",
    "                                \"outlet\": response['outlet'],\n",
    "                                \"rss1_link_name\": element.text,\n",
    "                                \"rss1_link\": element.get_attribute(\"href\"),\n",
    "                                \"rss1_link_type\": 0\n",
    "                            }\n",
    "                        )\n",
    "        elif response['outlet'] == \"thehindu\":\n",
    "            elements = driver.find_elements(By.XPATH, '//*/li/a')\n",
    "            for element in elements:\n",
    "                if element.text != \"\" and element.get_attribute(\"href\")[-4:] == \".rss\":\n",
    "                    feed.append({\n",
    "                                    \"outlet\": response['outlet'],\n",
    "                                    \"rss1_link_name\": element.text,\n",
    "                                    \"rss1_link\": element.get_attribute(\"href\"),\n",
    "                                    \"rss1_link_type\": 0\n",
    "                                }\n",
    "                            )\n",
    "        elif response['outlet'] == \"foxnews\": \n",
    "            elements = driver.find_elements(By.XPATH, '//*/a')\n",
    "            for element in elements:\n",
    "                if element.text != \"\" and element.get_attribute(\"href\")[-4:] == \".xml\":    \n",
    "                    feed.append({\n",
    "                                    \"outlet\": response['outlet'],\n",
    "                                    \"rss1_link_name\": element.text.split(\"/\")[-1][:-4],\n",
    "                                    \"rss1_link\": element.get_attribute(\"href\"),\n",
    "                                    \"rss1_link_type\": 0\n",
    "                                }\n",
    "                            )\n",
    "        elif response['outlet'] == \"cnn\":        \n",
    "            elements = driver.find_elements(By.XPATH, '//*/td/a')\n",
    "            for element in elements:\n",
    "                if element.text.split(\"_\")[-1][:-4] != \"\" and element.get_attribute(\"href\")[-4:] == \".rss\":    \n",
    "                    feed.append({\n",
    "                                    \"outlet\": response['outlet'],\n",
    "                                    \"rss1_link_name\": element.text.split(\"_\")[-1][:-4],\n",
    "                                    \"rss1_link\": element.get_attribute(\"href\"),\n",
    "                                    \"rss1_link_type\": 0\n",
    "                                }\n",
    "                            )\n",
    "        elif response['outlet'] == \"nytimes\":    \n",
    "            elements = driver.find_elements(By.XPATH, '//a')\n",
    "            for element in elements:\n",
    "                if element.text != \"\" and element.get_attribute(\"href\")[-4:] == \".xml\":\n",
    "                     \n",
    "                    feed.append({\n",
    "                                    \"outlet\": response['outlet'],\n",
    "                                    \"rss1_link_name\": element.text.split(\"/\")[-1][:-4],\n",
    "                                    \"rss1_link\": element.get_attribute(\"href\"),\n",
    "                                    \"rss1_link_type\": 0\n",
    "                                }\n",
    "                            )\n",
    "        mutation_variables = {\n",
    "            \"objects\": feed\n",
    "        }\n",
    "        #print({'query': mutation_query, 'variables': mutation_variables})\n",
    "        out1 = mutation_hasura_graphql(endpoint = endpoint, admin_key = admin_key, mutation_query = mutation_query, mutation_variables = mutation_variables)\n",
    "\n",
    "    driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://timesofindia.indiatimes.com/rss.cms\n",
      "timesofindia\n",
      "{'data': {'insert_synopse_articles_t_v1_rss1_feed_links': {'affected_rows': 0}}}\n",
      "https://www.thehindu.com/rssfeeds/\n",
      "thehindu\n",
      "{'data': {'insert_synopse_articles_t_v1_rss1_feed_links': {'affected_rows': 0}}}\n",
      "https://edition.cnn.com/services/rss/\n",
      "cnn\n",
      "{'data': {'insert_synopse_articles_t_v1_rss1_feed_links': {'affected_rows': 0}}}\n",
      "https://www.foxnews.com/story/foxnews-com-rss-feeds\n",
      "foxnews\n",
      "{'data': {'insert_synopse_articles_t_v1_rss1_feed_links': {'affected_rows': 0}}}\n",
      "https://www.nytimes.com/rss\n",
      "nytimes\n",
      "{'data': {'insert_synopse_articles_t_v1_rss1_feed_links': {'affected_rows': 0}}}\n"
     ]
    }
   ],
   "source": [
    "all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.nytimes.com/rss\n",
      "nytimes\n",
      "NYTimes.com Home Page (U.S.)\n",
      "World\n",
      "Africa\n",
      "Americas\n",
      "Asia Pacific\n",
      "Europe\n",
      "Middle East\n",
      "U.S.\n",
      "Education\n",
      "Politics\n",
      "The Upshot\n",
      "N.Y./Region\n",
      "Business\n",
      "Energy & Environment\n",
      "Small Business\n",
      "Economy\n",
      "DealBook\n",
      "Media & Advertising\n",
      "Your Money\n",
      "Technology\n",
      "Personal Tech\n",
      "Sports\n",
      "Baseball\n",
      "College Basketball\n",
      "College Football\n",
      "Golf\n",
      "Hockey\n",
      "Pro-Basketball\n",
      "Pro-Football\n",
      "Soccer\n",
      "Tennis\n",
      "Science\n",
      "Environment\n",
      "Space & Cosmos\n",
      "Health\n",
      "Well Blog\n",
      "Arts\n",
      "Art & Design\n",
      "Book Review\n",
      "Dance\n",
      "Movies\n",
      "Music\n",
      "Television\n",
      "Theater\n",
      "Fashion & Style\n",
      "Dining & Wine\n",
      "Love\n",
      "T Magazine\n",
      "Travel\n",
      "Jobs\n",
      "Real Estate\n",
      "Autos\n",
      "Lens Blog\n",
      "Obituaries\n",
      "Most E-Mailed\n",
      "Most Shared\n",
      "Most Viewed\n",
      "Charles M. Blow\n",
      "Jamelle Bouie\n",
      "David Brooks\n",
      "Frank Bruni\n",
      "Gail Collins\n",
      "Ross Douthat\n",
      "Maureen Dowd\n",
      "Thomas L. Friedman\n",
      "Michelle Goldberg\n",
      "Ezra Klein\n",
      "Nicholas D. Kristof\n",
      "Paul Krugman\n",
      "Farhad Manjoo\n",
      "Bret Stephens\n",
      "Sunday Opinion\n",
      "{'data': {'insert_synopse_articles_t_v1_rss1_feed_links': {'affected_rows': 64}}}\n"
     ]
    }
   ],
   "source": [
    "def all():\n",
    "    graphql_query = '''\n",
    "    query MyQuery {\n",
    "        synopse_articles_t_v1_outlets(where: {outlet: {_eq: \"nytimes\"}}) {\n",
    "            main_url\n",
    "            outlet\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    # Define the variables dictionary\n",
    "    variables = {\n",
    "    }\n",
    "    mutation_query = \"\"\"\n",
    "        mutation MyMutation($objects: [synopse_articles_t_v1_rss1_feed_links_insert_input!] = {}) {\n",
    "            insert_synopse_articles_t_v1_rss1_feed_links(objects: $objects, on_conflict: {constraint: t_v1_rss1_feed_links_rss1_link_key}) {\n",
    "                affected_rows\n",
    "            }\n",
    "        }\n",
    "        \"\"\"\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    #print(response_data)\n",
    "    chrome_options = Options()\n",
    "    #chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.page_load_strategy = 'eager'\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    for response in response_data['data']['synopse_articles_t_v1_outlets']:\n",
    "        url = response['main_url']\n",
    "        print(url)\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(10)\n",
    "        print(response['outlet'])\n",
    "        driver.implicitly_wait(10)\n",
    "        feed=[]\n",
    "        if response['outlet'] == \"timesofindia\":\n",
    "            elements = driver.find_elements(By.XPATH, '//*[@id=\"main-copy\"]/p[*]/table/tbody/tr[*]/td[1]/a')\n",
    "            for element in elements:\n",
    "                feed.append({\n",
    "                                \"outlet\": response['outlet'],\n",
    "                                \"rss1_link_name\": element.text,\n",
    "                                \"rss1_link\": element.get_attribute(\"href\"),\n",
    "                                \"rss1_link_type\": 0\n",
    "                            }\n",
    "                        )\n",
    "        elif response['outlet'] == \"thehindu\":\n",
    "            elements = driver.find_elements(By.XPATH, '//*/li/a')\n",
    "            for element in elements:\n",
    "                if element.text != \"\" and element.get_attribute(\"href\")[-4:] == \".rss\":\n",
    "                    feed.append({\n",
    "                                    \"outlet\": response['outlet'],\n",
    "                                    \"rss1_link_name\": element.text,\n",
    "                                    \"rss1_link\": element.get_attribute(\"href\"),\n",
    "                                    \"rss1_link_type\": 0\n",
    "                                }\n",
    "                            )\n",
    "        elif response['outlet'] == \"foxnews\": \n",
    "            driver.get(url)\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "            elements = driver.find_elements(By.XPATH, '//a')\n",
    "            for element in elements:\n",
    "                if element.text != \"\" and element.get_attribute(\"href\")[-4:] == \".xml\":    \n",
    "                    feed.append({\n",
    "                                    \"outlet\": response['outlet'],\n",
    "                                    \"rss1_link_name\": element.text.split(\"/\")[-1][:-4],\n",
    "                                    \"rss1_link\": element.get_attribute(\"href\"),\n",
    "                                    \"rss1_link_type\": 0\n",
    "                                }\n",
    "                            )\n",
    "        elif response['outlet'] == \"cnn\":        \n",
    "            elements = driver.find_elements(By.XPATH, '//*/td/a')\n",
    "            for element in elements:\n",
    "                if element.text.split(\"_\")[-1][:-4] != \"\" and element.get_attribute(\"href\")[-4:] == \".rss\":    \n",
    "                    feed.append({\n",
    "                                    \"outlet\": response['outlet'],\n",
    "                                    \"rss1_link_name\": element.text.split(\"_\")[-1][:-4],\n",
    "                                    \"rss1_link\": element.get_attribute(\"href\"),\n",
    "                                    \"rss1_link_type\": 0\n",
    "                                }\n",
    "                            )\n",
    "        elif response['outlet'] == \"nytimes\":\n",
    "            elements = driver.find_elements(By.XPATH, '//a')\n",
    "            for element in elements:\n",
    "                if element.text != \"\" and element.get_attribute(\"href\")[-4:] == \".xml\":    \n",
    "                    print(element.text)\n",
    "                    feed.append({\n",
    "                                    \"outlet\": response['outlet'],\n",
    "                                    \"rss1_link_name\": element.text,\n",
    "                                    \"rss1_link\": element.get_attribute(\"href\"),\n",
    "                                    \"rss1_link_type\": 0\n",
    "                                }\n",
    "                            )\n",
    "            \n",
    "        \n",
    "        mutation_variables = {\n",
    "            \"objects\": feed\n",
    "        }\n",
    "        #print({'query': mutation_query, 'variables': mutation_variables})\n",
    "        out1 = mutation_hasura_graphql(endpoint = endpoint, admin_key = admin_key, mutation_query = mutation_query, mutation_variables = mutation_variables)\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "all()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rss1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
