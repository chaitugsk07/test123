{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime, timezone\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "import pyperclip\n",
    "import time\n",
    "\n",
    "#git add . && git commit -m \"initial commit\" && git push origin main\n",
    "\n",
    "endpoint = \"https://active-monitor-48.hasura.app/v1/graphql\"\n",
    "admin_key = \"bAQuK7HSYvMAp6S6pnqXH0wQlyuKNUICzoW3jwecc27pwz6COLhE750s5YAec7Hz\"\n",
    "\n",
    "def query_hasura_graphql(endpoint, admin_key, query, variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'query': query,\n",
    "        'variables': variables\n",
    "    }\n",
    "    response = requests.post(endpoint, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def is_valid_timezone_format(published):\n",
    "    try:\n",
    "        # Attempt to parse the string\n",
    "        date_format = \"%a, %d %b %Y %H:%M:%S %z\"\n",
    "        date_object = datetime.strptime(published, date_format)\n",
    "        \n",
    "        hasura_timestamp = date_object.astimezone(timezone.utc).isoformat()\n",
    "        return True, hasura_timestamp\n",
    "    except ValueError:\n",
    "        # If parsing fails, the string is not in the correct format\n",
    "        return False, None\n",
    "\n",
    "def check_date_format(date_string):\n",
    "    try:\n",
    "        datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "        \n",
    "def mutation_hasura_graphql(endpoint, admin_key, mutation_query, mutation_variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "    response = requests.post(endpoint, json={'query': mutation_query, 'variables': mutation_variables}, headers=headers)\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "        return True, data\n",
    "    else:\n",
    "        print(f\"Mutation failed with status code {response.status_code}: {response.text}\")\n",
    "        return False, None\n",
    "\n",
    "def update_article_details(offset1):\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    synopse_articles_t_v1_rss1_articles(limit: $limit, offset: $offset, where: {is_in_detail: {_eq: 0}}, order_by: {post_published: desc}) {\n",
    "        post_link\n",
    "        is_default_image\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [synopse_articles_t_v1_rss1_articles_detail_insert_input!] = {}, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = {where: {}}) {\n",
    "        insert_synopse_articles_t_v1_rss1_articles_detail(objects: $objects, on_conflict: {constraint: t_v1_rss1_articles_detail_article_id_key}) {\n",
    "            affected_rows\n",
    "        }\n",
    "        update_synopse_articles_t_v1_rss1_articles_many(updates: $updates) {\n",
    "            affected_rows\n",
    "        }\n",
    "        }\n",
    "\n",
    "    \"\"\"    \n",
    "    options = webdriver.EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "        \"profile.default_content_setting_values.notifications\": 2,  # Disable notifications\n",
    "        \"profile.default_content_setting_values.media_stream_mic\": 2,  # Disable microphone\n",
    "        \"profile.default_content_setting_values.media_stream_camera\": 2,  # Disable camera\n",
    "        \"profile.default_content_setting_values.geolocation\": 2,  # Disable location services\n",
    "        \"profile.default_content_setting_values.automatic_downloads\": 2  # Disable automatic downloads\n",
    "    })\n",
    "    options.add_argument(\"--no-first-run\")  # Skip the welcome page\n",
    "    options.add_argument(\"--disable-infobars\")  # Disable the info bars\n",
    "    options.add_argument(\"--disable-extensions\")  # Disable extensions\n",
    "    options.add_argument(\"--disable-popup-blocking\")  # Disable popups\n",
    "    options.add_argument(\"--disable-features=EdgeTips\") \n",
    "    options.page_load_strategy = 'eager'\n",
    "    options.add_argument('--enable-immersive-reader')\n",
    "    driver = webdriver.Edge(options=options)\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 2,\n",
    "        \"offset\": offset1\n",
    "        }\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        #print(variables, response_data)\n",
    "        #print(response_data)\n",
    "        post_links_array = []\n",
    "        ids=[]\n",
    "        is_default_image_array = []\n",
    "        if response_data:\n",
    "            post_links_array = [item[\"post_link\"] for item in response_data[\"data\"][\"synopse_articles_t_v1_rss1_articles\"]]\n",
    "            is_default_image_array = [item[\"is_default_image\"] for item in response_data[\"data\"][\"synopse_articles_t_v1_rss1_articles\"]]\n",
    "            ids=[item[\"id\"] for item in response_data[\"data\"][\"synopse_articles_t_v1_rss1_articles\"]]\n",
    "        articles_detail = []\n",
    "        articles_update = []\n",
    "        if len(post_links_array) == 0:\n",
    "            break\n",
    "        try:\n",
    "            for a in range(len(post_links_array)):\n",
    "                main_link = post_links_array[a]\n",
    "                print(main_link)\n",
    "                driver.get(main_link)\n",
    "                time.sleep(2)\n",
    "                get_url = driver.current_url\n",
    "                read_link= \"read://aqq\"+get_url\n",
    "                driver.get(read_link)\n",
    "                time.sleep(2)\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('a').key_up(Keys.CONTROL).perform()\n",
    "                ActionChains(driver).key_down(Keys.CONTROL).send_keys('c').key_up(Keys.CONTROL).perform()\n",
    "                text = pyperclip.paste()\n",
    "                text2 = text\n",
    "                text3 = text2.split('\\n')\n",
    "                text3 = [s.replace('\\r', '') for s in text3]\n",
    "                special_chars = set(\"!@#$%^&*()_+[]{}|;:'\\\",<>?\")\n",
    "                text4 = [s for s in text3 if len(s) > 0 and (s[0] not in special_chars or s[-1] not in special_chars)]\n",
    "                my_list = text4\n",
    "                if ' '.join(my_list) == \"Hmmm… can't reach this page\":\n",
    "                    offset = offset + 1\n",
    "                    break\n",
    "                my_set = set()\n",
    "                desription = []\n",
    "                for item in my_list:\n",
    "                    if item not in my_set:\n",
    "                        desription.append(item)\n",
    "                        my_set.add(item)\n",
    "                #print(desription)\n",
    "                images_final = []\n",
    "                articles_detail.append({\n",
    "                    \"article_id\": ids[a],\n",
    "                    \"title\": desription[0],\n",
    "                    \"description\": desription[1:],\n",
    "                    \"image_link\": images_final,\n",
    "                }\n",
    "                )\n",
    "                if (is_default_image_array[a] == 0 and len(images_final) > 0):\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1 , \"image_link\": images_final[0], \"is_default_image\": 1}\n",
    "                    })\n",
    "                else:\n",
    "                    articles_update.append({\n",
    "                        \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                        \"_set\": {\"is_in_detail\": 1}\n",
    "                    })\n",
    "                \n",
    "                #print(main_link, desription[0], desription[1:], images_final)\n",
    "            #print(articles_update)\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "            break\n",
    "        except:\n",
    "            offset = offset + 1\n",
    "            mutation_variables = {\n",
    "            \"objects\": articles_detail,\n",
    "            \"updates\": articles_update,\n",
    "            }\n",
    "            out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "    driver.quit() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.thehindu.com/news/international/us-venezuela-swap-prisoners-maduro-ally-for-10-americans-plus-fugitive-contractor-fat-leonard/article67662305.ece\n",
      "[\"Hmmm… can't reach this pageIt looks like the webpage at read://aqqhttps//www.thehindu.com/news/international/us-venezuela-swap-prisoners-maduro-ally-for-10-americans-plus-fugitive-contractor-fat-leonard/article67662305.ece might be having issues or it may have moved permanently to a new web address.\", 'ERR_FAILED']\n",
      "https://www.thehindu.com/news/international/un-says-up-to-300000-sudanese-fled-their-homes-after-a-notorious-group-seized-their-safe-haven/article67662367.ece\n",
      "{'data': {'insert_synopse_articles_t_v1_rss1_articles_detail': {'affected_rows': 1}, 'update_synopse_articles_t_v1_rss1_articles_many': [{'affected_rows': 1}]}}\n",
      "https://www.thehindu.com/news/international/un-says-up-to-300000-sudanese-fled-their-homes-after-a-notorious-group-seized-their-safe-haven/article67662367.ece\n",
      "[\"Hmmm… can't reach this pageIt looks like the webpage at read://aqqhttps//www.thehindu.com/news/international/un-says-up-to-300000-sudanese-fled-their-homes-after-a-notorious-group-seized-their-safe-haven/article67662367.ece might be having issues or it may have moved permanently to a new web address.\", 'ERR_FAILED']\n",
      "https://www.thehindu.com/news/international/north-koreas-kim-again-threatens-use-of-nukes-as-he-praises-troops-for-long-range-missile-launch/article67662351.ece\n"
     ]
    }
   ],
   "source": [
    "update_article_details(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The string starts with 'Hmmm… can't reach this pageIt'\n"
     ]
    }
   ],
   "source": [
    "t1 = [\"Hmmm… can't reach this pageIt looks like the webpage at read://aqqhttps//www.thehindu.com/news/international/us-venezuela-swap-prisoners-maduro-ally-for-10-americans-plus-fugitive-contractor-fat-leonard/article67662305.ece might be having issues or it may have moved permanently to a new web address.\", 'ERR_FAILED']\n",
    "\n",
    "if t1[0].startswith(\"Hmmm… can't reach this pageIt\"):\n",
    "    print(\"The string starts with 'Hmmm… can't reach this pageIt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'webdriver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\D\\30_git\\test123\\samples\\get_article_details.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/get_article_details.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m graphql_query \u001b[39m=\u001b[39m \u001b[39m'''\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/get_article_details.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mquery MyQuery($limit: Int!, $offset: Int!) \u001b[39m\u001b[39m{\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/get_article_details.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39msynopse_articles_t_v1_rss1_articles(limit: $limit, offset: $offset, where: \u001b[39m\u001b[39m{\u001b[39m\u001b[39mis_in_detail: \u001b[39m\u001b[39m{_eq: 0}\u001b[39;00m\u001b[39m}, order_by: \u001b[39m\u001b[39m{\u001b[39m\u001b[39mpost_published: desc}) \u001b[39m\u001b[39m{\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/get_article_details.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m}\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/get_article_details.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m'''\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/get_article_details.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m mutation_query \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/get_article_details.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mmutation MyMutation($objects: [synopse_articles_t_v1_rss1_articles_detail_insert_input!] = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = \u001b[39m\u001b[39m{\u001b[39m\u001b[39mwhere: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m}) \u001b[39m\u001b[39m{\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/get_article_details.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m    insert_synopse_articles_t_v1_rss1_articles_detail(objects: $objects, on_conflict: \u001b[39m\u001b[39m{\u001b[39m\u001b[39mconstraint: t_v1_rss1_articles_detail_article_id_key}) \u001b[39m\u001b[39m{\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/get_article_details.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/get_article_details.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m    \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/get_article_details.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m options \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39mEdgeOptions()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/get_article_details.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m options\u001b[39m.\u001b[39muse_chromium \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/D/30_git/test123/samples/get_article_details.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m options\u001b[39m.\u001b[39mpage_load_strategy \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39meager\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'webdriver' is not defined"
     ]
    }
   ],
   "source": [
    "graphql_query = '''\n",
    "query MyQuery($limit: Int!, $offset: Int!) {\n",
    "synopse_articles_t_v1_rss1_articles(limit: $limit, offset: $offset, where: {is_in_detail: {_eq: 0}}, order_by: {post_published: desc}) {\n",
    "    post_link\n",
    "    is_default_image\n",
    "    id\n",
    "    }\n",
    "}\n",
    "'''\n",
    "mutation_query = \"\"\"\n",
    "mutation MyMutation($objects: [synopse_articles_t_v1_rss1_articles_detail_insert_input!] = {}, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = {where: {}}) {\n",
    "    insert_synopse_articles_t_v1_rss1_articles_detail(objects: $objects, on_conflict: {constraint: t_v1_rss1_articles_detail_article_id_key}) {\n",
    "        affected_rows\n",
    "    }\n",
    "    update_synopse_articles_t_v1_rss1_articles_many(updates: $updates) {\n",
    "        affected_rows\n",
    "    }\n",
    "    }\n",
    "\n",
    "\"\"\"    \n",
    "options = webdriver.EdgeOptions()\n",
    "options.use_chromium = True\n",
    "options.page_load_strategy = 'eager'\n",
    "options.add_argument('--enable-immersive-reader')\n",
    "driver = webdriver.Edge(options=options)\n",
    "variables = {\n",
    "\"limit\": 8,\n",
    "\"offset\": 0\n",
    "}\n",
    "response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "#print(variables, response_data)\n",
    "#print(response_data)\n",
    "post_links_array = []\n",
    "ids=[]\n",
    "is_default_image_array = []\n",
    "if response_data:\n",
    "    post_links_array = [item[\"post_link\"] for item in response_data[\"data\"][\"synopse_articles_t_v1_rss1_articles\"]]\n",
    "    is_default_image_array = [item[\"is_default_image\"] for item in response_data[\"data\"][\"synopse_articles_t_v1_rss1_articles\"]]\n",
    "    ids=[item[\"id\"] for item in response_data[\"data\"][\"synopse_articles_t_v1_rss1_articles\"]]\n",
    "articles_detail = []\n",
    "articles_update = []\n",
    "for a in range(len(post_links_array)):\n",
    "    main_link = post_links_array[a]\n",
    "    driver.execute_script(\"window.open('');\")\n",
    "    driver.switch_to.window(driver.window_handles[a + 1])\n",
    "    driver.get(main_link)\n",
    "for a in range(len(post_links_array)):\n",
    "    driver.switch_to.window(driver.window_handles[a + 1])\n",
    "    get_url = driver.current_url\n",
    "    read_link= \"read://\"+get_url\n",
    "    driver.get(read_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "\n",
    "def mousemove():\n",
    "    start_x, start_y = 90, 90\n",
    "    side_length = 100\n",
    "    pyautogui.moveTo(start_x, start_y)\n",
    "    pyautogui.moveTo(start_x + side_length, start_y)\n",
    "    pyautogui.moveTo(start_x + side_length, start_y + side_length)\n",
    "    pyautogui.moveTo(start_x, start_y + side_length)\n",
    "    pyautogui.moveTo(start_x, start_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime, timezone\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "import pyperclip\n",
    "import multiprocessing\n",
    "import time\n",
    "import psutil\n",
    "import shutil\n",
    "import pyautogui\n",
    "\n",
    "#git add . && git commit -m \"initial commit\" && git push origin main\n",
    "\n",
    "endpoint = \"https://active-monitor-48.hasura.app/v1/graphql\"\n",
    "admin_key = \"bAQuK7HSYvMAp6S6pnqXH0wQlyuKNUICzoW3jwecc27pwz6COLhE750s5YAec7Hz\"\n",
    "\n",
    "\n",
    "def mousemove():\n",
    "    start_x, start_y = 90, 90\n",
    "    side_length = 100\n",
    "    pyautogui.moveTo(start_x, start_y)\n",
    "    pyautogui.moveTo(start_x + side_length, start_y)\n",
    "    pyautogui.moveTo(start_x + side_length, start_y + side_length)\n",
    "    pyautogui.moveTo(start_x, start_y + side_length)\n",
    "    pyautogui.moveTo(start_x, start_y)\n",
    "    \n",
    "def delete_tmp():\n",
    "    rootDir = '/tmp'\n",
    "    for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "        if dirName.startswith(rootDir + \"/.com.microsoft\"):\n",
    "            try:\n",
    "                shutil.rmtree(dirName)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"No directories found starting with '.com.microsoft'\")\n",
    "                break\n",
    "\t\n",
    "def query_hasura_graphql(endpoint, admin_key, query, variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'query': query,\n",
    "        'variables': variables\n",
    "    }\n",
    "    response = requests.post(endpoint, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def is_valid_timezone_format(published):\n",
    "    try:\n",
    "        # Attempt to parse the string\n",
    "        date_format = \"%a, %d %b %Y %H:%M:%S %z\"\n",
    "        date_object = datetime.strptime(published, date_format)\n",
    "        \n",
    "        hasura_timestamp = date_object.astimezone(timezone.utc).isoformat()\n",
    "        return True, hasura_timestamp\n",
    "    except ValueError:\n",
    "        # If parsing fails, the string is not in the correct format\n",
    "        return False, None\n",
    "\n",
    "def check_date_format(date_string):\n",
    "    try:\n",
    "        datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "        \n",
    "def mutation_hasura_graphql(endpoint, admin_key, mutation_query, mutation_variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "    response = requests.post(endpoint, json={'query': mutation_query, 'variables': mutation_variables}, headers=headers)\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "        return True, data\n",
    "    else:\n",
    "        print(f\"Mutation failed with status code {response.status_code}: {response.text}\")\n",
    "        return False, None\n",
    "\n",
    "def update_article_details1(offset):\n",
    "    graphql_query = '''\n",
    "    query MyQuery($limit: Int!, $offset: Int!) {\n",
    "    synopse_articles_t_v1_rss1_articles(limit: $limit, offset: $offset, where: {is_in_detail: {_eq: 0}}, order_by: {post_published: desc}) {\n",
    "        post_link\n",
    "        is_default_image\n",
    "        id\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    offset1 = offset\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [synopse_articles_t_v1_rss1_articles_detail_insert_input!] = {}, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = {where: {}}) {\n",
    "        insert_synopse_articles_t_v1_rss1_articles_detail(objects: $objects, on_conflict: {constraint: t_v1_rss1_articles_detail_article_id_key}) {\n",
    "            affected_rows\n",
    "        }\n",
    "        update_synopse_articles_t_v1_rss1_articles_many(updates: $updates) {\n",
    "            affected_rows\n",
    "        }\n",
    "        }\n",
    "\n",
    "    \"\"\"    \n",
    "    options = webdriver.EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "        \"profile.default_content_setting_values.notifications\": 2,  # Disable notifications\n",
    "        \"profile.default_content_setting_values.media_stream_mic\": 2,  # Disable microphone\n",
    "        \"profile.default_content_setting_values.media_stream_camera\": 2,  # Disable camera\n",
    "        \"profile.default_content_setting_values.geolocation\": 2,  # Disable location services\n",
    "        \"profile.default_content_setting_values.automatic_downloads\": 2  # Disable automatic downloads\n",
    "    })\n",
    "    options.add_argument(\"--no-first-run\")  # Skip the welcome page\n",
    "    options.add_argument(\"--disable-infobars\")  # Disable the info bars\n",
    "    options.add_argument(\"--disable-extensions\")  # Disable extensions\n",
    "    options.add_argument(\"--disable-popup-blocking\")  # Disable popups\n",
    "    options.add_argument(\"--disable-features=EdgeTips\") \n",
    "    options.page_load_strategy = 'eager'\n",
    "    options.add_argument('--enable-immersive-reader')\n",
    "    driver = webdriver.Edge(options=options)\n",
    "    variables = {\n",
    "    \"limit\": 1,\n",
    "    \"offset\": offset1\n",
    "    }\n",
    "    response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "    #print(variables, response_data)\n",
    "    #print(response_data)\n",
    "    post_links_array = []\n",
    "    ids=[]\n",
    "    is_default_image_array = []\n",
    "    if response_data:\n",
    "        post_links_array = [item[\"post_link\"] for item in response_data[\"data\"][\"synopse_articles_t_v1_rss1_articles\"]]\n",
    "        is_default_image_array = [item[\"is_default_image\"] for item in response_data[\"data\"][\"synopse_articles_t_v1_rss1_articles\"]]\n",
    "        ids=[item[\"id\"] for item in response_data[\"data\"][\"synopse_articles_t_v1_rss1_articles\"]]\n",
    "    articles_detail = []\n",
    "    articles_update = []\n",
    "    for a in range(len(post_links_array)):\n",
    "        main_link = post_links_array[a]\n",
    "        print(main_link)\n",
    "        driver.get(main_link)\n",
    "        time.sleep(2)\n",
    "        get_url = driver.current_url\n",
    "        read_link= \"read://\"+get_url\n",
    "        driver.get(read_link)\n",
    "        time.sleep(2)\n",
    "        ActionChains(driver).key_down(Keys.CONTROL).send_keys('a').key_up(Keys.CONTROL).perform()\n",
    "        ActionChains(driver).key_down(Keys.CONTROL).send_keys('c').key_up(Keys.CONTROL).perform()\n",
    "        text = pyperclip.paste()\n",
    "        text2 = text\n",
    "        text3 = text2.split('\\n')\n",
    "        text3 = [s.replace('\\r', '') for s in text3]\n",
    "        special_chars = set(\"!@#$%^&*()_+[]{}|;:'\\\",<>?\")\n",
    "        text4 = [s for s in text3 if len(s) > 0 and (s[0] not in special_chars or s[-1] not in special_chars)]\n",
    "        my_list = text4\n",
    "        if my_list[0] == \"Hmmm… can't reach this page\":\n",
    "            articles_update.append({\n",
    "                \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                \"_set\": {\"is_in_detail\": 2}\n",
    "            })\n",
    "        my_set = set()\n",
    "        desription = []\n",
    "        for item in my_list:\n",
    "            if item not in my_set:\n",
    "                desription.append(item)\n",
    "                my_set.add(item)\n",
    "        #print(desription)\n",
    "        images_final = []\n",
    "        articles_detail.append({\n",
    "            \"article_id\": ids[a],\n",
    "            \"title\": desription[0],\n",
    "            \"description\": desription[1:],\n",
    "            \"image_link\": images_final,\n",
    "        }\n",
    "        )\n",
    "        if (is_default_image_array[a] == 0 and len(images_final) > 0):\n",
    "            articles_update.append({\n",
    "                \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                \"_set\": {\"is_in_detail\": 1 , \"image_link\": images_final[0], \"is_default_image\": 1}\n",
    "            })\n",
    "        else:\n",
    "            articles_update.append({\n",
    "                \"where\": {\"post_link\" : { \"_eq\": main_link }},\n",
    "                \"_set\": {\"is_in_detail\": 1}\n",
    "            })\n",
    "        \n",
    "        #print(main_link, desription[0], desription[1:], images_final)\n",
    "    #print(articles_update)\n",
    "    mutation_variables = {\n",
    "    \"objects\": articles_detail,\n",
    "    \"updates\": articles_update,\n",
    "    }\n",
    "    out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "    driver.quit()\n",
    "\n",
    "def kill_if_too_long(function, args, max_execution_time):\n",
    "    # Create a process that runs the function with the given arguments\n",
    "    process = multiprocessing.Process(target=function, args=args)\n",
    "    process.start()\n",
    "    mousemove()\n",
    "    delete_tmp()\n",
    "    # Wait for the specified maximum execution time\n",
    "    process.join(timeout=max_execution_time)\n",
    "\n",
    "    # If the process is still running after the maximum execution time, terminate it\n",
    "    if process.is_alive():\n",
    "        print(\"Function is running too long, terminating...\")\n",
    "        process.terminate()\n",
    "        process.join()\n",
    "\n",
    "def kill_process_tree(process_name):\n",
    "    for proc in psutil.process_iter(['pid', 'name']):\n",
    "        # Check if the process name starts with the given name string.\n",
    "        if proc.info['name'].startswith(process_name):\n",
    "            # Kill the process tree\n",
    "            parent = psutil.Process(proc.info['pid'])\n",
    "            for child in parent.children(recursive=True):\n",
    "                try:\n",
    "                    child.kill()\n",
    "                except psutil.NoSuchProcess:\n",
    "                    pass\n",
    "            try:\n",
    "                parent.kill()\n",
    "            except psutil.NoSuchProcess:\n",
    "                pass\n",
    "\n",
    "def get_process_names():\n",
    "    process_names = [proc.info['name'] for proc in psutil.process_iter(['name'])]\n",
    "    return process_names\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        try:\n",
    "            kill_if_too_long(update_article_details1, (30,), 30)\n",
    "            kill_process_tree('msedge')\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing grouping_l1.py\n"
     ]
    }
   ],
   "source": [
    "%%file grouping_l1.py\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import feedparser\n",
    "import re\n",
    "import numpy\n",
    "from datetime import datetime, timezone\n",
    "from multiprocessing import Process, set_start_method\n",
    "import multiprocessing\n",
    "\n",
    "endpoint = \"https://active-monitor-48.hasura.app/v1/graphql\"\n",
    "admin_key = \"bAQuK7HSYvMAp6S6pnqXH0wQlyuKNUICzoW3jwecc27pwz6COLhE750s5YAec7Hz\"\n",
    "\n",
    "def query_hasura_graphql(endpoint, admin_key, query, variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'query': query,\n",
    "        'variables': variables\n",
    "    }\n",
    "    response = requests.post(endpoint, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def is_valid_timezone_format(published):\n",
    "    try:\n",
    "        # Attempt to parse the string\n",
    "        date_format = \"%a, %d %b %Y %H:%M:%S %z\"\n",
    "        date_object = datetime.strptime(published, date_format)\n",
    "\n",
    "        hasura_timestamp = date_object.astimezone(timezone.utc).isoformat()\n",
    "        return True, hasura_timestamp\n",
    "    except ValueError:\n",
    "        # If parsing fails, the string is not in the correct format\n",
    "        return False, None\n",
    "\n",
    "def check_date_format(date_string):\n",
    "    try:\n",
    "        datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def mutation_hasura_graphql(endpoint, admin_key, mutation_query, mutation_variables):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-hasura-admin-secret': f'{admin_key}'\n",
    "    }\n",
    "    response = requests.post(endpoint, json={'query': mutation_query, 'variables': mutation_variables}, headers=headers)\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "        return True, data\n",
    "    else:\n",
    "        print(f\"Mutation failed with status code {response.status_code}: {response.text}\")\n",
    "        return False, None\n",
    "\n",
    "def grouping_l1(offset1):\n",
    "    print(offset1)\n",
    "    graphql_query = '''\n",
    "    query MyQuery($offset: Int!, $limit: Int!) {\n",
    "      synopse_articles_t_v1_rss1_articles(offset: $offset, limit: $limit, order_by: {created_at: desc}, where: {is_grouped: {_eq: 0}, is_vectorized: {_eq: 1}}) {\n",
    "        id\n",
    "      }\n",
    "    }\n",
    "    '''\n",
    "    offset = offset1\n",
    "    mutation_query = \"\"\"\n",
    "    mutation MyMutation($objects: [synopse_articles_t_v3_article_groups_l1_insert_input!] = {}, $updates: [synopse_articles_t_v1_rss1_articles_updates!] = {where: {}}) {\n",
    "      insert_synopse_articles_t_v3_article_groups_l1(objects: $objects, on_conflict: {constraint: t_v3_article_groups_l1_article_id_key}) {\n",
    "        affected_rows\n",
    "      }\n",
    "      update_synopse_articles_t_v1_rss1_articles_many(updates: $updates) {\n",
    "        affected_rows\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    func_query = '''\n",
    "    query MyQuery($p_article_id: bigint!) {\n",
    "      synopse_articles_f_get_similar_articles_l1(args: {p_article_id: $p_article_id}) {\n",
    "        article_id\n",
    "      }\n",
    "    }\n",
    "    '''\n",
    "    while True:\n",
    "        variables = {\n",
    "        \"limit\": 10,\n",
    "        \"offset\": offset\n",
    "        }\n",
    "        synopse_articles_t_v3_article_groups_l1_insert_input_loc=[]\n",
    "        synopse_articles_t_v1_rss1_articles_updates_loc=[]\n",
    "        response_data = query_hasura_graphql(endpoint, admin_key, graphql_query, variables)\n",
    "        if len(response_data['data']['synopse_articles_t_v1_rss1_articles']) == 0:\n",
    "            break\n",
    "        s1= []\n",
    "        ids=[]\n",
    "        for response in response_data['data']['synopse_articles_t_v1_rss1_articles']:\n",
    "            func_variables = {\n",
    "                \"p_article_id\": response['id']\n",
    "                }\n",
    "            func_response_data = query_hasura_graphql(endpoint, admin_key, func_query, func_variables)\n",
    "            article_group = []\n",
    "            #print(json.dumps(func_response_data, indent=4))\n",
    "            if len(func_response_data['data']['synopse_articles_f_get_similar_articles_l1']) > 0:\n",
    "                for func_response in func_response_data['data']['synopse_articles_f_get_similar_articles_l1']:\n",
    "                    article_group.append(func_response['article_id'])\n",
    "\n",
    "            synopse_articles_t_v3_article_groups_l1_insert_input_loc.append({\n",
    "                \"article_id\": response['id'],\n",
    "                \"initial_group\": article_group,\n",
    "                \"article_count\": len(article_group)\n",
    "                }\n",
    "                )\n",
    "            synopse_articles_t_v1_rss1_articles_updates_loc.append({\n",
    "                \"where\": {\"id\" : { \"_eq\": response['id'] }},\n",
    "                \"_set\": {\"is_grouped\": 1}\n",
    "                })\n",
    "        mutation_variables = {\n",
    "        \"objects\": synopse_articles_t_v3_article_groups_l1_insert_input_loc,\n",
    "        \"updates\": synopse_articles_t_v1_rss1_articles_updates_loc,\n",
    "        }\n",
    "        out1 = mutation_hasura_graphql(endpoint=endpoint, admin_key=admin_key, mutation_query=mutation_query, mutation_variables=mutation_variables)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the list of arguments\n",
    "    n1 =  2\n",
    "    mod = 50\n",
    "    n2 = 10\n",
    "    offset = (mod * (n2 + 1)) * n1\n",
    "    set_start_method('spawn', force=True)\n",
    "    args = []\n",
    "    for i in range(0 , n2):\n",
    "      args.append((i * mod) + offset)\n",
    "    print(args)\n",
    "\n",
    "    # Create a list to hold the processes\n",
    "    processes = []\n",
    "\n",
    "    # Create and start a process for each argument\n",
    "    for arg in args:\n",
    "        process = multiprocessing.Process(target=grouping_l1, args=(arg,))\n",
    "        processes.append(process)\n",
    "        process.start()\n",
    "\n",
    "    # Wait for all processes to finish\n",
    "    for process in processes:\n",
    "        process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} grouping_l1.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rss1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
