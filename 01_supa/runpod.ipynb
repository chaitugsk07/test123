{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Former U.N. Ambassador Nikki Haley is running for president, and she's already won the support of all six voters in Dixville Notch, New Hampshire. The small town is known for its midnight voting tradition, and Haley is the first candidate to win all the votes there since 1960. However, Haley still faces an uphill battle against former President Donald Trump, who is leading in the polls. The New Hampshire primary is just getting started, and it's too early to tell how the rest of the state will vote. But for now, Haley can celebrate her small victory in Dixville Notch.\n",
      "\n",
      "In conclusion, the New Hampshire primary is underway, and voters in Dixville Notch have already cast their ballots. Former U.N. Ambassador Nikki Haley won the support of all six voters in the small town, but she still faces an uphill battle against former President Donald Trump, who is leading in the polls. Dixville Notch is known for its midnight voting tradition, and Haley is the first candidate to win all the votes there since 1960. However, it's too early to tell how the rest of the state will vote. The New Hampshire primary is an important event in the U.S. political landscape, and it will be interesting to see how the race between Haley and Trump unfolds.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "url = \"https://4d2ltz6qvx9r9v-5000.proxy.runpod.net/v1/completions\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"authorization\": \"sk-111111111111111111111111111111111111111111111111\"\n",
    "}\n",
    "\n",
    "history = []\n",
    "\n",
    "data = {\n",
    "    \"prompt\": \"\"\"Concisely provide a balanced and objective summary of the articles limited to a minimum of 3 paragraphs in 150 to 200 words. Capture the key points acknowledging diverse perspectives showcasing factual information without personal opinion. Briefly explain the topic's context and potential implications allowing readers to form their own informed conclusions. Remember to strive for neutrality while remaining engaging and informative to focus on factual information by avoiding emotional language or sensationalism. Employ active voice and concise sentences for maximum clarity to ensure the summary is easily understood.\n",
    "\n",
    "        \n",
    "Voting underway in New Hampshire primary Voting is underway in the New Hampshire primary, with the small town of Dixville Notch starting things off just after midnight. All six voters in the small town voted for Nikki Haley, but the former U.S. ambassador to the U.N. will need a lot more to beat former President Donald Trump. Tony Dokoupil has more from Manchester, New Hampshire, and Caitlin Huey-Burns reports on the race between Haley and Trump. Voting is underway in the New Hampshire primary, with the small town of Dixville Notch starting things off just after midnight. All six voters in the small town voted for Nikki Haley, but the former U.S. ambassador to the U.N. will need a lot more to beat former President Donald Trump. Tony Dokoupil has more from Manchester, New Hampshire, and Caitlin Huey-Burns reports on the race between Haley and Trump.\n",
    "\n",
    "Nikki Haley wins all 6 votes in Dixville Notch primary Voters in Dixville Notch, New Hampshire, came out unanimously for Nikki Haley over Donald Trump early on Tuesday. Dixville Notch is the tiny resort township where community members traditionally vote at midnight on primary day. CBS News political reporter Cristina Corujo was at the polling site. Voters in Dixville Notch, New Hampshire, came out unanimously for Nikki Haley over Donald Trump early on Tuesday. Dixville Notch is the tiny resort township where community members traditionally vote at midnight on primary day. CBS News political reporter Cristina Corujo was at the polling site.\"\"\",\n",
    "\n",
    "          \"max_tokens\": 1000,\n",
    "          \"temperature\": 0.3,\n",
    "          \"top_p\": 0.9,\n",
    "          \"seed\": 10\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data, verify=False)\n",
    "assistant_message = response.json()['choices'][0]['text']\n",
    "print(assistant_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"id\":\"conv-1706262449480150528\",\"object\":\"text_completion\",\"created\":1706262449,\"model\":\"TheBloke_Mistral-7B-Instruct-v0.2-GPTQ\",\"choices\":[{\"index\":0,\"finish_reason\":\"length\",\"text\":\" Preheat the oven to 350 degrees F (175 degrees C). Grease and flour a 9-inch round cake pan.\\\\n2. In a large bowl, cream together 1/2 cup (1 stick) of unsalted butter and 1 cup of granulated sugar until light and fluffy.\\\\n3. Beat in 2 eggs, one at a time, then add 2 teaspoons of pure vanilla extract.\\\\n4. In a separate bowl, combine 2 cups of all-purpose flour, 1 teaspoon of baking powder, 1 teaspoon of baking soda, and 1/4 teaspoon of salt.\\\\n5. Gradually add the dry ingredients to the butter mixture, alternating with 1 1/2 cups of buttermilk.\\\\n6. Fold in 1 cup of grated carrots, 1/2 cup of raisins, and \",\"logprobs\":{\"top_logprobs\":[{}]}}],\"usage\":{\"prompt_tokens\":11,\"completion_tokens\":202,\"total_tokens\":213}}'\n"
     ]
    }
   ],
   "source": [
    "print(response.content)\n",
    "print(\"asdasd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 =\"\"\"\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"title\": \"Nikki Haley Wins Unanimously in Dixville Notch Primary Ahead of Donald Trump\",\n",
    "  \"keypoints\": [\n",
    "    {\n",
    "      \"point\": \"Nikki Haley receives all 6 votes in Dixville Notch primary, while Donald Trump is yet to receive any.\"\n",
    "    },\n",
    "    {\n",
    "      \"point\": \"Dixville Notch, a tiny resort township, traditionally votes at midnight on primary day.\"\n",
    "    },\n",
    "    {\n",
    "      \"point\": \"Nikki Haley, former U.S. ambassador to the U.N., needs more votes to beat former President Donald Trump.\"\n",
    "    }\n",
    "  ],\n",
    "  \"body\": \"In the New Hampshire primary, Nikki Haley won all 6 votes in Dixville Notch, a tiny resort township where community members traditionally vote at midnight on primary day. However, Haley will need more votes to beat former President Donald Trump. The New Hampshire primary is underway, and Dixville Notch was the first town to start voting. While Haley won all the votes in Dixville Notch, it is essential to note that she will need more votes to beat Trump. The race between Haley and Trump is a significant one, and it will be interesting to see how it unfolds in the coming days.\",\n",
    "  \"tags\": [\"Politics & Global Affairs\"],\n",
    "  \"keywords\": [\"Nikki Haley\", \"Donald Trump\", \"New Hampshire primary\", \"Dixville Notch\", \"U.S. ambassador to the U.N.\"]\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Nikki Haley Wins Unanimously in Dixville Notch Primary Ahead of Donald Trump', 'keypoints': [{'point': 'Nikki Haley receives all 6 votes in Dixville Notch primary, while Donald Trump is yet to receive any.'}, {'point': 'Dixville Notch, a tiny resort township, traditionally votes at midnight on primary day.'}, {'point': 'Nikki Haley, former U.S. ambassador to the U.N., needs more votes to beat former President Donald Trump.'}], 'body': 'In the New Hampshire primary, Nikki Haley won all 6 votes in Dixville Notch, a tiny resort township where community members traditionally vote at midnight on primary day. However, Haley will need more votes to beat former President Donald Trump. The New Hampshire primary is underway, and Dixville Notch was the first town to start voting. While Haley won all the votes in Dixville Notch, it is essential to note that she will need more votes to beat Trump. The race between Haley and Trump is a significant one, and it will be interesting to see how it unfolds in the coming days.', 'tags': ['Politics & Global Affairs'], 'keywords': ['Nikki Haley', 'Donald Trump', 'New Hampshire primary', 'Dixville Notch', 'U.S. ambassador to the U.N.']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json(s):\n",
    "    start = s.find('{')\n",
    "    end = s.rfind('}') + 1  # +1 to include the '}' in the substring\n",
    "    json_str = s[start:end]\n",
    "    try:\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "    \n",
    "json_obj = extract_json(t1)\n",
    "print(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nikki Haley Wins Unanimously in Dixville Notch Primary Ahead of Donald Trump\n",
      "['Nikki Haley receives all 6 votes in Dixville Notch primary, while Donald Trump is yet to receive any.', 'Dixville Notch, a tiny resort township, traditionally votes at midnight on primary day.', 'Nikki Haley, former U.S. ambassador to the U.N., needs more votes to beat former President Donald Trump.']\n",
      "In the New Hampshire primary, Nikki Haley won all 6 votes in Dixville Notch, a tiny resort township where community members traditionally vote at midnight on primary day. However, Haley will need more votes to beat former President Donald Trump. The New Hampshire primary is underway, and Dixville Notch was the first town to start voting. While Haley won all the votes in Dixville Notch, it is essential to note that she will need more votes to beat Trump. The race between Haley and Trump is a significant one, and it will be interesting to see how it unfolds in the coming days.\n",
      "['Politics & Global Affairs']\n",
      "['Nikki Haley', 'Donald Trump', 'New Hampshire primary', 'Dixville Notch', 'U.S. ambassador to the U.N.']\n"
     ]
    }
   ],
   "source": [
    "print(json_obj['title'])\n",
    "result = [item['point'] for item in json_obj['keypoints']]\n",
    "print(result)\n",
    "print(json_obj['body'])\n",
    "print(json_obj['tags'])\n",
    "print(json_obj['keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'meta-llama/Llama-2-7b-chat-hf-5bad1ecb-d1a3-41fa-aab5-df317549eb1f', 'object': 'text_completion', 'created': 1707918662, 'model': 'meta-llama/Llama-2-7b-chat-hf', 'choices': [{'message': {'role': 'assistant', 'content': '  Test!', 'tool_calls': None, 'tool_call_id': None}, 'index': 0, 'finish_reason': 'stop', 'logprobs': None}], 'usage': {'prompt_tokens': 32, 'completion_tokens': 4, 'total_tokens': 36}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "s = requests.Session()\n",
    "\n",
    "api_base = \"https://api.endpoints.anyscale.com/v1\"\n",
    "token = \"esecret_7eix5t1gpk7a9t356htd89jn2g\"\n",
    "url = f\"{api_base}/chat/completions\"\n",
    "body = {\n",
    "  \"model\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "  \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \n",
    "               {\"role\": \"user\", \"content\": \"Say 'Test'.\"}],\n",
    "  \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "with s.post(url, headers={\"Authorization\": f\"Bearer {token}\"}, json=body) as resp:\n",
    "    print(resp.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's have a chat. (Enter `quit` to exit)\n",
      ">   I'm just an AI, I don't have have personal opinions or biases, and I cannot predict the outcome of the war between Russia and Ukraine. The conflict is a complex issue with many variables and factors involved, and it's difficult to make a definitive prediction.\n",
      "\n",
      "However, I can provide some context and insights based on the information available. The conflict between Russia and Ukraine has been ongoing since 2014, and it has escalated into a full-scale war in recent months. The situation on the battlefield is fluid and dynamic, with both sides reporting gains and losses.\n",
      "\n",
      "Russia has a significant advantage in terms of military hardware and manpower, and it has been able to make progress in some areas. However, Ukraine has shown remarkable resilience and has been able to defend itself effectively in many instances. The country has also received significant support from the international community, including military aid and economic assistance.\n",
      "\n",
      "The outcome of the war will depend on various factors, including the effectiveness of each side's military strategies, the political will of the leaders involved, and the response of the international community. It's important to note that the conflict has already caused significant human suffering, displacement, and economic hardship, and a peaceful resolution is desperately needed.\n",
      "\n",
      "In the end, a negotiated settlement that addresses the core issues driving the conflict is likely the best outcome for all parties involved. Diplomatic efforts have been ongoing, and it's possible that a peace agreement could be reached in the coming months. However, the conflict is complex, and a lasting resolution will require sustained effort and compromise from all sides.\n",
      ">   I cannot predict the outcome of the war with certainty, but I can provide some context and insights based on current information.\n",
      "\n",
      "The conflict between Russia and Ukraine has been ongoing since 2014, with various periods of escalation and de-escalation. The recent incident involving the downing of a Russian military transport plane has raised tensions again, with both sides accusing each other of responsibility.\n",
      "\n",
      "Russia has been facing international sanctions and criticism due to its actions in Ukraine, and the country has been trying to acquire more ballistic missiles from foreign countries, including Iran and North Korea, to counter Ukraine's air defenses. Meanwhile, Ukraine's allies have promised to continue sending military aid, despite stretched resources.\n",
      "\n",
      "In terms of military strength, both countries have been building up their capabilities. Russia has a larger military budget and a greater number of military personnel, but Ukraine has been receiving military aid from the West and has been focusing on developing its air defenses.\n",
      "\n",
      "It's difficult to predict how the conflict will unfold in the coming months, but it's clear that there are significant challenges ahead for both sides. A peaceful resolution to the conflict would require a comprehensive and inclusive political settlement, which has yet to be achieved.\n",
      "\n",
      "In the meantime, it's important for both sides to avoid further escalation and to prioritize diplomatic efforts to find a peaceful solution. The international community should also continue to support efforts to resolve the conflict and to provide humanitarian assistance to those affected by the fighting.\n",
      ">   I cannot predict the outcome of the war or take sides. However, I can provide some context and insights based on the information available.\n",
      "\n",
      "The conflict between Russia and Ukraine has been ongoing since 2014, with both sides suffering losses and gaining victories. The situation is complex, with both sides accusing each other of aggression and violations of human rights.\n",
      "\n",
      "The recent incident involving the Russian transport plane crashing near the border with Ukraine, killing all 74 people on board, has raised tensions and sparked accusations from both sides. Russia's Defense Ministry has accused Ukraine of shooting down the plane, while Ukrainian officials have denied any involvement and suggested that the plane may have been downed by friendly fire or a technical malfunction.\n",
      "\n",
      "It's difficult to determine who will win the war, as the conflict is complex and involves various factors, including military strength, political will, and international diplomacy. The conflict has already caused significant human suffering, displacement, and economic hardship, and it's important for all parties involved to work towards a peaceful resolution.\n",
      "\n",
      "The international community has been involved in attempts to resolve the conflict through diplomatic efforts, with the United"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inp \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 29\u001b[0m, in \u001b[0;36mOpenAIChatAgent.process_input\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     22\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moai_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     23\u001b[0m    \n\u001b[0;32m     24\u001b[0m    model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m     25\u001b[0m    messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage_history,\n\u001b[0;32m     26\u001b[0m    stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 29\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelta\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# End token \u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\openai\\_streaming.py:44\u001b[0m, in \u001b[0;36mStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[_T]:\n\u001b[1;32m---> 44\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\openai\\_streaming.py:56\u001b[0m, in \u001b[0;36mStream.__stream__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m process_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_process_response_data\n\u001b[0;32m     54\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_events()\n\u001b[1;32m---> 56\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[DONE]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\openai\\_streaming.py:48\u001b[0m, in \u001b[0;36mStream._iter_events\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_events\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder\u001b[38;5;241m.\u001b[39miter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39miter_lines())\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\openai\\_streaming.py:224\u001b[0m, in \u001b[0;36mSSEDecoder.iter\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miter\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator: Iterator[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given an iterator that yields lines, iterate over it & yield every event encountered\"\"\"\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43msse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\httpx\\_models.py:863\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    861\u001b[0m decoder \u001b[38;5;241m=\u001b[39m LineDecoder()\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 863\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\httpx\\_models.py:850\u001b[0m, in \u001b[0;36mResponse.iter_text\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    848\u001b[0m chunker \u001b[38;5;241m=\u001b[39m TextChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\httpx\\_models.py:829\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    827\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 829\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\httpx\\_models.py:887\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    884\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 887\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\httpx\\_client.py:124\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m--> 124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\httpx\\_transports\\default.py:111\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 111\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:361\u001b[0m, in \u001b[0;36mConnectionPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m--> 361\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\httpcore\\_sync\\http11.py:337\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 337\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\httpcore\\_sync\\http11.py:329\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[1;32m--> 329\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\httpcore\\_sync\\http11.py:198\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    195\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\httpcore\\_sync\\http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 212\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mc:\\Users\\gskch\\miniconda3\\envs\\syn1\\Lib\\ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import openai\n",
    "\n",
    "ANYSCALE_ENDPOINT_TOKEN = \"esecret_7eix5t1gpk7a9t356htd89jn2g\"\n",
    "class OpenAIChatAgent:\n",
    "    def __init__(self, model: str):\n",
    "    #In this simple example, we do not modify the past conversation.\n",
    "    #Eventually you will run out of context window, but this should be enough for a 30-step conversation\n",
    "    #You need to either trim the message history or summarize it for longer conversations\n",
    "        self.message_history = []\n",
    "        self.model = model \n",
    "        self.oai_client = openai.OpenAI(\n",
    "           base_url = \"https://api.endpoints.anyscale.com/v1\",\n",
    "           api_key=ANYSCALE_ENDPOINT_TOKEN\n",
    "        )\n",
    "    def greet(self):\n",
    "        return None\n",
    "\n",
    "    def process_input(self, input: str):\n",
    "        self.update_message_history(input)\n",
    "\n",
    "        response = self.oai_client.chat.completions.create(\n",
    "           \n",
    "           model = self.model,\n",
    "           messages = self.message_history,\n",
    "           stream = True\n",
    "        )\n",
    "        words = ''\n",
    "        for tok in response: \n",
    "            delta = tok.choices[0].delta\n",
    "            if not delta: # End token \n",
    "                self.message_history.append({\n",
    "                    'role': 'assistant',\n",
    "                    'content': words\n",
    "                })\n",
    "                break\n",
    "            elif delta.content:\n",
    "                words += delta.content\n",
    "                yield delta.content \n",
    "            else: \n",
    "                continue\n",
    "\n",
    "    def update_message_history(self, inp):\n",
    "        self.message_history.append({\n",
    "            'role': 'user',\n",
    "            'content': inp\n",
    "        })\n",
    "        \n",
    "agent = OpenAIChatAgent(\"meta-llama/Llama-2-70b-chat-hf\")\n",
    "sys.stdout.write(\"Let's have a chat. (Enter `quit` to exit)\\n\") \n",
    "while True: \n",
    "    sys.stdout.write('> ')\n",
    "    inp = input()\n",
    "    if inp == 'quit':\n",
    "        break\n",
    "    for word in agent.process_input(inp):\n",
    "        sys.stdout.write(word)\n",
    "        sys.stdout.flush()\n",
    "    sys.stdout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [404]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://6fo3h5eavtckki-5000.proxy.runpod.net\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"input\": {\n",
    "        \"text\": \"This is a demo of text to speech by MetaVoice-1B, an open-source foundational audio model by MetaVoice.\",\n",
    "        \"input_audio\": \"https://replicate.delivery/pbxt/KMZ6fyOMKrtwERmDWAJnd5KRy39a86dgloX7SYP5dVTnQXjv/jacob.wav\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing summerize.py\n"
     ]
    }
   ],
   "source": [
    "%%file summerize.py\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "import numpy\n",
    "from datetime import datetime, timezone\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from multiprocessing import Process, set_start_method\n",
    "import multiprocessing\n",
    "import time\n",
    "import gc\n",
    "import psycopg2\n",
    "\n",
    "def create_conn_source(select_query):\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=\"ep-purple-boat-77462220.ap-southeast-1.aws.neon.tech\",\n",
    "            database=\"neondb\",\n",
    "            user=\"gskchaitanya.gadde\",\n",
    "            password=\"aWO71xgmLjUv\"\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(select_query)\n",
    "        rows = cur.fetchall()\n",
    "        return rows\n",
    "        cur.close()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "\n",
    "def update_conn_source(update_query):\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=\"ep-purple-boat-77462220.ap-southeast-1.aws.neon.tech\",\n",
    "            database=\"neondb\",\n",
    "            user=\"gskchaitanya.gadde\",\n",
    "            password=\"aWO71xgmLjUv\"\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(update_query)\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "\n",
    "def insert_conn_source(insert_query, data):\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=\"ep-purple-boat-77462220.ap-southeast-1.aws.neon.tech\",\n",
    "            database=\"neondb\",\n",
    "            user=\"gskchaitanya.gadde\",\n",
    "            password=\"aWO71xgmLjUv\"\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        for item in data:\n",
    "            #print(item)\n",
    "            cur.execute(insert_query, item)\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        print(\"Data inserted successfully\")\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "\n",
    "def is_valid_timezone_format(published):\n",
    "    try:\n",
    "        # Attempt to parse the string\n",
    "        date_format = \"%a, %d %b %Y %H:%M:%S %z\"\n",
    "        date_object = datetime.strptime(published, date_format)\n",
    "\n",
    "        hasura_timestamp = date_object.astimezone(timezone.utc).isoformat()\n",
    "        return True, hasura_timestamp\n",
    "    except ValueError:\n",
    "        # If parsing fails, the string is not in the correct format\n",
    "        return False, None\n",
    "\n",
    "def check_date_format(date_string):\n",
    "    try:\n",
    "        datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(device)\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "def summarize(text, maxSummarylength=500):\n",
    "    # Encode the text and summarize\n",
    "    inputs = tokenizer.encode(\"summarize: \" +\n",
    "                              text,\n",
    "                              return_tensors=\"pt\",\n",
    "                              max_length=1024, truncation=True).to(device)\n",
    "    summary_ids = model.generate(inputs, max_length=int(maxSummarylength),  # Cast to int\n",
    "                                 min_length=int(maxSummarylength/2),\n",
    "                                 length_penalty=10.0,\n",
    "                                 num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "def split_text_into_pieces(text,\n",
    "                           max_tokens=900,\n",
    "                           overlapPercent=10):\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # Calculate the overlap in tokens\n",
    "    overlap_tokens = int(max_tokens * overlapPercent / 100)\n",
    "\n",
    "    # Split the tokens into chunks of size\n",
    "    # max_tokens with overlap\n",
    "    pieces = [tokens[i:i + max_tokens]\n",
    "              for i in range(0, len(tokens),\n",
    "                             max_tokens - overlap_tokens)]\n",
    "\n",
    "    # Convert the token pieces back into text\n",
    "    text_pieces = [tokenizer.decode(\n",
    "        tokenizer.convert_tokens_to_ids(piece),\n",
    "        skip_special_tokens=True) for piece in pieces]\n",
    "\n",
    "    return text_pieces\n",
    "\n",
    "\n",
    "def recursive_summarize(text, max_length=200, recursionLevel=0):\n",
    "    recursionLevel=recursionLevel+1\n",
    "    # print(\"######### Recursion level: \",\n",
    "    #       recursionLevel,\"\\n\\n######### \")\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    expectedCountOfChunks = len(tokens)/max_length\n",
    "    max_length=int(len(tokens)/expectedCountOfChunks)+2\n",
    "\n",
    "    # Break the text into pieces of max_length\n",
    "    pieces = split_text_into_pieces(text, max_tokens=max_length)\n",
    "\n",
    "    # print(\"Number of pieces: \", len(pieces))\n",
    "    # Summarize each piece\n",
    "    summaries=[]\n",
    "    k=0\n",
    "    for k in range(0, len(pieces)):\n",
    "        piece=pieces[k]\n",
    "        # print(\"****************************************************\")\n",
    "        # print(\"Piece:\",(k+1),\" out of \", len(pieces), \"pieces\")\n",
    "        # print(piece, \"\\n\")\n",
    "        summary =summarize(piece, maxSummarylength=max_length/3*2)\n",
    "        # print(\"SUMNMARY: \", summary)\n",
    "        summaries.append(summary)\n",
    "        # print(\"****************************************************\")\n",
    "\n",
    "    concatenated_summary = ' '.join(summaries)\n",
    "\n",
    "    tokens = tokenizer.tokenize(concatenated_summary)\n",
    "\n",
    "    if len(tokens) > max_length:\n",
    "        # If the concatenated_summary is too long, repeat the process\n",
    "        # print(\"############# GOING RECURSIVE ##############\")\n",
    "        return recursive_summarize(concatenated_summary,\n",
    "                                   max_length=max_length,\n",
    "                                   recursionLevel=recursionLevel)\n",
    "    else:\n",
    "      # Concatenate the summaries and summarize again\n",
    "        final_summary=concatenated_summary\n",
    "        if len(pieces)>1:\n",
    "            final_summary = summarize(concatenated_summary,\n",
    "                                  maxSummarylength=max_length)\n",
    "        return final_summary\n",
    "\n",
    "def summerizer(offset1):\n",
    "  print(offset1)\n",
    "  while True:\n",
    "    articles_details = \"\"\"\n",
    "      SELECT\n",
    "        a.id,\n",
    "        a.title,\n",
    "        a.summary,\n",
    "        a.detail\n",
    "      FROM\n",
    "        synopse_articles.v_v6_article_word_count a\n",
    "      where a.is_in_detail = 1\n",
    "      and a.is_vectorized = 0\n",
    "      and a.is_summerized = 0\n",
    "      and a.total_count >= 300\n",
    "      ORDER BY\n",
    "        id DESC\n",
    "      LIMIT 1 OFFSET \"\"\" + str(offset1) + \"\"\";\n",
    "      \"\"\"\n",
    "    articles_details_output = create_conn_source(articles_details)\n",
    "    if len(articles_details_output) == 0:\n",
    "        break\n",
    "    title = articles_details_output[0][1]\n",
    "    summary = articles_details_output[0][2]\n",
    "    description = articles_details_output[0][3]\n",
    "    filled_prompt = title + \"/n\" + summary + \"/n\" + description\n",
    "    summary = recursive_summarize(filled_prompt)\n",
    "    print(summary)\n",
    "    v1 = []\n",
    "    v2 = []\n",
    "    v2.append(articles_details_output[0][0])\n",
    "    v2.append(summary)\n",
    "    v1.append(tuple(v2))\n",
    "    q1= f\"\"\"UPDATE synopse_articles.t_v1_rss1_articles\n",
    "            SET is_summerized = 1\n",
    "            WHERE id = \"\"\" + str(articles_details_output[0][0]) +\"\"\";\"\"\"\n",
    "    update_conn_source(q1)\n",
    "    v1_insert_query =\"INSERT INTO synopse_articles.t_v2_articles_summary (article_id, summary) VALUES (%s, %s)\"\n",
    "    insert_conn_source(v1_insert_query, v1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the list of arguments\n",
    "\n",
    "    set_start_method('spawn', force=True)\n",
    "    args = [ 180 , 190 , 200]\n",
    "\n",
    "    # Create a list to hold the processes\n",
    "    processes = []\n",
    "\n",
    "    # Create and start a process for each argument\n",
    "    for arg in args:\n",
    "        process = multiprocessing.Process(target=summerizer, args=(arg,))\n",
    "        processes.append(process)\n",
    "        process.start()\n",
    "\n",
    "    # Wait for all processes to finish\n",
    "    for process in processes:\n",
    "        process.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} summerize.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syn1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
